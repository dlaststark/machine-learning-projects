{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdtap\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningratefinder import LearningRateFinder\n",
    "from clr_callback import CyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths for train and predict datasets\n",
    "train_file = 'DataSet/Data_Train.xlsx'\n",
    "predict_file = 'DataSet/Data_Test.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train/predict data from spreadsheet into pandas dataframes\n",
    "train_df = pd.read_excel(train_file)\n",
    "predict_df = pd.read_excel(predict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Location</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>Average_Cost</th>\n",
       "      <th>Minimum_Order</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Delivery_Time</th>\n",
       "      <th>Del_Time</th>\n",
       "      <th>Del_Time_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_6321</td>\n",
       "      <td>FTI College, Law College Road, Pune</td>\n",
       "      <td>Fast Food, Rolls, Burger, Salad, Wraps</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_2882</td>\n",
       "      <td>Sector 3, Marathalli</td>\n",
       "      <td>Ice Cream, Desserts</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_1595</td>\n",
       "      <td>Mumbai Central</td>\n",
       "      <td>Italian, Street Food, Fast Food</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>3.6</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>65 minutes</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_5929</td>\n",
       "      <td>Sector 1, Noida</td>\n",
       "      <td>Mughlai, North Indian, Chinese</td>\n",
       "      <td>250</td>\n",
       "      <td>99</td>\n",
       "      <td>3.7</td>\n",
       "      <td>176</td>\n",
       "      <td>95</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_6123</td>\n",
       "      <td>Rmz Centennial, I Gate, Whitefield</td>\n",
       "      <td>Cafe, Beverages</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>3.2</td>\n",
       "      <td>521</td>\n",
       "      <td>235</td>\n",
       "      <td>65 minutes</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant                             Location  \\\n",
       "0    ID_6321  FTI College, Law College Road, Pune   \n",
       "1    ID_2882                 Sector 3, Marathalli   \n",
       "2    ID_1595                       Mumbai Central   \n",
       "3    ID_5929                      Sector 1, Noida   \n",
       "4    ID_6123   Rmz Centennial, I Gate, Whitefield   \n",
       "\n",
       "                                 Cuisines Average_Cost  Minimum_Order Rating  \\\n",
       "0  Fast Food, Rolls, Burger, Salad, Wraps          200             50    3.5   \n",
       "1                     Ice Cream, Desserts          100             50    3.5   \n",
       "2         Italian, Street Food, Fast Food          150             50    3.6   \n",
       "3          Mughlai, North Indian, Chinese          250             99    3.7   \n",
       "4                         Cafe, Beverages          200             99    3.2   \n",
       "\n",
       "  Votes Reviews Delivery_Time  Del_Time  Del_Time_enc  \n",
       "0    12       4    30 minutes        30             0  \n",
       "1    11       4    30 minutes        30             0  \n",
       "2    99      30    65 minutes        65             1  \n",
       "3   176      95    30 minutes        30             0  \n",
       "4   521     235    65 minutes        65             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get numeric value from \"Delivery_Time\" field in train data\n",
    "train_df['Del_Time'] = train_df['Delivery_Time'].apply(lambda x: pd.to_numeric(x.split('minutes')[0].strip()))\n",
    "train_df['Del_Time_enc'] = train_df['Del_Time'].factorize()[0]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_Time</th>\n",
       "      <th>Del_Time_enc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>7406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Del_Time  Del_Time_enc  count\n",
       "0        10             3      4\n",
       "1        20             4     20\n",
       "2        30             0   7406\n",
       "3        45             2   2665\n",
       "4        65             1    923\n",
       "5        80             6     14\n",
       "6       120             5     62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['Del_Time', 'Del_Time_enc']).size().reset_index().rename(columns={0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: (11094, 1)\n",
      "Sample train_y data: \n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Extract \"Del_Time\" field from train_df into NumPy array\n",
    "train_y = np.array([train_df['Del_Time_enc'].values]).T\n",
    "train_df.drop(['Del_Time', 'Delivery_Time', 'Del_Time_enc'], inplace=True, axis=1)\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"Sample train_y data: \\n{}\".format(train_y[0:10,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 8)\n"
     ]
    }
   ],
   "source": [
    "# Combine the train and predict dataframes\n",
    "combined_df = train_df.append(predict_df, sort=False, ignore_index=True)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FTI College, Law College Road, Pune</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Pune</td>\n",
       "      <td>FTI College, Law College Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sector 3, Marathalli</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Sector 3, Marathalli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mumbai Central</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sector 1, Noida</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Sector 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Rmz Centennial, I Gate, Whitefield</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rmz Centennial, I Gate, Whitefield</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Location        State       City  \\\n",
       "0  FTI College, Law College Road, Pune  Maharashtra       Pune   \n",
       "1                 Sector 3, Marathalli    Karnataka  Bangalore   \n",
       "2                       Mumbai Central  Maharashtra     Mumbai   \n",
       "3                      Sector 1, Noida    New Delhi      Noida   \n",
       "4   Rmz Centennial, I Gate, Whitefield    Karnataka  Bangalore   \n",
       "\n",
       "                                 Area  \n",
       "0       FTI College, Law College Road  \n",
       "1                Sector 3, Marathalli  \n",
       "2                      Mumbai Central  \n",
       "3                            Sector 1  \n",
       "4  Rmz Centennial, I Gate, Whitefield  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read location analysis data\n",
    "loc_analysis_df = pd.read_excel(\"Location_Analysis.xlsx\")\n",
    "loc_analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 10)\n"
     ]
    }
   ],
   "source": [
    "# Derive \"State\", \"City\" and \"Area\" based on \"Location\" field\n",
    "combined_df['State'] = combined_df['Location'].apply(lambda x: loc_analysis_df[loc_analysis_df['Location'] == x]['State'].max(axis=0))\n",
    "combined_df['City'] = combined_df['Location'].apply(lambda x: loc_analysis_df[loc_analysis_df['Location'] == x]['City'].max(axis=0))\n",
    "combined_df['Area'] = combined_df['Location'].apply(lambda x: loc_analysis_df[loc_analysis_df['Location'] == x]['Area'].max(axis=0))\n",
    "combined_df.drop(['Location'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 14)\n"
     ]
    }
   ],
   "source": [
    "# Convert \"State\" field to one-hot encoding\n",
    "dummy_df = pd.get_dummies(combined_df['State'], prefix='State')\n",
    "combined_df = pd.concat([combined_df, dummy_df], axis=1)\n",
    "combined_df.drop(['State'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 24)\n"
     ]
    }
   ],
   "source": [
    "# Convert \"City\" field to one-hot encoding\n",
    "dummy_df = pd.get_dummies(combined_df['City'], prefix='City')\n",
    "combined_df = pd.concat([combined_df, dummy_df], axis=1)\n",
    "combined_df.drop(['City'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 94)\n"
     ]
    }
   ],
   "source": [
    "# Column encoding for \"Area\" field\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, ngram_range=(1, 1), stop_words='english', max_features=10000)\n",
    "features = tfidf.fit_transform(combined_df.Area).toarray()\n",
    "features_df = pd.DataFrame(features, columns=tfidf.get_feature_names())\n",
    "combined_df = pd.merge(combined_df, features_df, left_index=True, right_index=True)\n",
    "combined_df.drop(['Area'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 194)\n"
     ]
    }
   ],
   "source": [
    "# Convert \"Cuisines\" field into categorical encoded individual fields\n",
    "combined_df['Cuisine_List'] = combined_df['Cuisines'].apply(lambda x: x.split(', '))\n",
    "combined_df = combined_df.drop('Cuisine_List', 1).join(combined_df.Cuisine_List.str.join('|').str.get_dummies())\n",
    "combined_df.drop(['Cuisines'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 194)\n"
     ]
    }
   ],
   "source": [
    "# Fill invalid string value in \"Average_Cost\" field with mean value\n",
    "combined_df['Avg_Cost'] = combined_df['Average_Cost'].apply(lambda x: np.nan if x == 'for' else x)\n",
    "mean_cost = combined_df['Avg_Cost'].mean()\n",
    "combined_df['Avg_Cost'] = combined_df['Avg_Cost'].fillna(mean_cost)\n",
    "combined_df.drop(['Average_Cost'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 194)\n"
     ]
    }
   ],
   "source": [
    "# Fill invalid string value in \"Rating\" field based on below rule:\n",
    "# 1) If ['NEW','Opening Soon','Temporarily Closed'] then 0\n",
    "# 2) If '-', then NaN\n",
    "combined_df['modified_rating'] = combined_df['Rating'].apply(lambda x: np.nan if x == '-' else (0 if x in ['NEW','Opening Soon','Temporarily Closed'] else pd.to_numeric(x)))\n",
    "mean_rating = combined_df['modified_rating'].mean()\n",
    "combined_df['modified_rating'] = combined_df['modified_rating'].fillna(mean_rating)\n",
    "combined_df.drop(['Rating'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 194)\n"
     ]
    }
   ],
   "source": [
    "# Fill invalid string value in \"Votes\" field with mean value\n",
    "combined_df['modified_votes'] = combined_df['Votes'].apply(lambda x: np.nan if x == '-' else pd.to_numeric(x))\n",
    "mean_cost = combined_df['modified_votes'].mean()\n",
    "combined_df['modified_votes'] = combined_df['modified_votes'].fillna(mean_cost)\n",
    "combined_df.drop(['Votes'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 194)\n"
     ]
    }
   ],
   "source": [
    "# Fill invalid string value in \"Reviews\" field with mean value\n",
    "combined_df['modified_reviews'] = combined_df['Reviews'].apply(lambda x: np.nan if x == '-' else pd.to_numeric(x))\n",
    "mean_cost = combined_df['modified_reviews'].mean()\n",
    "combined_df['modified_reviews'] = combined_df['modified_reviews'].fillna(mean_cost)\n",
    "combined_df.drop(['Reviews'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df: (13868, 193)\n"
     ]
    }
   ],
   "source": [
    "combined_df.drop(['Restaurant'], inplace=True, axis=1)\n",
    "print(\"combined_df: {}\".format(combined_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with NaN value: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any column has NaN value in dataframe\n",
    "print(\"Column with NaN value: {}\".format(combined_df.columns[combined_df.isnull().any()].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate combined_df into train/predict datasets\n",
    "train_x = combined_df[:11094]\n",
    "predict_x = combined_df[11094:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11094, 193)\n",
      "(2774, 193)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(predict_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the train_x/predict_x datasets\n",
    "scaler_x = RobustScaler().fit(train_x)\n",
    "train_x = scaler_x.transform(train_x)\n",
    "predict_x = scaler_x.transform(predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train/validation/test datasets\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=1)\n",
    "for train_index, validation_index in sss.split(train_x, train_y):\n",
    "    train_x, validation_x = train_x[train_index], train_x[validation_index]\n",
    "    train_y, validation_y = train_y[train_index], train_y[validation_index]\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "for train_index, test_index in sss.split(train_x, train_y):\n",
    "    train_x, test_x = train_x[train_index], train_x[test_index]\n",
    "    train_y, test_y = train_y[train_index], train_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "train_x shape: (7543, 193)\n",
      "train_y shape: (7543, 1)\n",
      "\n",
      "------------------------- Validation Dataset -------------------------\n",
      "validation_x shape: (1665, 193)\n",
      "validation_y shape: (1665, 1)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "test_x shape: (1886, 193)\n",
      "test_y shape: (1886, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"train_x shape: {}\".format(train_x.shape))\n",
    "print(\"train_y shape: {}\".format(train_y.shape))\n",
    "\n",
    "print(\"\\n------------------------- Validation Dataset -------------------------\")\n",
    "print(\"validation_x shape: {}\".format(validation_x.shape))\n",
    "print(\"validation_y shape: {}\".format(validation_y.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"test_x shape: {}\".format(test_x.shape))\n",
    "print(\"test_y shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balancing done.\n",
      "train_x shape: (35252, 193)\n",
      "train_y shape: (35252, 1)\n"
     ]
    }
   ],
   "source": [
    "# Handling class imbalance\n",
    "sm = SMOTE(k_neighbors=1)\n",
    "sm_x, sm_y = sm.fit_sample(train_x, train_y.ravel())\n",
    "train_x = sm_x\n",
    "train_y = np.array([sm_y]).T\n",
    "print(\"Class balancing done.\")\n",
    "print(\"train_x shape: {}\".format(train_x.shape))\n",
    "print(\"train_y shape: {}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_y/validation_y/test_y into one-hot encode matrix\n",
    "train_y = tf.keras.utils.to_categorical(train_y, 7)\n",
    "validation_y = tf.keras.utils.to_categorical(validation_y, 7)\n",
    "test_y = tf.keras.utils.to_categorical(test_y, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "train_x shape: (35252, 193)\n",
      "train_y shape: (35252, 7)\n",
      "\n",
      "------------------------- Validation Dataset -------------------------\n",
      "validation_x shape: (1665, 193)\n",
      "validation_y shape: (1665, 7)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "test_x shape: (1886, 193)\n",
      "test_y shape: (1886, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"train_x shape: {}\".format(train_x.shape))\n",
    "print(\"train_y shape: {}\".format(train_y.shape))\n",
    "\n",
    "print(\"\\n------------------------- Validation Dataset -------------------------\")\n",
    "print(\"validation_x shape: {}\".format(validation_x.shape))\n",
    "print(\"validation_y shape: {}\".format(validation_y.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"test_x shape: {}\".format(test_x.shape))\n",
    "print(\"test_y shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform', name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_input_nodes = Integer(low=16, high=128, name='num_input_nodes')\n",
    "dim_num_dense_nodes_FC2 = Integer(low=16, high=128, name='num_dense_nodes_FC2')\n",
    "dim_num_dense_nodes_FC3 = Integer(low=16, high=128, name='num_dense_nodes_FC3')\n",
    "dim_num_dense_nodes_FC4 = Integer(low=8, high=128, name='num_dense_nodes_FC4')\n",
    "dim_num_dense_nodes_FC5 = Integer(low=8, high=128, name='num_dense_nodes_FC5')\n",
    "dim_adam_decay = Real(low=1e-6, high=1e-2, name=\"adam_decay\")\n",
    "\n",
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_input_nodes,\n",
    "              dim_num_dense_nodes_FC2,\n",
    "              dim_num_dense_nodes_FC3,\n",
    "              dim_num_dense_nodes_FC4,\n",
    "              dim_num_dense_nodes_FC5,\n",
    "              dim_adam_decay]\n",
    "\n",
    "default_parameters = [1e-3, 1, 128, 64, 64, 32, 32, 1e-3]\n",
    "\n",
    "input_shape = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers, num_input_nodes, adam_decay,\n",
    "                num_dense_nodes_FC2, num_dense_nodes_FC3, num_dense_nodes_FC4, num_dense_nodes_FC5):\n",
    "    \n",
    "    # Input Layer\n",
    "    x_input = Input(shape=(input_shape, ), name='INPUT')\n",
    "    \n",
    "    # Fully-connected Layer 1\n",
    "    x = Dense(units=num_input_nodes, name='FC-1', activation='relu', kernel_initializer=he_uniform(seed=1), kernel_regularizer=l2(0.1))(x_input)\n",
    "    x = BatchNormalization(name='BN_FC-1')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-1')(x)\n",
    "    \n",
    "    # Fully-connected Layer 2\n",
    "    x = Dense(units=num_dense_nodes_FC2, name='FC-2', activation='relu', kernel_initializer=he_uniform(seed=1), kernel_regularizer=l2(0.1))(x)\n",
    "    x = BatchNormalization(name='BN_FC-2')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-2')(x)\n",
    "    \n",
    "    # Fully-connected Layer 3\n",
    "    x = Dense(units=num_dense_nodes_FC3, name='FC-3', activation='relu', kernel_initializer=he_uniform(seed=1), kernel_regularizer=l2(0.1))(x)\n",
    "    x = BatchNormalization(name='BN_FC-3')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-3')(x)\n",
    "    \n",
    "    # Fully-connected Layer 4\n",
    "    x = Dense(units=num_dense_nodes_FC4, name='FC-4', activation='relu', kernel_initializer=he_uniform(seed=1), kernel_regularizer=l2(0.1))(x)\n",
    "    x = BatchNormalization(name='BN_FC-4')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-4')(x)\n",
    "    \n",
    "    # Fully-connected Layer 5\n",
    "    x = Dense(units=num_dense_nodes_FC5, name='FC-5', activation='relu', kernel_initializer=he_uniform(seed=1), kernel_regularizer=l2(0.1))(x)\n",
    "    x = BatchNormalization(name='BN_FC-5')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-5')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    x = Dense(units=7, activation='softmax', name='OUTPUT', kernel_initializer=he_uniform(seed=1))(x)\n",
    "\n",
    "    # Create Keras Model instance\n",
    "    model = Model(inputs=x_input, outputs=x, name='Model')\n",
    "    \n",
    "    adam = Adam(lr=learning_rate, decay= adam_decay)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers, num_input_nodes, adam_decay,\n",
    "            num_dense_nodes_FC2, num_dense_nodes_FC3, num_dense_nodes_FC4, num_dense_nodes_FC5):\n",
    "\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_input_nodes=num_input_nodes,\n",
    "                         adam_decay=adam_decay,\n",
    "                         num_dense_nodes_FC2=num_dense_nodes_FC2,\n",
    "                         num_dense_nodes_FC3=num_dense_nodes_FC3,\n",
    "                         num_dense_nodes_FC4=num_dense_nodes_FC4,\n",
    "                         num_dense_nodes_FC5=num_dense_nodes_FC5,\n",
    "                        )\n",
    "    \n",
    "    blackbox = model.fit(x=train_x, y=train_y, \n",
    "                         epochs=30, batch_size=128, \n",
    "                         validation_data=(validation_x, validation_y))\n",
    "\n",
    "    accuracy = blackbox.history['val_accuracy'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 11s 299us/sample - loss: 23.9127 - accuracy: 0.2375 - val_loss: 7.1181 - val_accuracy: 0.0126\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 3.6894 - accuracy: 0.4694 - val_loss: 2.2913 - val_accuracy: 0.2408\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.3878 - accuracy: 0.6402 - val_loss: 1.5904 - val_accuracy: 0.2498\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.9863 - accuracy: 0.6944 - val_loss: 1.3636 - val_accuracy: 0.4787\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.8839 - accuracy: 0.7148 - val_loss: 1.4137 - val_accuracy: 0.4306\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.8194 - accuracy: 0.7305 - val_loss: 1.2639 - val_accuracy: 0.5357\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.8033 - accuracy: 0.7349 - val_loss: 1.2740 - val_accuracy: 0.5099\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7738 - accuracy: 0.7399 - val_loss: 1.2248 - val_accuracy: 0.5249\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.7357 - accuracy: 0.7504 - val_loss: 1.1845 - val_accuracy: 0.5574\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.7225 - accuracy: 0.7488 - val_loss: 1.2088 - val_accuracy: 0.5333\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.7105 - accuracy: 0.7524 - val_loss: 1.1796 - val_accuracy: 0.5381\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.6934 - accuracy: 0.7575 - val_loss: 1.2611 - val_accuracy: 0.4649\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.6914 - accuracy: 0.7566 - val_loss: 1.2028 - val_accuracy: 0.5213\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.6680 - accuracy: 0.7615 - val_loss: 1.2034 - val_accuracy: 0.5069\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 116us/sample - loss: 0.6635 - accuracy: 0.7645 - val_loss: 1.1492 - val_accuracy: 0.5327\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.6446 - accuracy: 0.7667 - val_loss: 1.1340 - val_accuracy: 0.5441\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6464 - accuracy: 0.7670 - val_loss: 1.1668 - val_accuracy: 0.5459\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.6333 - accuracy: 0.7740 - val_loss: 1.1053 - val_accuracy: 0.5604\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6333 - accuracy: 0.7715 - val_loss: 1.1666 - val_accuracy: 0.5261\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.6263 - accuracy: 0.7739 - val_loss: 1.1254 - val_accuracy: 0.5459\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6159 - accuracy: 0.7758 - val_loss: 1.1465 - val_accuracy: 0.5423\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6133 - accuracy: 0.7761 - val_loss: 1.1081 - val_accuracy: 0.5664\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6038 - accuracy: 0.7788 - val_loss: 1.1774 - val_accuracy: 0.5111\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.5965 - accuracy: 0.7828 - val_loss: 1.1391 - val_accuracy: 0.5315\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.5892 - accuracy: 0.7840 - val_loss: 1.0982 - val_accuracy: 0.5520\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.5886 - accuracy: 0.7832 - val_loss: 1.1245 - val_accuracy: 0.5411\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.5775 - accuracy: 0.7893 - val_loss: 1.1190 - val_accuracy: 0.5447\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.5698 - accuracy: 0.7863 - val_loss: 1.1572 - val_accuracy: 0.5183\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.5821 - accuracy: 0.7851 - val_loss: 1.1033 - val_accuracy: 0.5447\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.5707 - accuracy: 0.7875 - val_loss: 1.0971 - val_accuracy: 0.5556\n",
      "\n",
      "Accuracy: 55.56%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 11s 300us/sample - loss: 5.4414 - accuracy: 0.4873 - val_loss: 1.9253 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 116us/sample - loss: 1.3380 - accuracy: 0.6391 - val_loss: 1.7102 - val_accuracy: 0.2300\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 1.1301 - accuracy: 0.6745 - val_loss: 1.4431 - val_accuracy: 0.5339\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 1.0329 - accuracy: 0.6895 - val_loss: 1.4854 - val_accuracy: 0.4739\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 0.9446 - accuracy: 0.7034 - val_loss: 1.4071 - val_accuracy: 0.4679\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.8965 - accuracy: 0.7124 - val_loss: 1.3203 - val_accuracy: 0.5664\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 0.8554 - accuracy: 0.7193 - val_loss: 1.3557 - val_accuracy: 0.4925\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 0.8289 - accuracy: 0.7224 - val_loss: 1.2993 - val_accuracy: 0.4907\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 0.7875 - accuracy: 0.7320 - val_loss: 1.2857 - val_accuracy: 0.4991\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 119us/sample - loss: 0.7726 - accuracy: 0.7339 - val_loss: 1.3177 - val_accuracy: 0.4625\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 123us/sample - loss: 0.7566 - accuracy: 0.7372 - val_loss: 1.2034 - val_accuracy: 0.5652\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.7341 - accuracy: 0.7419 - val_loss: 1.2177 - val_accuracy: 0.5399\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.7275 - accuracy: 0.7434 - val_loss: 1.2384 - val_accuracy: 0.4991\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.7031 - accuracy: 0.7445 - val_loss: 1.1985 - val_accuracy: 0.5285\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.6982 - accuracy: 0.7457 - val_loss: 1.2049 - val_accuracy: 0.5514\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 5s 129us/sample - loss: 0.6980 - accuracy: 0.7492 - val_loss: 1.1501 - val_accuracy: 0.5646\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 0.6823 - accuracy: 0.7507 - val_loss: 1.1856 - val_accuracy: 0.5399\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 116us/sample - loss: 0.6769 - accuracy: 0.7509 - val_loss: 1.2209 - val_accuracy: 0.4985\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.6673 - accuracy: 0.7534 - val_loss: 1.1848 - val_accuracy: 0.5411\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 119us/sample - loss: 0.6591 - accuracy: 0.7572 - val_loss: 1.1935 - val_accuracy: 0.5117\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.6525 - accuracy: 0.7571 - val_loss: 1.1959 - val_accuracy: 0.5111\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 116us/sample - loss: 0.6465 - accuracy: 0.7602 - val_loss: 1.1418 - val_accuracy: 0.5471\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.6385 - accuracy: 0.7617 - val_loss: 1.2376 - val_accuracy: 0.4799\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.6306 - accuracy: 0.7648 - val_loss: 1.1139 - val_accuracy: 0.5676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.6259 - accuracy: 0.7644 - val_loss: 1.1246 - val_accuracy: 0.5562\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.6248 - accuracy: 0.7671 - val_loss: 1.1162 - val_accuracy: 0.5586\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.6131 - accuracy: 0.7665 - val_loss: 1.0930 - val_accuracy: 0.5574\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.6207 - accuracy: 0.7646 - val_loss: 1.1162 - val_accuracy: 0.5550\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.6119 - accuracy: 0.7698 - val_loss: 1.1422 - val_accuracy: 0.5285\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.6047 - accuracy: 0.7699 - val_loss: 1.0997 - val_accuracy: 0.5586\n",
      "\n",
      "Accuracy: 55.86%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 242us/sample - loss: 58.7999 - accuracy: 0.1420 - val_loss: 53.0669 - val_accuracy: 0.1976\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 49.1409 - accuracy: 0.1518 - val_loss: 46.4497 - val_accuracy: 0.1796\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 43.8982 - accuracy: 0.1555 - val_loss: 42.2521 - val_accuracy: 0.1664\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 40.4055 - accuracy: 0.1623 - val_loss: 39.2733 - val_accuracy: 0.1616\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 37.7922 - accuracy: 0.1660 - val_loss: 36.9856 - val_accuracy: 0.1538\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 35.7588 - accuracy: 0.1684 - val_loss: 35.1454 - val_accuracy: 0.1453\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 34.0973 - accuracy: 0.1712 - val_loss: 33.6239 - val_accuracy: 0.1477\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 5s 141us/sample - loss: 32.6951 - accuracy: 0.1725 - val_loss: 32.3498 - val_accuracy: 0.1375\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 31.4899 - accuracy: 0.1763 - val_loss: 31.2150 - val_accuracy: 0.1339\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 30.4453 - accuracy: 0.1774 - val_loss: 30.2310 - val_accuracy: 0.1309\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 29.5110 - accuracy: 0.1800 - val_loss: 29.3527 - val_accuracy: 0.1225\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 28.6950 - accuracy: 0.1830 - val_loss: 28.5752 - val_accuracy: 0.1189\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 27.9501 - accuracy: 0.1826 - val_loss: 27.8693 - val_accuracy: 0.1153\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 27.2799 - accuracy: 0.1837 - val_loss: 27.2102 - val_accuracy: 0.1087\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 26.6459 - accuracy: 0.1887 - val_loss: 26.6203 - val_accuracy: 0.1033\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 26.0972 - accuracy: 0.1864 - val_loss: 26.0704 - val_accuracy: 0.1039\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - ETA: 0s - loss: 25.5553 - accuracy: 0.192 - 5s 130us/sample - loss: 25.5553 - accuracy: 0.1925 - val_loss: 25.5603 - val_accuracy: 0.0979\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 127us/sample - loss: 25.0685 - accuracy: 0.1941 - val_loss: 25.0904 - val_accuracy: 0.0919.2035 - accuracy: 0. - ETA: 2s \n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 24.6219 - accuracy: 0.1896 - val_loss: 24.6581 - val_accuracy: 0.0883\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 24.2043 - accuracy: 0.1900 - val_loss: 24.2409 - val_accuracy: 0.0949\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 23.7867 - accuracy: 0.1956 - val_loss: 23.8489 - val_accuracy: 0.0877\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 23.4197 - accuracy: 0.1917 - val_loss: 23.4893 - val_accuracy: 0.0823\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 23.0564 - accuracy: 0.1962 - val_loss: 23.1329 - val_accuracy: 0.0829\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 22.7183 - accuracy: 0.1964 - val_loss: 22.8032 - val_accuracy: 0.0769\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 22.4052 - accuracy: 0.1977 - val_loss: 22.5109 - val_accuracy: 0.0757\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 22.1178 - accuracy: 0.1962 - val_loss: 22.2113 - val_accuracy: 0.0757\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 21.8299 - accuracy: 0.1979 - val_loss: 21.9305 - val_accuracy: 0.0745\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 21.5639 - accuracy: 0.2010 - val_loss: 21.6619 - val_accuracy: 0.0733\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 126us/sample - loss: 21.2795 - accuracy: 0.2052 - val_loss: 21.4015 - val_accuracy: 0.0721\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 120us/sample - loss: 21.0341 - accuracy: 0.2073 - val_loss: 21.1601 - val_accuracy: 0.0733\n",
      "\n",
      "Accuracy: 7.33%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 10s 296us/sample - loss: 38.2666 - accuracy: 0.1972 - val_loss: 18.7603 - val_accuracy: 0.0096\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 12.0048 - accuracy: 0.3215 - val_loss: 7.6950 - val_accuracy: 0.0715\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 5.3968 - accuracy: 0.4312 - val_loss: 4.0463 - val_accuracy: 0.2619\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 2.9498 - accuracy: 0.5477 - val_loss: 2.5456 - val_accuracy: 0.3429\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 1.8099 - accuracy: 0.6428 - val_loss: 1.9170 - val_accuracy: 0.3910\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 1.2763 - accuracy: 0.6838 - val_loss: 1.6338 - val_accuracy: 0.4024\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 1.0019 - accuracy: 0.7164 - val_loss: 1.4367 - val_accuracy: 0.4462\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.8519 - accuracy: 0.7308 - val_loss: 1.2943 - val_accuracy: 0.5369\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.7677 - accuracy: 0.7414 - val_loss: 1.2964 - val_accuracy: 0.5009\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.7112 - accuracy: 0.7549 - val_loss: 1.2528 - val_accuracy: 0.4985\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.6713 - accuracy: 0.7592 - val_loss: 1.1385 - val_accuracy: 0.5664\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.6436 - accuracy: 0.7667 - val_loss: 1.1676 - val_accuracy: 0.5393\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.6250 - accuracy: 0.7670 - val_loss: 1.2163 - val_accuracy: 0.4943\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.6109 - accuracy: 0.7721 - val_loss: 1.1431 - val_accuracy: 0.5375\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.5949 - accuracy: 0.7762 - val_loss: 1.1478 - val_accuracy: 0.5219\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.5853 - accuracy: 0.7787 - val_loss: 1.1306 - val_accuracy: 0.5261\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.5782 - accuracy: 0.7819 - val_loss: 1.1189 - val_accuracy: 0.5399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.5705 - accuracy: 0.7817 - val_loss: 1.0971 - val_accuracy: 0.5357\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.5652 - accuracy: 0.7855 - val_loss: 1.0754 - val_accuracy: 0.5628\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.5516 - accuracy: 0.7886 - val_loss: 1.0842 - val_accuracy: 0.5550\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.5455 - accuracy: 0.7889 - val_loss: 1.0718 - val_accuracy: 0.5640\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.5460 - accuracy: 0.7901 - val_loss: 1.0698 - val_accuracy: 0.5646\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.5393 - accuracy: 0.7916 - val_loss: 1.0694 - val_accuracy: 0.5580\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.5331 - accuracy: 0.7939 - val_loss: 1.0747 - val_accuracy: 0.5598\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.5310 - accuracy: 0.7966 - val_loss: 1.0635 - val_accuracy: 0.5688\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.5279 - accuracy: 0.7963 - val_loss: 1.0778 - val_accuracy: 0.5646\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.5262 - accuracy: 0.7948 - val_loss: 1.0198 - val_accuracy: 0.5832\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.5188 - accuracy: 0.8013 - val_loss: 1.0537 - val_accuracy: 0.5790\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.5156 - accuracy: 0.8008 - val_loss: 1.0975 - val_accuracy: 0.5514\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.5122 - accuracy: 0.8020 - val_loss: 1.0641 - val_accuracy: 0.5640\n",
      "\n",
      "Accuracy: 56.40%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 242us/sample - loss: 8.8077 - accuracy: 0.4767 - val_loss: 1.8429 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.2092 - accuracy: 0.6479 - val_loss: 1.4741 - val_accuracy: 0.3814\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 1.0476 - accuracy: 0.6779 - val_loss: 1.4997 - val_accuracy: 0.4462\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.9584 - accuracy: 0.6964 - val_loss: 1.3582 - val_accuracy: 0.4378\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.9059 - accuracy: 0.7078 - val_loss: 1.3290 - val_accuracy: 0.5261\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.8776 - accuracy: 0.7090 - val_loss: 1.3596 - val_accuracy: 0.4054\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.8339 - accuracy: 0.7168 - val_loss: 1.3139 - val_accuracy: 0.4426\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 0.8076 - accuracy: 0.7228 - val_loss: 1.2418 - val_accuracy: 0.5321\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.7833 - accuracy: 0.7281 - val_loss: 1.2540 - val_accuracy: 0.5021\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.7625 - accuracy: 0.7295 - val_loss: 1.2513 - val_accuracy: 0.4955\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7573 - accuracy: 0.7290 - val_loss: 1.2512 - val_accuracy: 0.5069\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7382 - accuracy: 0.7334 - val_loss: 1.1929 - val_accuracy: 0.5393\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7332 - accuracy: 0.7337 - val_loss: 1.1929 - val_accuracy: 0.5159\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 0.7210 - accuracy: 0.7366 - val_loss: 1.2051 - val_accuracy: 0.4871\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7168 - accuracy: 0.7391 - val_loss: 1.2200 - val_accuracy: 0.5117\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.7208 - accuracy: 0.7379 - val_loss: 1.1687 - val_accuracy: 0.5303\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7058 - accuracy: 0.7436 - val_loss: 1.2442 - val_accuracy: 0.4895\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7069 - accuracy: 0.7401 - val_loss: 1.1922 - val_accuracy: 0.4967\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.6914 - accuracy: 0.7425 - val_loss: 1.1954 - val_accuracy: 0.5255\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.6892 - accuracy: 0.7431 - val_loss: 1.1962 - val_accuracy: 0.4967\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.6856 - accuracy: 0.7455 - val_loss: 1.1366 - val_accuracy: 0.5477\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 0.6789 - accuracy: 0.7473 - val_loss: 1.1747 - val_accuracy: 0.5153\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.6679 - accuracy: 0.7492 - val_loss: 1.1740 - val_accuracy: 0.5057\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.6655 - accuracy: 0.7483 - val_loss: 1.1879 - val_accuracy: 0.5135\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 0.6669 - accuracy: 0.7479 - val_loss: 1.1606 - val_accuracy: 0.5117\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.6623 - accuracy: 0.7489 - val_loss: 1.1226 - val_accuracy: 0.5339\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.6483 - accuracy: 0.7521 - val_loss: 1.1825 - val_accuracy: 0.5117\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.6480 - accuracy: 0.7516 - val_loss: 1.1580 - val_accuracy: 0.5099\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.6481 - accuracy: 0.7510 - val_loss: 1.1184 - val_accuracy: 0.5441\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.6410 - accuracy: 0.7516 - val_loss: 1.1298 - val_accuracy: 0.5315\n",
      "\n",
      "Accuracy: 53.15%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 243us/sample - loss: 72.2677 - accuracy: 0.1492 - val_loss: 61.8441 - val_accuracy: 0.0937\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 57.7323 - accuracy: 0.1584 - val_loss: 53.1803 - val_accuracy: 0.0649\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 51.0822 - accuracy: 0.1715 - val_loss: 48.1488 - val_accuracy: 0.0571\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 46.8565 - accuracy: 0.1784 - val_loss: 44.7001 - val_accuracy: 0.0348\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 43.8279 - accuracy: 0.1851 - val_loss: 42.0880 - val_accuracy: 0.0306\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 41.4937 - accuracy: 0.1914 - val_loss: 40.0290 - val_accuracy: 0.0270\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 39.5977 - accuracy: 0.1934 - val_loss: 38.3328 - val_accuracy: 0.0246\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 38.0135 - accuracy: 0.1978 - val_loss: 36.8875 - val_accuracy: 0.0264\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 36.6551 - accuracy: 0.2040 - val_loss: 35.6559 - val_accuracy: 0.0234\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 35.4764 - accuracy: 0.2066 - val_loss: 34.5700 - val_accuracy: 0.0216\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 4s 113us/sample - loss: 34.4439 - accuracy: 0.2069 - val_loss: 33.6117 - val_accuracy: 0.0186\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 33.5213 - accuracy: 0.2096 - val_loss: 32.7539 - val_accuracy: 0.0210\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 32.6747 - accuracy: 0.2173 - val_loss: 31.9720 - val_accuracy: 0.0192\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 31.9245 - accuracy: 0.2166 - val_loss: 31.2533 - val_accuracy: 0.0174\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 31.2309 - accuracy: 0.2204 - val_loss: 30.6059 - val_accuracy: 0.0192\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 30.5942 - accuracy: 0.2238 - val_loss: 30.0001 - val_accuracy: 0.0186\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 29.9971 - accuracy: 0.2247 - val_loss: 29.4512 - val_accuracy: 0.0168\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 29.4523 - accuracy: 0.2308 - val_loss: 28.9265 - val_accuracy: 0.0192\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 28.9538 - accuracy: 0.2297 - val_loss: 28.4465 - val_accuracy: 0.0192\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 28.4686 - accuracy: 0.2316 - val_loss: 27.9992 - val_accuracy: 0.0174\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 28.0217 - accuracy: 0.2336 - val_loss: 27.5650 - val_accuracy: 0.0150\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 27.6022 - accuracy: 0.2370 - val_loss: 27.1729 - val_accuracy: 0.0150\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 27.1940 - accuracy: 0.2417 - val_loss: 26.7857 - val_accuracy: 0.0168\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 26.8201 - accuracy: 0.2417 - val_loss: 26.4273 - val_accuracy: 0.0162\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 26.4685 - accuracy: 0.2398 - val_loss: 26.0960 - val_accuracy: 0.0168\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 26.1285 - accuracy: 0.2442 - val_loss: 25.7678 - val_accuracy: 0.0156\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 25.8072 - accuracy: 0.2472 - val_loss: 25.4609 - val_accuracy: 0.0168\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 5s 152us/sample - loss: 25.5021 - accuracy: 0.2463 - val_loss: 25.1716 - val_accuracy: 0.0162\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 25.2135 - accuracy: 0.2447 - val_loss: 24.8896 - val_accuracy: 0.0156\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 24.9294 - accuracy: 0.2493 - val_loss: 24.6175 - val_accuracy: 0.0156\n",
      "\n",
      "Accuracy: 1.56%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 10s 270us/sample - loss: 58.7221 - accuracy: 0.1570 - val_loss: 48.5754 - val_accuracy: 0.0246\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 44.0031 - accuracy: 0.1736 - val_loss: 39.7820 - val_accuracy: 0.0342\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 37.2658 - accuracy: 0.1863 - val_loss: 34.7417 - val_accuracy: 0.0330\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 33.0967 - accuracy: 0.1938 - val_loss: 31.3535 - val_accuracy: 0.0312\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 30.1463 - accuracy: 0.2039 - val_loss: 28.8543 - val_accuracy: 0.0312\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 27.9058 - accuracy: 0.2135 - val_loss: 26.9030 - val_accuracy: 0.0318\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 26.1130 - accuracy: 0.2170 - val_loss: 25.3280 - val_accuracy: 0.0300\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 24.6607 - accuracy: 0.2198 - val_loss: 24.0042 - val_accuracy: 0.0324\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 23.4171 - accuracy: 0.2261 - val_loss: 22.8778 - val_accuracy: 0.0306\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 22.3648 - accuracy: 0.2332 - val_loss: 21.9143 - val_accuracy: 0.0306\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 21.4185 - accuracy: 0.2406 - val_loss: 21.0566 - val_accuracy: 0.0360\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 20.6033 - accuracy: 0.2454 - val_loss: 20.2902 - val_accuracy: 0.0384\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 19.8891 - accuracy: 0.2468 - val_loss: 19.6191 - val_accuracy: 0.0390\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 19.2326 - accuracy: 0.2506 - val_loss: 19.0118 - val_accuracy: 0.0378\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 18.6320 - accuracy: 0.2584 - val_loss: 18.4437 - val_accuracy: 0.0396\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 18.0928 - accuracy: 0.2613 - val_loss: 17.9406 - val_accuracy: 0.0384\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 17.6056 - accuracy: 0.2604 - val_loss: 17.4732 - val_accuracy: 0.0408\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 17.1526 - accuracy: 0.2634 - val_loss: 17.0383 - val_accuracy: 0.0420\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 16.7264 - accuracy: 0.2695 - val_loss: 16.6372 - val_accuracy: 0.0414\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 16.3250 - accuracy: 0.2743 - val_loss: 16.2715 - val_accuracy: 0.0426\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 15.9636 - accuracy: 0.2730 - val_loss: 15.9210 - val_accuracy: 0.0480\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 15.6216 - accuracy: 0.2796 - val_loss: 15.6011 - val_accuracy: 0.0426\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 15.3047 - accuracy: 0.2832 - val_loss: 15.2920 - val_accuracy: 0.0468\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 15.0005 - accuracy: 0.2863 - val_loss: 15.0033 - val_accuracy: 0.0462\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 14.7280 - accuracy: 0.2844 - val_loss: 14.7328 - val_accuracy: 0.0414\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 14.4600 - accuracy: 0.2874 - val_loss: 14.4845 - val_accuracy: 0.0462\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 14.1961 - accuracy: 0.2903 - val_loss: 14.2343 - val_accuracy: 0.0462\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 13.9644 - accuracy: 0.2931 - val_loss: 14.0024 - val_accuracy: 0.0474\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 13.7364 - accuracy: 0.2961 - val_loss: 13.7780 - val_accuracy: 0.0492\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 13.5241 - accuracy: 0.2982 - val_loss: 13.5774 - val_accuracy: 0.0505\n",
      "\n",
      "Accuracy: 5.05%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 253us/sample - loss: 43.8288 - accuracy: 0.2206 - val_loss: 18.8648 - val_accuracy: 0.0330\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 119us/sample - loss: 10.1524 - accuracy: 0.3923 - val_loss: 5.1971 - val_accuracy: 0.2360\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 3.0329 - accuracy: 0.5654 - val_loss: 2.1781 - val_accuracy: 0.3628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 1.3674 - accuracy: 0.6805 - val_loss: 1.4548 - val_accuracy: 0.5411\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.9645 - accuracy: 0.7157 - val_loss: 1.4049 - val_accuracy: 0.4462\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.8531 - accuracy: 0.7312 - val_loss: 1.3810 - val_accuracy: 0.4192\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 0.7990 - accuracy: 0.7369 - val_loss: 1.2462 - val_accuracy: 0.4979\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.7796 - accuracy: 0.7401 - val_loss: 1.2257 - val_accuracy: 0.5459\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.7600 - accuracy: 0.7473 - val_loss: 1.2964 - val_accuracy: 0.4673\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 116us/sample - loss: 0.7441 - accuracy: 0.7484 - val_loss: 1.2806 - val_accuracy: 0.4931\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.7239 - accuracy: 0.7571 - val_loss: 1.2538 - val_accuracy: 0.5321\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.7013 - accuracy: 0.7595 - val_loss: 1.1620 - val_accuracy: 0.5556\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.6871 - accuracy: 0.7618 - val_loss: 1.1652 - val_accuracy: 0.5339\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 0.6754 - accuracy: 0.7680 - val_loss: 1.1422 - val_accuracy: 0.5435\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.6684 - accuracy: 0.7681 - val_loss: 1.1325 - val_accuracy: 0.5862\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.6586 - accuracy: 0.7716 - val_loss: 1.2323 - val_accuracy: 0.5141\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - ETA: 0s - loss: 0.6529 - accuracy: 0.77 - 4s 114us/sample - loss: 0.6533 - accuracy: 0.7702 - val_loss: 1.1989 - val_accuracy: 0.5195\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.6434 - accuracy: 0.7757 - val_loss: 1.0999 - val_accuracy: 0.5676\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 0.6300 - accuracy: 0.7777 - val_loss: 1.1729 - val_accuracy: 0.5423\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 5s 147us/sample - loss: 0.6337 - accuracy: 0.7748 - val_loss: 1.1483 - val_accuracy: 0.5495\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.6223 - accuracy: 0.7791 - val_loss: 1.1769 - val_accuracy: 0.5393\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.6173 - accuracy: 0.7793 - val_loss: 1.2038 - val_accuracy: 0.5135\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.6147 - accuracy: 0.7777 - val_loss: 1.1160 - val_accuracy: 0.5532\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 0.6068 - accuracy: 0.7823 - val_loss: 1.1685 - val_accuracy: 0.5123\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 119us/sample - loss: 0.6043 - accuracy: 0.7824 - val_loss: 1.1209 - val_accuracy: 0.5508\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.6026 - accuracy: 0.7815 - val_loss: 1.1027 - val_accuracy: 0.5495\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 115us/sample - loss: 0.6029 - accuracy: 0.7823 - val_loss: 1.1444 - val_accuracy: 0.5201\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 116us/sample - loss: 0.5896 - accuracy: 0.7862 - val_loss: 1.1613 - val_accuracy: 0.5285\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 120us/sample - loss: 0.5810 - accuracy: 0.7861 - val_loss: 1.1207 - val_accuracy: 0.5508\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.5840 - accuracy: 0.7853 - val_loss: 1.1411 - val_accuracy: 0.5387\n",
      "\n",
      "Accuracy: 53.87%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 223us/sample - loss: 48.1198 - accuracy: 0.1604 - val_loss: 40.9732 - val_accuracy: 0.0505\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 37.7995 - accuracy: 0.1702 - val_loss: 34.9329 - val_accuracy: 0.0204\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 33.2198 - accuracy: 0.1776 - val_loss: 31.4685 - val_accuracy: 0.0126\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 30.3351 - accuracy: 0.1867 - val_loss: 29.1025 - val_accuracy: 0.0096\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 28.2882 - accuracy: 0.1889 - val_loss: 27.3490 - val_accuracy: 0.0066\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 26.7209 - accuracy: 0.1927 - val_loss: 25.9546 - val_accuracy: 0.0060\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 25.4566 - accuracy: 0.1961 - val_loss: 24.8145 - val_accuracy: 0.0048\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 24.3924 - accuracy: 0.1964 - val_loss: 23.8590 - val_accuracy: 0.0048\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 23.5086 - accuracy: 0.1944 - val_loss: 23.0353 - val_accuracy: 0.0042\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 22.7184 - accuracy: 0.1988 - val_loss: 22.3128 - val_accuracy: 0.0042\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 22.0383 - accuracy: 0.2011 - val_loss: 21.6802 - val_accuracy: 0.0042\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 21.4299 - accuracy: 0.2044 - val_loss: 21.0959 - val_accuracy: 0.0042\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 20.8871 - accuracy: 0.2048 - val_loss: 20.5738 - val_accuracy: 0.0042\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 20.3851 - accuracy: 0.2100 - val_loss: 20.1196 - val_accuracy: 0.0042\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 19.9398 - accuracy: 0.2119 - val_loss: 19.6950 - val_accuracy: 0.0042\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 19.5156 - accuracy: 0.2113 - val_loss: 19.2983 - val_accuracy: 0.0042\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 19.1378 - accuracy: 0.2109 - val_loss: 18.9380 - val_accuracy: 0.0042\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 18.7780 - accuracy: 0.2186 - val_loss: 18.5968 - val_accuracy: 0.0042\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 18.4521 - accuracy: 0.2164 - val_loss: 18.2859 - val_accuracy: 0.0042\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 18.1432 - accuracy: 0.2169 - val_loss: 17.9909 - val_accuracy: 0.0042\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 17.8489 - accuracy: 0.2203 - val_loss: 17.7070 - val_accuracy: 0.0042\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 17.5793 - accuracy: 0.2182 - val_loss: 17.4466 - val_accuracy: 0.0042\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 17.3231 - accuracy: 0.2230 - val_loss: 17.2039 - val_accuracy: 0.0042\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 17.0835 - accuracy: 0.2173 - val_loss: 16.9620 - val_accuracy: 0.0042\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 16.8522 - accuracy: 0.2240 - val_loss: 16.7439 - val_accuracy: 0.0042\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 16.6448 - accuracy: 0.2247 - val_loss: 16.5413 - val_accuracy: 0.0042\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 3s 92us/sample - loss: 16.4269 - accuracy: 0.2231 - val_loss: 16.3422 - val_accuracy: 0.0042\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 16.2322 - accuracy: 0.2241 - val_loss: 16.1579 - val_accuracy: 0.0042\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 16.0394 - accuracy: 0.2281 - val_loss: 15.9731 - val_accuracy: 0.0048\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 15.8651 - accuracy: 0.2248 - val_loss: 15.8012 - val_accuracy: 0.0048\n",
      "\n",
      "Accuracy: 0.48%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 256us/sample - loss: 79.4138 - accuracy: 0.1648 - val_loss: 59.2098 - val_accuracy: 0.0378\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 49.9315 - accuracy: 0.2020 - val_loss: 42.2035 - val_accuracy: 0.0426\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 37.5016 - accuracy: 0.2438 - val_loss: 33.2832 - val_accuracy: 0.0697\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 30.3303 - accuracy: 0.2851 - val_loss: 27.7058 - val_accuracy: 0.0937\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 25.6056 - accuracy: 0.3124 - val_loss: 23.8500 - val_accuracy: 0.0997\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 22.1989 - accuracy: 0.3406 - val_loss: 21.0013 - val_accuracy: 0.1045\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 19.6347 - accuracy: 0.3619 - val_loss: 18.7720 - val_accuracy: 0.1075\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 120us/sample - loss: 17.5990 - accuracy: 0.3725 - val_loss: 17.0058 - val_accuracy: 0.1123\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 15.9587 - accuracy: 0.3919 - val_loss: 15.5558 - val_accuracy: 0.1111\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 14.6111 - accuracy: 0.3978 - val_loss: 14.3384 - val_accuracy: 0.1081\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 13.4726 - accuracy: 0.4052 - val_loss: 13.3090 - val_accuracy: 0.1099\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 128us/sample - loss: 12.5063 - accuracy: 0.4146 - val_loss: 12.4280 - val_accuracy: 0.1033\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 11.6623 - accuracy: 0.4226 - val_loss: 11.6484 - val_accuracy: 0.1069\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 123us/sample - loss: 10.9165 - accuracy: 0.4294 - val_loss: 10.9648 - val_accuracy: 0.1105\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 10.2789 - accuracy: 0.4380 - val_loss: 10.3596 - val_accuracy: 0.1111\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 9.7146 - accuracy: 0.4426 - val_loss: 9.8044 - val_accuracy: 0.1249\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 124us/sample - loss: 9.1966 - accuracy: 0.4487 - val_loss: 9.3233 - val_accuracy: 0.1315\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 8.7351 - accuracy: 0.4560 - val_loss: 8.8815 - val_accuracy: 0.1369\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 123us/sample - loss: 8.3150 - accuracy: 0.4664 - val_loss: 8.4849 - val_accuracy: 0.1526\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 7.9445 - accuracy: 0.4669 - val_loss: 8.1200 - val_accuracy: 0.1634\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 123us/sample - loss: 7.6018 - accuracy: 0.4722 - val_loss: 7.7961 - val_accuracy: 0.1694\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 7.2927 - accuracy: 0.4739 - val_loss: 7.4965 - val_accuracy: 0.1826\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 6.9987 - accuracy: 0.4858 - val_loss: 7.2098 - val_accuracy: 0.1886\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 6.7399 - accuracy: 0.4898 - val_loss: 6.9489 - val_accuracy: 0.1916\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 6.4956 - accuracy: 0.4944 - val_loss: 6.7141 - val_accuracy: 0.2000\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 6.2821 - accuracy: 0.4956 - val_loss: 6.4935 - val_accuracy: 0.2054\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 6.0622 - accuracy: 0.5003 - val_loss: 6.2916 - val_accuracy: 0.2120\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 123us/sample - loss: 5.8646 - accuracy: 0.5068 - val_loss: 6.1032 - val_accuracy: 0.2186\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 121us/sample - loss: 5.6885 - accuracy: 0.5104 - val_loss: 5.9213 - val_accuracy: 0.2312\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 5.5211 - accuracy: 0.5148 - val_loss: 5.7607 - val_accuracy: 0.2348\n",
      "\n",
      "Accuracy: 23.48%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 219us/sample - loss: 43.3886 - accuracy: 0.1507 - val_loss: 37.3322 - val_accuracy: 0.0402\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 34.6492 - accuracy: 0.1623 - val_loss: 32.1962 - val_accuracy: 0.0511\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 30.7196 - accuracy: 0.1679 - val_loss: 29.2438 - val_accuracy: 0.0498\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 28.2582 - accuracy: 0.1740 - val_loss: 27.2282 - val_accuracy: 0.0468\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 26.5444 - accuracy: 0.1721 - val_loss: 25.7269 - val_accuracy: 0.0456\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 25.1972 - accuracy: 0.1746 - val_loss: 24.5364 - val_accuracy: 0.0450\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 24.1133 - accuracy: 0.1757 - val_loss: 23.5648 - val_accuracy: 0.0438\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 23.2266 - accuracy: 0.1787 - val_loss: 22.7437 - val_accuracy: 0.0438\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 22.4560 - accuracy: 0.1781 - val_loss: 22.0450 - val_accuracy: 0.0408\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 21.7999 - accuracy: 0.1837 - val_loss: 21.4290 - val_accuracy: 0.0438\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 21.2188 - accuracy: 0.1825 - val_loss: 20.8821 - val_accuracy: 0.0432\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 20.7007 - accuracy: 0.1855 - val_loss: 20.4031 - val_accuracy: 0.0402\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 20.2309 - accuracy: 0.1838 - val_loss: 19.9563 - val_accuracy: 0.0420\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 19.8144 - accuracy: 0.1856 - val_loss: 19.5560 - val_accuracy: 0.0408\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 19.4353 - accuracy: 0.1889 - val_loss: 19.1967 - val_accuracy: 0.0384\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 19.0874 - accuracy: 0.1873 - val_loss: 18.8656 - val_accuracy: 0.0450\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 18.7572 - accuracy: 0.1883 - val_loss: 18.5447 - val_accuracy: 0.0438\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 18.4496 - accuracy: 0.1940 - val_loss: 18.2649 - val_accuracy: 0.0384\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 18.1643 - accuracy: 0.1922 - val_loss: 17.9947 - val_accuracy: 0.0420\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 3s 88us/sample - loss: 17.9195 - accuracy: 0.1899 - val_loss: 17.7404 - val_accuracy: 0.0426\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 17.6750 - accuracy: 0.1924 - val_loss: 17.5113 - val_accuracy: 0.0426\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 17.4363 - accuracy: 0.1943 - val_loss: 17.2828 - val_accuracy: 0.0462\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 17.2300 - accuracy: 0.1910 - val_loss: 17.0826 - val_accuracy: 0.0432\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 17.0194 - accuracy: 0.1940 - val_loss: 16.8751 - val_accuracy: 0.0462\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 16.8233 - accuracy: 0.1945 - val_loss: 16.6964 - val_accuracy: 0.0462\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 16.6485 - accuracy: 0.1935 - val_loss: 16.5165 - val_accuracy: 0.0480\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 16.4718 - accuracy: 0.1962 - val_loss: 16.3481 - val_accuracy: 0.0432\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 16.3014 - accuracy: 0.1976 - val_loss: 16.1844 - val_accuracy: 0.0474\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 16.1501 - accuracy: 0.1995 - val_loss: 16.0336 - val_accuracy: 0.0462\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 15.9990 - accuracy: 0.1983 - val_loss: 15.8917 - val_accuracy: 0.0456\n",
      "\n",
      "Accuracy: 4.56%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 243us/sample - loss: 20.5212 - accuracy: 0.3553 - val_loss: 2.6650 - val_accuracy: 0.2354\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.4277 - accuracy: 0.6615 - val_loss: 1.6401 - val_accuracy: 0.3922\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.2359 - accuracy: 0.6870 - val_loss: 1.6276 - val_accuracy: 0.4727\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.1972 - accuracy: 0.6871 - val_loss: 1.5660 - val_accuracy: 0.4589\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.1689 - accuracy: 0.6854 - val_loss: 1.6008 - val_accuracy: 0.4072\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.1764 - accuracy: 0.6747 - val_loss: 1.5740 - val_accuracy: 0.4456\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.1431 - accuracy: 0.6816 - val_loss: 1.5252 - val_accuracy: 0.5309\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.1584 - accuracy: 0.6851 - val_loss: 1.6427 - val_accuracy: 0.3748\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.1169 - accuracy: 0.6854 - val_loss: 1.5075 - val_accuracy: 0.5309\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.1337 - accuracy: 0.6789 - val_loss: 1.7226 - val_accuracy: 0.3694\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.1148 - accuracy: 0.6757 - val_loss: 1.5196 - val_accuracy: 0.5063\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0918 - accuracy: 0.6800 - val_loss: 1.6343 - val_accuracy: 0.4402\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.1073 - accuracy: 0.6800 - val_loss: 1.5221 - val_accuracy: 0.5321\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0887 - accuracy: 0.6792 - val_loss: 1.4626 - val_accuracy: 0.5574\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0835 - accuracy: 0.6795 - val_loss: 1.5559 - val_accuracy: 0.5604\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0845 - accuracy: 0.6761 - val_loss: 1.5874 - val_accuracy: 0.4378\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0752 - accuracy: 0.6776 - val_loss: 1.4666 - val_accuracy: 0.4420\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.1068 - accuracy: 0.6779 - val_loss: 1.5630 - val_accuracy: 0.3856\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0939 - accuracy: 0.6749 - val_loss: 1.4871 - val_accuracy: 0.4817\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 5s 143us/sample - loss: 1.0672 - accuracy: 0.6777 - val_loss: 1.4694 - val_accuracy: 0.5700\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 1.0662 - accuracy: 0.6766 - val_loss: 1.8299 - val_accuracy: 0.2733\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0702 - accuracy: 0.6787 - val_loss: 1.4648 - val_accuracy: 0.5820\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.0571 - accuracy: 0.6819 - val_loss: 1.5833 - val_accuracy: 0.3435\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0586 - accuracy: 0.6746 - val_loss: 1.6634 - val_accuracy: 0.4763\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0646 - accuracy: 0.6827 - val_loss: 1.3715 - val_accuracy: 0.5838\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0368 - accuracy: 0.6864 - val_loss: 1.3668 - val_accuracy: 0.6030\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0516 - accuracy: 0.6872 - val_loss: 1.4602 - val_accuracy: 0.4565\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0424 - accuracy: 0.6834 - val_loss: 1.3339 - val_accuracy: 0.5676\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0531 - accuracy: 0.6778 - val_loss: 1.4669 - val_accuracy: 0.4811\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0495 - accuracy: 0.6761 - val_loss: 1.4703 - val_accuracy: 0.4937\n",
      "\n",
      "Accuracy: 49.37%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 221us/sample - loss: 5.3554 - accuracy: 0.3074 - val_loss: 1.9469 - val_accuracy: 0.2498\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 78us/sample - loss: 1.8104 - accuracy: 0.3940 - val_loss: 2.0089 - val_accuracy: 0.0655\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.8009 - accuracy: 0.4031 - val_loss: 2.0174 - val_accuracy: 0.2252\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.7758 - accuracy: 0.4057 - val_loss: 2.1240 - val_accuracy: 0.1093\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.7568 - accuracy: 0.4026 - val_loss: 1.9342 - val_accuracy: 0.4432\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 76us/sample - loss: 1.7724 - accuracy: 0.4035 - val_loss: 1.8133 - val_accuracy: 0.0462\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.7833 - accuracy: 0.4033 - val_loss: 2.0011 - val_accuracy: 0.3489\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.7482 - accuracy: 0.4026 - val_loss: 1.8386 - val_accuracy: 0.2811\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 79us/sample - loss: 1.7152 - accuracy: 0.4032 - val_loss: 1.8407 - val_accuracy: 0.1736\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 78us/sample - loss: 1.7465 - accuracy: 0.4018 - val_loss: 2.0461 - val_accuracy: 0.3471\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.7007 - accuracy: 0.4039 - val_loss: 1.8075 - val_accuracy: 0.3730\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.7221 - accuracy: 0.3999 - val_loss: 1.9766 - val_accuracy: 0.0276\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 3s 77us/sample - loss: 1.7167 - accuracy: 0.4057 - val_loss: 1.8561 - val_accuracy: 0.3598\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 78us/sample - loss: 1.7087 - accuracy: 0.4043 - val_loss: 1.8825 - val_accuracy: 0.0889\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.6917 - accuracy: 0.4009 - val_loss: 1.8827 - val_accuracy: 0.2505\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 122us/sample - loss: 1.7209 - accuracy: 0.4003 - val_loss: 1.7943 - val_accuracy: 0.3321\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 79us/sample - loss: 1.6889 - accuracy: 0.3992 - val_loss: 1.8677 - val_accuracy: 0.2517\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.7342 - accuracy: 0.3951 - val_loss: 2.0748 - val_accuracy: 0.1880\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 78us/sample - loss: 1.7307 - accuracy: 0.4006 - val_loss: 1.8272 - val_accuracy: 0.2054\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.7206 - accuracy: 0.3978 - val_loss: 1.9911 - val_accuracy: 0.4210\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - ETA: 0s - loss: 1.7348 - accuracy: 0.39 - 3s 82us/sample - loss: 1.7346 - accuracy: 0.3952 - val_loss: 1.8794 - val_accuracy: 0.2973\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.7060 - accuracy: 0.4033 - val_loss: 1.9980 - val_accuracy: 0.1886\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 1.7259 - accuracy: 0.4005 - val_loss: 1.9034 - val_accuracy: 0.1796\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.7093 - accuracy: 0.3993 - val_loss: 1.8445 - val_accuracy: 0.4312\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.6964 - accuracy: 0.3996 - val_loss: 1.8548 - val_accuracy: 0.2865\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.7143 - accuracy: 0.4004 - val_loss: 1.7345 - val_accuracy: 0.2643\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.6939 - accuracy: 0.3954 - val_loss: 1.9292 - val_accuracy: 0.0384\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 82us/sample - loss: 1.6798 - accuracy: 0.3948 - val_loss: 1.8530 - val_accuracy: 0.3309\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 1.6706 - accuracy: 0.3998 - val_loss: 2.0978 - val_accuracy: 0.1231\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 79us/sample - loss: 1.6851 - accuracy: 0.3986 - val_loss: 1.8405 - val_accuracy: 0.3003\n",
      "\n",
      "Accuracy: 30.03%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 233us/sample - loss: 18.5059 - accuracy: 0.2548 - val_loss: 6.7222 - val_accuracy: 0.0090\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 4.3620 - accuracy: 0.4433 - val_loss: 3.3175 - val_accuracy: 0.1694\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 2.4152 - accuracy: 0.5525 - val_loss: 2.1811 - val_accuracy: 0.5369\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 1.6769 - accuracy: 0.6120 - val_loss: 1.8132 - val_accuracy: 0.3279\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 1.3167 - accuracy: 0.6423 - val_loss: 1.6632 - val_accuracy: 0.3183\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 1.1242 - accuracy: 0.6621 - val_loss: 1.5596 - val_accuracy: 0.3724\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.9913 - accuracy: 0.6769 - val_loss: 1.4320 - val_accuracy: 0.5694\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.9093 - accuracy: 0.6871 - val_loss: 1.4168 - val_accuracy: 0.3910\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8555 - accuracy: 0.6924 - val_loss: 1.3404 - val_accuracy: 0.4979\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.8153 - accuracy: 0.7023 - val_loss: 1.3645 - val_accuracy: 0.3634\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7719 - accuracy: 0.7128 - val_loss: 1.2895 - val_accuracy: 0.4757\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7508 - accuracy: 0.7175 - val_loss: 1.3091 - val_accuracy: 0.4198\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.7362 - accuracy: 0.7207 - val_loss: 1.2602 - val_accuracy: 0.4649\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7169 - accuracy: 0.7204 - val_loss: 1.2126 - val_accuracy: 0.5105\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.7039 - accuracy: 0.7252 - val_loss: 1.2320 - val_accuracy: 0.4877\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6884 - accuracy: 0.7347 - val_loss: 1.2039 - val_accuracy: 0.4955\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6768 - accuracy: 0.7343 - val_loss: 1.1892 - val_accuracy: 0.4901\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.6732 - accuracy: 0.7356 - val_loss: 1.1884 - val_accuracy: 0.5045\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6626 - accuracy: 0.7380 - val_loss: 1.1946 - val_accuracy: 0.4907\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6507 - accuracy: 0.7441 - val_loss: 1.1299 - val_accuracy: 0.5393\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6462 - accuracy: 0.7455 - val_loss: 1.1766 - val_accuracy: 0.5063\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6413 - accuracy: 0.7447 - val_loss: 1.1657 - val_accuracy: 0.5177\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6425 - accuracy: 0.7453 - val_loss: 1.1485 - val_accuracy: 0.5345\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6333 - accuracy: 0.7500 - val_loss: 1.1485 - val_accuracy: 0.5261\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6312 - accuracy: 0.7500 - val_loss: 1.1005 - val_accuracy: 0.5622\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6223 - accuracy: 0.7503 - val_loss: 1.1320 - val_accuracy: 0.5429\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6239 - accuracy: 0.7505 - val_loss: 1.1610 - val_accuracy: 0.5273\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6135 - accuracy: 0.7543 - val_loss: 1.1468 - val_accuracy: 0.5297\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6157 - accuracy: 0.7533 - val_loss: 1.1298 - val_accuracy: 0.5339\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6137 - accuracy: 0.7557 - val_loss: 1.1419 - val_accuracy: 0.5363\n",
      "\n",
      "Accuracy: 53.63%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 220us/sample - loss: 5.1687 - accuracy: 0.3744 - val_loss: 1.8921 - val_accuracy: 0.1063\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.3924 - accuracy: 0.4933 - val_loss: 1.7019 - val_accuracy: 0.2234\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 78us/sample - loss: 1.2597 - accuracy: 0.5324 - val_loss: 1.4103 - val_accuracy: 0.5453\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.1795 - accuracy: 0.5536 - val_loss: 1.4051 - val_accuracy: 0.5604\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.1272 - accuracy: 0.5693 - val_loss: 1.4159 - val_accuracy: 0.4967\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 3s 79us/sample - loss: 1.0980 - accuracy: 0.5788 - val_loss: 1.4666 - val_accuracy: 0.3213\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 1.0560 - accuracy: 0.5927 - val_loss: 1.3786 - val_accuracy: 0.5213\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 1.0330 - accuracy: 0.5992 - val_loss: 1.3020 - val_accuracy: 0.5736\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.0169 - accuracy: 0.6033 - val_loss: 1.4229 - val_accuracy: 0.1790\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 80us/sample - loss: 1.0045 - accuracy: 0.6065 - val_loss: 1.3766 - val_accuracy: 0.3574\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 0.9962 - accuracy: 0.6070 - val_loss: 1.3231 - val_accuracy: 0.5562\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 0.9717 - accuracy: 0.6162 - val_loss: 1.3890 - val_accuracy: 0.5387\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.9647 - accuracy: 0.6201 - val_loss: 1.3587 - val_accuracy: 0.4553\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 81us/sample - loss: 0.9679 - accuracy: 0.6177 - val_loss: 1.3496 - val_accuracy: 0.5634\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 79us/sample - loss: 0.9468 - accuracy: 0.6226 - val_loss: 1.3975 - val_accuracy: 0.2739\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9529 - accuracy: 0.6200 - val_loss: 1.3370 - val_accuracy: 0.5165\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.9408 - accuracy: 0.6201 - val_loss: 1.3974 - val_accuracy: 0.3291\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.9433 - accuracy: 0.6221 - val_loss: 1.3572 - val_accuracy: 0.5189\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.9280 - accuracy: 0.6277 - val_loss: 1.3469 - val_accuracy: 0.3622\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.9311 - accuracy: 0.6239 - val_loss: 1.2748 - val_accuracy: 0.5760\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.9168 - accuracy: 0.6290 - val_loss: 1.3763 - val_accuracy: 0.5189\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.9202 - accuracy: 0.6254 - val_loss: 1.3298 - val_accuracy: 0.5297\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.9146 - accuracy: 0.6279 - val_loss: 1.3170 - val_accuracy: 0.5628\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 86us/sample - loss: 0.9105 - accuracy: 0.6308 - val_loss: 1.3541 - val_accuracy: 0.4517\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.9147 - accuracy: 0.6273 - val_loss: 1.3106 - val_accuracy: 0.5393\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.9178 - accuracy: 0.6271 - val_loss: 1.3023 - val_accuracy: 0.5724\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.9039 - accuracy: 0.6309 - val_loss: 1.3379 - val_accuracy: 0.5255\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.9053 - accuracy: 0.6295 - val_loss: 1.3173 - val_accuracy: 0.5574\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.9067 - accuracy: 0.6311 - val_loss: 1.2999 - val_accuracy: 0.4595\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.9015 - accuracy: 0.6311 - val_loss: 1.3347 - val_accuracy: 0.3772\n",
      "\n",
      "Accuracy: 37.72%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 250us/sample - loss: 12.5955 - accuracy: 0.3573 - val_loss: 2.3909 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 1.4675 - accuracy: 0.5277 - val_loss: 1.7570 - val_accuracy: 0.1381\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 1.1977 - accuracy: 0.5929 - val_loss: 1.3787 - val_accuracy: 0.5165\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 1.0756 - accuracy: 0.6436 - val_loss: 1.3348 - val_accuracy: 0.5255\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.9887 - accuracy: 0.6673 - val_loss: 1.2820 - val_accuracy: 0.5267\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.9223 - accuracy: 0.6813 - val_loss: 1.2537 - val_accuracy: 0.5339\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.8912 - accuracy: 0.6852 - val_loss: 1.1926 - val_accuracy: 0.5610\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.8675 - accuracy: 0.6906 - val_loss: 1.2314 - val_accuracy: 0.5207\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.8364 - accuracy: 0.6952 - val_loss: 1.1587 - val_accuracy: 0.5423\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.8074 - accuracy: 0.7046 - val_loss: 1.1497 - val_accuracy: 0.5520\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.8003 - accuracy: 0.7071 - val_loss: 1.1453 - val_accuracy: 0.5616\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 0.7824 - accuracy: 0.7091 - val_loss: 1.1383 - val_accuracy: 0.5417\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.7770 - accuracy: 0.7107 - val_loss: 1.1465 - val_accuracy: 0.5339\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7625 - accuracy: 0.7170 - val_loss: 1.1343 - val_accuracy: 0.5688\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7475 - accuracy: 0.7197 - val_loss: 1.1159 - val_accuracy: 0.5610\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.7392 - accuracy: 0.7223 - val_loss: 1.1265 - val_accuracy: 0.5471\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7286 - accuracy: 0.7251 - val_loss: 1.0972 - val_accuracy: 0.5622\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7257 - accuracy: 0.7249 - val_loss: 1.1070 - val_accuracy: 0.5628\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7239 - accuracy: 0.7248 - val_loss: 1.0682 - val_accuracy: 0.5796\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7032 - accuracy: 0.7311 - val_loss: 1.1206 - val_accuracy: 0.5399\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6985 - accuracy: 0.7337 - val_loss: 1.1123 - val_accuracy: 0.5502\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6960 - accuracy: 0.7319 - val_loss: 1.0778 - val_accuracy: 0.5550loss: 0.6963 - accuracy: 0.73 - ETA: \n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6985 - accuracy: 0.7330 - val_loss: 1.0815 - val_accuracy: 0.5387\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.6869 - accuracy: 0.7359 - val_loss: 1.0539 - val_accuracy: 0.5580\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.6840 - accuracy: 0.7344 - val_loss: 1.0129 - val_accuracy: 0.5886\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6760 - accuracy: 0.7391 - val_loss: 1.0497 - val_accuracy: 0.5694\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6699 - accuracy: 0.7407 - val_loss: 1.0312 - val_accuracy: 0.5778\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6681 - accuracy: 0.7418 - val_loss: 1.0571 - val_accuracy: 0.5634\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.6639 - accuracy: 0.7461 - val_loss: 1.0530 - val_accuracy: 0.5580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.6630 - accuracy: 0.7431 - val_loss: 1.0227 - val_accuracy: 0.5826\n",
      "\n",
      "Accuracy: 58.26%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 241us/sample - loss: 13.2001 - accuracy: 0.2920 - val_loss: 2.5895 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.6265 - accuracy: 0.4833 - val_loss: 1.8076 - val_accuracy: 0.0835\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 1.2958 - accuracy: 0.5310 - val_loss: 1.4688 - val_accuracy: 0.3550\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 1.1658 - accuracy: 0.5639 - val_loss: 1.4340 - val_accuracy: 0.3093\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 127us/sample - loss: 1.0855 - accuracy: 0.6077 - val_loss: 1.3442 - val_accuracy: 0.4210\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 116us/sample - loss: 1.0207 - accuracy: 0.6346 - val_loss: 1.2990 - val_accuracy: 0.4859\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.9632 - accuracy: 0.6570 - val_loss: 1.3588 - val_accuracy: 0.4216\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 118us/sample - loss: 0.9229 - accuracy: 0.6641 - val_loss: 1.2858 - val_accuracy: 0.4805\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.9040 - accuracy: 0.6684 - val_loss: 1.2642 - val_accuracy: 0.4949\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.8856 - accuracy: 0.6742 - val_loss: 1.2241 - val_accuracy: 0.5123\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 0.8620 - accuracy: 0.6781 - val_loss: 1.2335 - val_accuracy: 0.4961\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.8512 - accuracy: 0.6773 - val_loss: 1.2014 - val_accuracy: 0.5249\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.8228 - accuracy: 0.6892 - val_loss: 1.1784 - val_accuracy: 0.5495\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.8139 - accuracy: 0.6861 - val_loss: 1.1667 - val_accuracy: 0.5369\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.8049 - accuracy: 0.6890 - val_loss: 1.1731 - val_accuracy: 0.5405\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.7927 - accuracy: 0.6935 - val_loss: 1.1733 - val_accuracy: 0.5369\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.7847 - accuracy: 0.6960 - val_loss: 1.1606 - val_accuracy: 0.5477\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 0.7706 - accuracy: 0.7032 - val_loss: 1.1573 - val_accuracy: 0.5447\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7682 - accuracy: 0.7005 - val_loss: 1.1483 - val_accuracy: 0.5465\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.7626 - accuracy: 0.7020 - val_loss: 1.1353 - val_accuracy: 0.5489\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.7587 - accuracy: 0.7039 - val_loss: 1.1636 - val_accuracy: 0.5207\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.7557 - accuracy: 0.7068 - val_loss: 1.1526 - val_accuracy: 0.5532\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.7400 - accuracy: 0.7071 - val_loss: 1.1247 - val_accuracy: 0.5616\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.7349 - accuracy: 0.7087 - val_loss: 1.1269 - val_accuracy: 0.5544\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.7311 - accuracy: 0.7096 - val_loss: 1.0973 - val_accuracy: 0.5586\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.7385 - accuracy: 0.7114 - val_loss: 1.1186 - val_accuracy: 0.5586\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7269 - accuracy: 0.7125 - val_loss: 1.1167 - val_accuracy: 0.5586\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 5s 152us/sample - loss: 0.7295 - accuracy: 0.7081 - val_loss: 1.1144 - val_accuracy: 0.5526\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 0.7318 - accuracy: 0.7100 - val_loss: 1.1181 - val_accuracy: 0.5646\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 0.7225 - accuracy: 0.7123 - val_loss: 1.1162 - val_accuracy: 0.5459\n",
      "\n",
      "Accuracy: 54.59%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 242us/sample - loss: 18.1002 - accuracy: 0.2152 - val_loss: 7.8776 - val_accuracy: 0.0138\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 4.9764 - accuracy: 0.3769 - val_loss: 3.4361 - val_accuracy: 0.5532\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 2.5098 - accuracy: 0.4905 - val_loss: 2.0558 - val_accuracy: 0.6132\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.6217 - accuracy: 0.5677 - val_loss: 1.6724 - val_accuracy: 0.2517\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 1.2650 - accuracy: 0.6007 - val_loss: 1.4299 - val_accuracy: 0.6288\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.0782 - accuracy: 0.6292 - val_loss: 1.3920 - val_accuracy: 0.6270\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.9784 - accuracy: 0.6423 - val_loss: 1.3743 - val_accuracy: 0.2517\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.9255 - accuracy: 0.6538 - val_loss: 1.3580 - val_accuracy: 0.4270\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.8988 - accuracy: 0.6526 - val_loss: 1.3208 - val_accuracy: 0.6324\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.8699 - accuracy: 0.6592 - val_loss: 1.3333 - val_accuracy: 0.2450\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.8567 - accuracy: 0.6587 - val_loss: 1.3076 - val_accuracy: 0.2697\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8456 - accuracy: 0.6599 - val_loss: 1.3307 - val_accuracy: 0.4318\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8328 - accuracy: 0.6609 - val_loss: 1.3112 - val_accuracy: 0.4763\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8102 - accuracy: 0.6667 - val_loss: 1.3022 - val_accuracy: 0.5417\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7996 - accuracy: 0.6692 - val_loss: 1.2864 - val_accuracy: 0.2751\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.8027 - accuracy: 0.6667 - val_loss: 1.3172 - val_accuracy: 0.2811\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.7879 - accuracy: 0.6705 - val_loss: 1.2925 - val_accuracy: 0.2474\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.7825 - accuracy: 0.6707 - val_loss: 1.2896 - val_accuracy: 0.3736\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.7674 - accuracy: 0.6734 - val_loss: 1.2915 - val_accuracy: 0.3381\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7634 - accuracy: 0.6773 - val_loss: 1.2916 - val_accuracy: 0.2631\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7592 - accuracy: 0.6761 - val_loss: 1.2943 - val_accuracy: 0.2408\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7524 - accuracy: 0.6747 - val_loss: 1.2978 - val_accuracy: 0.2697\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7448 - accuracy: 0.6777 - val_loss: 1.2880 - val_accuracy: 0.5189\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7561 - accuracy: 0.6717 - val_loss: 1.2846 - val_accuracy: 0.3880\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7466 - accuracy: 0.6779 - val_loss: 1.2871 - val_accuracy: 0.2492\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7359 - accuracy: 0.6727 - val_loss: 1.2928 - val_accuracy: 0.2529\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7368 - accuracy: 0.6782 - val_loss: 1.2842 - val_accuracy: 0.3526\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7331 - accuracy: 0.6748 - val_loss: 1.2804 - val_accuracy: 0.2492\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7332 - accuracy: 0.6799 - val_loss: 1.2898 - val_accuracy: 0.2390\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7276 - accuracy: 0.6752 - val_loss: 1.2806 - val_accuracy: 0.2396\n",
      "\n",
      "Accuracy: 23.96%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 238us/sample - loss: 9.7573 - accuracy: 0.3489 - val_loss: 2.2100 - val_accuracy: 0.1189\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 1.4208 - accuracy: 0.5723 - val_loss: 1.6528 - val_accuracy: 0.2180\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 1.1625 - accuracy: 0.6283 - val_loss: 1.4388 - val_accuracy: 0.3904\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 1.0720 - accuracy: 0.6494 - val_loss: 1.3988 - val_accuracy: 0.5213\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.9913 - accuracy: 0.6648 - val_loss: 1.3241 - val_accuracy: 0.4703\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.9377 - accuracy: 0.6714 - val_loss: 1.3008 - val_accuracy: 0.4697\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.8931 - accuracy: 0.6793 - val_loss: 1.3046 - val_accuracy: 0.4438\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.8738 - accuracy: 0.6826 - val_loss: 1.2370 - val_accuracy: 0.5405\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8413 - accuracy: 0.6884 - val_loss: 1.2064 - val_accuracy: 0.5315\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.8268 - accuracy: 0.6918 - val_loss: 1.2182 - val_accuracy: 0.5309\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.8117 - accuracy: 0.6945 - val_loss: 1.2421 - val_accuracy: 0.4673\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7927 - accuracy: 0.6967 - val_loss: 1.1721 - val_accuracy: 0.5153\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7771 - accuracy: 0.7001 - val_loss: 1.2003 - val_accuracy: 0.5261\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7705 - accuracy: 0.7024 - val_loss: 1.1974 - val_accuracy: 0.4997\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.7579 - accuracy: 0.7037 - val_loss: 1.1720 - val_accuracy: 0.5201\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7515 - accuracy: 0.7059 - val_loss: 1.1649 - val_accuracy: 0.5255\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7445 - accuracy: 0.7099 - val_loss: 1.1401 - val_accuracy: 0.5471\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.7337 - accuracy: 0.7080 - val_loss: 1.1542 - val_accuracy: 0.5441\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7249 - accuracy: 0.7092 - val_loss: 1.1595 - val_accuracy: 0.5255\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.7204 - accuracy: 0.7093 - val_loss: 1.1431 - val_accuracy: 0.5309\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7174 - accuracy: 0.7134 - val_loss: 1.1281 - val_accuracy: 0.5495\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.7097 - accuracy: 0.7162 - val_loss: 1.1290 - val_accuracy: 0.5544\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.7025 - accuracy: 0.7175 - val_loss: 1.1026 - val_accuracy: 0.5526\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7023 - accuracy: 0.7166 - val_loss: 1.1421 - val_accuracy: 0.5237\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6923 - accuracy: 0.7200 - val_loss: 1.0991 - val_accuracy: 0.5616\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6851 - accuracy: 0.7220 - val_loss: 1.1132 - val_accuracy: 0.5544\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6811 - accuracy: 0.7268 - val_loss: 1.0918 - val_accuracy: 0.5676\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6886 - accuracy: 0.7204 - val_loss: 1.0748 - val_accuracy: 0.5640\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6813 - accuracy: 0.7221 - val_loss: 1.1195 - val_accuracy: 0.5375\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6779 - accuracy: 0.7248 - val_loss: 1.0972 - val_accuracy: 0.5465\n",
      "\n",
      "Accuracy: 54.65%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 238us/sample - loss: 13.7710 - accuracy: 0.2881 - val_loss: 3.5716 - val_accuracy: 0.0048\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 2.0495 - accuracy: 0.4968 - val_loss: 1.7455 - val_accuracy: 0.2240\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 1.1755 - accuracy: 0.6182 - val_loss: 1.4414 - val_accuracy: 0.2523\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.9823 - accuracy: 0.6563 - val_loss: 1.3761 - val_accuracy: 0.6168\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.8911 - accuracy: 0.6739 - val_loss: 1.4027 - val_accuracy: 0.4444\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.8431 - accuracy: 0.6885 - val_loss: 1.3644 - val_accuracy: 0.4787\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.8081 - accuracy: 0.7018 - val_loss: 1.2017 - val_accuracy: 0.6168\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.7853 - accuracy: 0.7071 - val_loss: 1.3153 - val_accuracy: 0.4294\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.7633 - accuracy: 0.7132 - val_loss: 1.2344 - val_accuracy: 0.5171\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.7516 - accuracy: 0.7122 - val_loss: 1.2617 - val_accuracy: 0.4817\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.7307 - accuracy: 0.7206 - val_loss: 1.2614 - val_accuracy: 0.4655\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.7223 - accuracy: 0.7236 - val_loss: 1.2337 - val_accuracy: 0.4961\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.7191 - accuracy: 0.7220 - val_loss: 1.1988 - val_accuracy: 0.5099\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7108 - accuracy: 0.7283 - val_loss: 1.2505 - val_accuracy: 0.4823\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7034 - accuracy: 0.7287 - val_loss: 1.1613 - val_accuracy: 0.5345\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.7099 - accuracy: 0.7307 - val_loss: 1.1691 - val_accuracy: 0.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 82us/sample - loss: 0.6983 - accuracy: 0.7321 - val_loss: 1.1833 - val_accuracy: 0.5177\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6931 - accuracy: 0.7298 - val_loss: 1.1924 - val_accuracy: 0.4913\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6901 - accuracy: 0.7337 - val_loss: 1.2134 - val_accuracy: 0.4841\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.6765 - accuracy: 0.7342 - val_loss: 1.2039 - val_accuracy: 0.4871\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 82us/sample - loss: 0.6752 - accuracy: 0.7397 - val_loss: 1.1751 - val_accuracy: 0.5165\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 82us/sample - loss: 0.6653 - accuracy: 0.7383 - val_loss: 1.1623 - val_accuracy: 0.5081\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6649 - accuracy: 0.7395 - val_loss: 1.1544 - val_accuracy: 0.5207\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6570 - accuracy: 0.7421 - val_loss: 1.1604 - val_accuracy: 0.5213\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6585 - accuracy: 0.7433 - val_loss: 1.1333 - val_accuracy: 0.5291\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6512 - accuracy: 0.7442 - val_loss: 1.1547 - val_accuracy: 0.5135\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6478 - accuracy: 0.7424 - val_loss: 1.1341 - val_accuracy: 0.5291\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6507 - accuracy: 0.7428 - val_loss: 1.1629 - val_accuracy: 0.5051\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.6431 - accuracy: 0.7455 - val_loss: 1.1543 - val_accuracy: 0.5045\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 83us/sample - loss: 0.6477 - accuracy: 0.7440 - val_loss: 1.1536 - val_accuracy: 0.5123\n",
      "\n",
      "Accuracy: 51.23%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 256us/sample - loss: 34.2645 - accuracy: 0.1974 - val_loss: 10.5073 - val_accuracy: 0.0162\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 5.9680 - accuracy: 0.4201 - val_loss: 3.5681 - val_accuracy: 0.6444\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 2.4338 - accuracy: 0.5663 - val_loss: 2.0735 - val_accuracy: 0.5982\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.5066 - accuracy: 0.6179 - val_loss: 1.7673 - val_accuracy: 0.4114\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.2394 - accuracy: 0.6391 - val_loss: 1.5929 - val_accuracy: 0.1898\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.1473 - accuracy: 0.6480 - val_loss: 1.5706 - val_accuracy: 0.1880\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 1.1247 - accuracy: 0.6480 - val_loss: 1.7035 - val_accuracy: 0.3285\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.1221 - accuracy: 0.6498 - val_loss: 1.5221 - val_accuracy: 0.4901\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0669 - accuracy: 0.6637 - val_loss: 1.4835 - val_accuracy: 0.5243\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.0615 - accuracy: 0.6655 - val_loss: 1.5163 - val_accuracy: 0.4817\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0725 - accuracy: 0.6636 - val_loss: 1.6052 - val_accuracy: 0.2997\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0815 - accuracy: 0.6616 - val_loss: 1.5296 - val_accuracy: 0.4156\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0548 - accuracy: 0.6678 - val_loss: 1.4444 - val_accuracy: 0.4973\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 114us/sample - loss: 1.0402 - accuracy: 0.6661 - val_loss: 1.4398 - val_accuracy: 0.4745\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 1.0532 - accuracy: 0.6656 - val_loss: 1.4603 - val_accuracy: 0.4517\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0552 - accuracy: 0.6612 - val_loss: 1.5293 - val_accuracy: 0.3207\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.0245 - accuracy: 0.6659 - val_loss: 1.5241 - val_accuracy: 0.2919\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 1.0273 - accuracy: 0.6662 - val_loss: 1.5295 - val_accuracy: 0.2961\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0438 - accuracy: 0.6592 - val_loss: 1.5112 - val_accuracy: 0.2559\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0363 - accuracy: 0.6696 - val_loss: 1.4662 - val_accuracy: 0.3832\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.0214 - accuracy: 0.6675 - val_loss: 1.4556 - val_accuracy: 0.4997\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.0300 - accuracy: 0.6657 - val_loss: 1.4841 - val_accuracy: 0.3874\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.0157 - accuracy: 0.6711 - val_loss: 1.3634 - val_accuracy: 0.4979\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0167 - accuracy: 0.6724 - val_loss: 1.4509 - val_accuracy: 0.3790\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 1.0213 - accuracy: 0.6718 - val_loss: 1.4539 - val_accuracy: 0.3309\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.0263 - accuracy: 0.6675 - val_loss: 1.4356 - val_accuracy: 0.4450\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.0265 - accuracy: 0.6671 - val_loss: 1.5120 - val_accuracy: 0.3093\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.0295 - accuracy: 0.6687 - val_loss: 1.5806 - val_accuracy: 0.3207\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.0272 - accuracy: 0.6658 - val_loss: 1.4438 - val_accuracy: 0.3592\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 1.0217 - accuracy: 0.6645 - val_loss: 1.5052 - val_accuracy: 0.4324\n",
      "\n",
      "Accuracy: 43.24%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 246us/sample - loss: 15.1617 - accuracy: 0.3877 - val_loss: 3.6679 - val_accuracy: 0.2402\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 2.2405 - accuracy: 0.5681 - val_loss: 2.0245 - val_accuracy: 0.0649\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 1.3878 - accuracy: 0.6096 - val_loss: 1.5717 - val_accuracy: 0.1159\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 1.1136 - accuracy: 0.6341 - val_loss: 1.5125 - val_accuracy: 0.2685\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 1.0008 - accuracy: 0.6549 - val_loss: 1.4654 - val_accuracy: 0.2661\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.9170 - accuracy: 0.6707 - val_loss: 1.3300 - val_accuracy: 0.5556\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.8716 - accuracy: 0.6818 - val_loss: 1.3579 - val_accuracy: 0.3958\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8442 - accuracy: 0.6869 - val_loss: 1.3445 - val_accuracy: 0.3844\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.8112 - accuracy: 0.6949 - val_loss: 1.3103 - val_accuracy: 0.4342\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7974 - accuracy: 0.6993 - val_loss: 1.3458 - val_accuracy: 0.4024\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7754 - accuracy: 0.7059 - val_loss: 1.2582 - val_accuracy: 0.4817\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7555 - accuracy: 0.7106 - val_loss: 1.2347 - val_accuracy: 0.5027\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7470 - accuracy: 0.7124 - val_loss: 1.3112 - val_accuracy: 0.4102\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7504 - accuracy: 0.7107 - val_loss: 1.2762 - val_accuracy: 0.4613\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7389 - accuracy: 0.7137 - val_loss: 1.2608 - val_accuracy: 0.4462\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.7252 - accuracy: 0.7181 - val_loss: 1.2331 - val_accuracy: 0.4589\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7134 - accuracy: 0.7233 - val_loss: 1.2094 - val_accuracy: 0.5105\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.7053 - accuracy: 0.7234 - val_loss: 1.1981 - val_accuracy: 0.5087\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.7011 - accuracy: 0.7256 - val_loss: 1.1968 - val_accuracy: 0.5063\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.6895 - accuracy: 0.7312 - val_loss: 1.2312 - val_accuracy: 0.4667\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6811 - accuracy: 0.7332 - val_loss: 1.1629 - val_accuracy: 0.5255\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6788 - accuracy: 0.7330 - val_loss: 1.1344 - val_accuracy: 0.5363\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6753 - accuracy: 0.7355 - val_loss: 1.2034 - val_accuracy: 0.5063ss: 0.6\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6745 - accuracy: 0.7375 - val_loss: 1.1860 - val_accuracy: 0.5027\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6671 - accuracy: 0.7404 - val_loss: 1.2300 - val_accuracy: 0.4571\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6581 - accuracy: 0.7378 - val_loss: 1.1525 - val_accuracy: 0.5399\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.6519 - accuracy: 0.7396 - val_loss: 1.1798 - val_accuracy: 0.5147\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6576 - accuracy: 0.7402 - val_loss: 1.1477 - val_accuracy: 0.5327\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.6475 - accuracy: 0.7448 - val_loss: 1.1892 - val_accuracy: 0.5135\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.6501 - accuracy: 0.7435 - val_loss: 1.2221 - val_accuracy: 0.4931\n",
      "\n",
      "Accuracy: 49.31%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 232us/sample - loss: 6.7641 - accuracy: 0.4444 - val_loss: 1.9324 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 1.5671 - accuracy: 0.5815 - val_loss: 1.8795 - val_accuracy: 0.1670\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5565 - accuracy: 0.5886 - val_loss: 1.7422 - val_accuracy: 0.3862\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5625 - accuracy: 0.5778 - val_loss: 2.0913 - val_accuracy: 0.0685\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5767 - accuracy: 0.5497 - val_loss: 1.7301 - val_accuracy: 0.5604\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5616 - accuracy: 0.5349 - val_loss: 1.6311 - val_accuracy: 0.6060\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5628 - accuracy: 0.5188 - val_loss: 1.6350 - val_accuracy: 0.5868\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5361 - accuracy: 0.5077 - val_loss: 1.8114 - val_accuracy: 0.5111\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5250 - accuracy: 0.5036 - val_loss: 1.6560 - val_accuracy: 0.5532\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5256 - accuracy: 0.5025 - val_loss: 1.8581 - val_accuracy: 0.4979\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5302 - accuracy: 0.5022 - val_loss: 1.7291 - val_accuracy: 0.5081\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5300 - accuracy: 0.5105 - val_loss: 1.7343 - val_accuracy: 0.5526\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5770 - accuracy: 0.4993 - val_loss: 1.8465 - val_accuracy: 0.2517\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5230 - accuracy: 0.4971 - val_loss: 1.9076 - val_accuracy: 0.4456\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5112 - accuracy: 0.4976 - val_loss: 1.6172 - val_accuracy: 0.5808\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5149 - accuracy: 0.4999 - val_loss: 1.7948 - val_accuracy: 0.2396\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.4987 - accuracy: 0.5029 - val_loss: 1.8229 - val_accuracy: 0.5273\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5253 - accuracy: 0.5033 - val_loss: 1.8172 - val_accuracy: 0.2018\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5242 - accuracy: 0.4941 - val_loss: 1.6564 - val_accuracy: 0.5934\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.5203 - accuracy: 0.4965 - val_loss: 1.7442 - val_accuracy: 0.5429\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.4854 - accuracy: 0.5028 - val_loss: 1.6176 - val_accuracy: 0.5688\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.5136 - accuracy: 0.4984 - val_loss: 1.7720 - val_accuracy: 0.4342\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.4758 - accuracy: 0.5001 - val_loss: 1.8414 - val_accuracy: 0.4919\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.4881 - accuracy: 0.4979 - val_loss: 1.7726 - val_accuracy: 0.4366\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.4845 - accuracy: 0.5002 - val_loss: 1.7995 - val_accuracy: 0.5117\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5169 - accuracy: 0.4965 - val_loss: 1.6682 - val_accuracy: 0.5826\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.4795 - accuracy: 0.4993 - val_loss: 1.8833 - val_accuracy: 0.2108\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.4889 - accuracy: 0.5029 - val_loss: 1.7332 - val_accuracy: 0.5279\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.4777 - accuracy: 0.5005 - val_loss: 1.8825 - val_accuracy: 0.2973\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.5211 - accuracy: 0.4979 - val_loss: 1.7704 - val_accuracy: 0.2991\n",
      "\n",
      "Accuracy: 29.91%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 251us/sample - loss: 12.7837 - accuracy: 0.3636 - val_loss: 2.4625 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 1.4422 - accuracy: 0.5287 - val_loss: 1.6871 - val_accuracy: 0.1832\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 1.1913 - accuracy: 0.5942 - val_loss: 1.4106 - val_accuracy: 0.4408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 1.0574 - accuracy: 0.6370 - val_loss: 1.2852 - val_accuracy: 0.5099\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.9713 - accuracy: 0.6650 - val_loss: 1.2700 - val_accuracy: 0.5123\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.9150 - accuracy: 0.6776 - val_loss: 1.3430 - val_accuracy: 0.4450\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.8738 - accuracy: 0.6894 - val_loss: 1.3236 - val_accuracy: 0.4505\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.8430 - accuracy: 0.6998 - val_loss: 1.2137 - val_accuracy: 0.5141\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.8218 - accuracy: 0.7015 - val_loss: 1.2013 - val_accuracy: 0.5219\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.7892 - accuracy: 0.7115 - val_loss: 1.2007 - val_accuracy: 0.5063\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.7767 - accuracy: 0.7121 - val_loss: 1.1805 - val_accuracy: 0.5387\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.7742 - accuracy: 0.7133 - val_loss: 1.1466 - val_accuracy: 0.5267\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.7585 - accuracy: 0.7175 - val_loss: 1.1335 - val_accuracy: 0.5465\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.7483 - accuracy: 0.7225 - val_loss: 1.1676 - val_accuracy: 0.5111\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.7341 - accuracy: 0.7206 - val_loss: 1.1169 - val_accuracy: 0.5453\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.7236 - accuracy: 0.7261 - val_loss: 1.1041 - val_accuracy: 0.5670\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.7130 - accuracy: 0.7267 - val_loss: 1.0946 - val_accuracy: 0.5550\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.7102 - accuracy: 0.7272 - val_loss: 1.1051 - val_accuracy: 0.5483\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.6978 - accuracy: 0.7302 - val_loss: 1.1031 - val_accuracy: 0.5514\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.6923 - accuracy: 0.7311 - val_loss: 1.1068 - val_accuracy: 0.5508\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.6887 - accuracy: 0.7347 - val_loss: 1.0770 - val_accuracy: 0.5682\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.6823 - accuracy: 0.7354 - val_loss: 1.1009 - val_accuracy: 0.5598\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.6778 - accuracy: 0.7362 - val_loss: 1.0800 - val_accuracy: 0.5652\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.6700 - accuracy: 0.7392 - val_loss: 1.0573 - val_accuracy: 0.5784\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.6657 - accuracy: 0.7402 - val_loss: 1.0617 - val_accuracy: 0.5718\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.6623 - accuracy: 0.7417 - val_loss: 1.0575 - val_accuracy: 0.5718\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.6656 - accuracy: 0.7403 - val_loss: 1.0448 - val_accuracy: 0.5736\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.6487 - accuracy: 0.7459 - val_loss: 1.0417 - val_accuracy: 0.5826\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.6530 - accuracy: 0.7447 - val_loss: 1.0148 - val_accuracy: 0.5946\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.6471 - accuracy: 0.7438 - val_loss: 1.0219 - val_accuracy: 0.5880\n",
      "\n",
      "Accuracy: 58.80%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 247us/sample - loss: 12.7536 - accuracy: 0.3580 - val_loss: 2.4842 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 1.4819 - accuracy: 0.5286 - val_loss: 1.7357 - val_accuracy: 0.2589\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 1.1780 - accuracy: 0.6167 - val_loss: 1.5019 - val_accuracy: 0.3538\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 1.0378 - accuracy: 0.6564 - val_loss: 1.3837 - val_accuracy: 0.4276\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.9524 - accuracy: 0.6747 - val_loss: 1.2927 - val_accuracy: 0.4817\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.8867 - accuracy: 0.6915 - val_loss: 1.2586 - val_accuracy: 0.5111\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.8602 - accuracy: 0.6971 - val_loss: 1.2521 - val_accuracy: 0.5087\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.8324 - accuracy: 0.7011 - val_loss: 1.1947 - val_accuracy: 0.5189\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.8147 - accuracy: 0.7006 - val_loss: 1.1871 - val_accuracy: 0.5453\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.7830 - accuracy: 0.7093 - val_loss: 1.1881 - val_accuracy: 0.5093\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.7792 - accuracy: 0.7097 - val_loss: 1.1829 - val_accuracy: 0.5255\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.7582 - accuracy: 0.7143 - val_loss: 1.1111 - val_accuracy: 0.5784\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 0.7455 - accuracy: 0.7194 - val_loss: 1.1070 - val_accuracy: 0.5688\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.7379 - accuracy: 0.7208 - val_loss: 1.1489 - val_accuracy: 0.5189\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.7277 - accuracy: 0.7237 - val_loss: 1.1678 - val_accuracy: 0.5237\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.7168 - accuracy: 0.7253 - val_loss: 1.0818 - val_accuracy: 0.5568\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.7034 - accuracy: 0.7294 - val_loss: 1.0810 - val_accuracy: 0.5634\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.6978 - accuracy: 0.7303 - val_loss: 1.1039 - val_accuracy: 0.5538\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.6955 - accuracy: 0.7328 - val_loss: 1.1461 - val_accuracy: 0.5063\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 119us/sample - loss: 0.6849 - accuracy: 0.7344 - val_loss: 1.0964 - val_accuracy: 0.5459\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.6785 - accuracy: 0.7332 - val_loss: 1.1176 - val_accuracy: 0.5339\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.6751 - accuracy: 0.7370 - val_loss: 1.0822 - val_accuracy: 0.5502\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 4s 117us/sample - loss: 0.6754 - accuracy: 0.7387 - val_loss: 1.1036 - val_accuracy: 0.5441\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 4s 109us/sample - loss: 0.6637 - accuracy: 0.7371 - val_loss: 1.0722 - val_accuracy: 0.5622\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 4s 112us/sample - loss: 0.6657 - accuracy: 0.7406 - val_loss: 1.1002 - val_accuracy: 0.5363\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.6570 - accuracy: 0.7410 - val_loss: 1.0409 - val_accuracy: 0.5658\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 0.6582 - accuracy: 0.7429 - val_loss: 1.0413 - val_accuracy: 0.5694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 106us/sample - loss: 0.6547 - accuracy: 0.7465 - val_loss: 1.0833 - val_accuracy: 0.5538\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.6516 - accuracy: 0.7427 - val_loss: 1.0495 - val_accuracy: 0.5616\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.6478 - accuracy: 0.7450 - val_loss: 1.0456 - val_accuracy: 0.5652\n",
      "\n",
      "Accuracy: 56.52%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 255us/sample - loss: 21.3865 - accuracy: 0.2651 - val_loss: 8.4007 - val_accuracy: 0.0024\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 5.4197 - accuracy: 0.4621 - val_loss: 3.9110 - val_accuracy: 0.2949\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 2.8776 - accuracy: 0.5559 - val_loss: 2.5987 - val_accuracy: 0.2216\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.9385 - accuracy: 0.6048 - val_loss: 2.1185 - val_accuracy: 0.2751\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 86us/sample - loss: 1.4928 - accuracy: 0.6285 - val_loss: 1.7905 - val_accuracy: 0.4492\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.2489 - accuracy: 0.6541 - val_loss: 1.6647 - val_accuracy: 0.3309\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 1.1096 - accuracy: 0.6618 - val_loss: 1.5627 - val_accuracy: 0.3363\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.0104 - accuracy: 0.6708 - val_loss: 1.4925 - val_accuracy: 0.3351\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.9427 - accuracy: 0.6830 - val_loss: 1.4565 - val_accuracy: 0.3532\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.9036 - accuracy: 0.6892 - val_loss: 1.4068 - val_accuracy: 0.3814\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8815 - accuracy: 0.6911 - val_loss: 1.4174 - val_accuracy: 0.3706\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8473 - accuracy: 0.6979 - val_loss: 1.3534 - val_accuracy: 0.4072\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.8317 - accuracy: 0.7014 - val_loss: 1.3806 - val_accuracy: 0.3994\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.8177 - accuracy: 0.7009 - val_loss: 1.3456 - val_accuracy: 0.4030\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.8089 - accuracy: 0.7032 - val_loss: 1.3421 - val_accuracy: 0.4018\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.8023 - accuracy: 0.7023 - val_loss: 1.3390 - val_accuracy: 0.4042\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7869 - accuracy: 0.7054 - val_loss: 1.3130 - val_accuracy: 0.4216\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7842 - accuracy: 0.7063 - val_loss: 1.3217 - val_accuracy: 0.4138\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.7800 - accuracy: 0.7071 - val_loss: 1.2801 - val_accuracy: 0.4312\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 4s 110us/sample - loss: 0.7739 - accuracy: 0.7092 - val_loss: 1.3099 - val_accuracy: 0.4000\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 113us/sample - loss: 0.7691 - accuracy: 0.7119 - val_loss: 1.3001 - val_accuracy: 0.4138\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.7597 - accuracy: 0.7108 - val_loss: 1.3054 - val_accuracy: 0.4102\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.7578 - accuracy: 0.7126 - val_loss: 1.2871 - val_accuracy: 0.4162\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7601 - accuracy: 0.7132 - val_loss: 1.2829 - val_accuracy: 0.4108\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7458 - accuracy: 0.7151 - val_loss: 1.2865 - val_accuracy: 0.4192\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.7456 - accuracy: 0.7122 - val_loss: 1.2800 - val_accuracy: 0.4180\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7460 - accuracy: 0.7158 - val_loss: 1.2812 - val_accuracy: 0.4180\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7457 - accuracy: 0.7180 - val_loss: 1.2825 - val_accuracy: 0.4192\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7475 - accuracy: 0.7122 - val_loss: 1.2822 - val_accuracy: 0.4066\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.7343 - accuracy: 0.7202 - val_loss: 1.2731 - val_accuracy: 0.4210\n",
      "\n",
      "Accuracy: 42.10%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 238us/sample - loss: 31.9424 - accuracy: 0.1758 - val_loss: 15.0198 - val_accuracy: 0.0282\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 9.2118 - accuracy: 0.2511 - val_loss: 5.7590 - val_accuracy: 0.1814\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 3.7663 - accuracy: 0.4359 - val_loss: 2.7371 - val_accuracy: 0.2252\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 1.8634 - accuracy: 0.5943 - val_loss: 1.7608 - val_accuracy: 0.2042\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 1.2475 - accuracy: 0.6444 - val_loss: 1.5302 - val_accuracy: 0.2360\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 1.0496 - accuracy: 0.6593 - val_loss: 1.4785 - val_accuracy: 0.2336\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.9994 - accuracy: 0.6673 - val_loss: 1.4907 - val_accuracy: 0.3165\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 105us/sample - loss: 0.9519 - accuracy: 0.6725 - val_loss: 1.4479 - val_accuracy: 0.5453\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 107us/sample - loss: 0.9506 - accuracy: 0.6699 - val_loss: 1.3901 - val_accuracy: 0.6300\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.9286 - accuracy: 0.6722 - val_loss: 1.4323 - val_accuracy: 0.6306\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.9248 - accuracy: 0.6814 - val_loss: 1.3980 - val_accuracy: 0.6216\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 0.9177 - accuracy: 0.6807 - val_loss: 1.3999 - val_accuracy: 0.4523\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.9185 - accuracy: 0.6816 - val_loss: 1.4371 - val_accuracy: 0.4072\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.9134 - accuracy: 0.6862 - val_loss: 1.4086 - val_accuracy: 0.4889\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.8941 - accuracy: 0.6898 - val_loss: 1.3400 - val_accuracy: 0.5820\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8872 - accuracy: 0.6930 - val_loss: 1.3431 - val_accuracy: 0.6114\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.8689 - accuracy: 0.6940 - val_loss: 1.3771 - val_accuracy: 0.5964\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8767 - accuracy: 0.6941 - val_loss: 1.5940 - val_accuracy: 0.3952\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8687 - accuracy: 0.6943 - val_loss: 1.3283 - val_accuracy: 0.5862\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8799 - accuracy: 0.6923 - val_loss: 1.4886 - val_accuracy: 0.5664\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.8681 - accuracy: 0.6973 - val_loss: 1.3258 - val_accuracy: 0.5976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8725 - accuracy: 0.6935 - val_loss: 1.2813 - val_accuracy: 0.6216\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.8782 - accuracy: 0.6977 - val_loss: 1.3343 - val_accuracy: 0.5982\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8811 - accuracy: 0.6975 - val_loss: 1.3387 - val_accuracy: 0.6030\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8698 - accuracy: 0.6963 - val_loss: 1.3750 - val_accuracy: 0.5075\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8545 - accuracy: 0.6988 - val_loss: 1.3542 - val_accuracy: 0.4667\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8624 - accuracy: 0.6948 - val_loss: 1.3374 - val_accuracy: 0.5616\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.8547 - accuracy: 0.7004 - val_loss: 1.3240 - val_accuracy: 0.5928\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8655 - accuracy: 0.6957 - val_loss: 1.3611 - val_accuracy: 0.5171\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8628 - accuracy: 0.6986 - val_loss: 1.3646 - val_accuracy: 0.4985\n",
      "\n",
      "Accuracy: 49.85%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 243us/sample - loss: 9.2708 - accuracy: 0.3954 - val_loss: 2.2052 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 1.4068 - accuracy: 0.5285 - val_loss: 1.6625 - val_accuracy: 0.2006\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 4s 108us/sample - loss: 1.2063 - accuracy: 0.5766 - val_loss: 1.3529 - val_accuracy: 0.5081\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 1.1027 - accuracy: 0.6111 - val_loss: 1.3378 - val_accuracy: 0.4643\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 1.0176 - accuracy: 0.6447 - val_loss: 1.3254 - val_accuracy: 0.4607\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.9426 - accuracy: 0.6672 - val_loss: 1.2328 - val_accuracy: 0.5009\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.9096 - accuracy: 0.6753 - val_loss: 1.2538 - val_accuracy: 0.5219\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.8722 - accuracy: 0.6836 - val_loss: 1.2544 - val_accuracy: 0.4895\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8426 - accuracy: 0.6924 - val_loss: 1.2605 - val_accuracy: 0.4937\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.8178 - accuracy: 0.6949 - val_loss: 1.1933 - val_accuracy: 0.5405\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.8049 - accuracy: 0.6993 - val_loss: 1.2212 - val_accuracy: 0.5051\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7829 - accuracy: 0.7030 - val_loss: 1.1909 - val_accuracy: 0.5285\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7657 - accuracy: 0.7102 - val_loss: 1.2101 - val_accuracy: 0.5069\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7521 - accuracy: 0.7155 - val_loss: 1.1520 - val_accuracy: 0.5273\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.7456 - accuracy: 0.7134 - val_loss: 1.1654 - val_accuracy: 0.5369\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7392 - accuracy: 0.7166 - val_loss: 1.1630 - val_accuracy: 0.5291\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7296 - accuracy: 0.7168 - val_loss: 1.1573 - val_accuracy: 0.5387\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.7227 - accuracy: 0.7180 - val_loss: 1.1398 - val_accuracy: 0.5303\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.7143 - accuracy: 0.7210 - val_loss: 1.0926 - val_accuracy: 0.5670\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7093 - accuracy: 0.7235 - val_loss: 1.1079 - val_accuracy: 0.5453\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7030 - accuracy: 0.7257 - val_loss: 1.0960 - val_accuracy: 0.5489\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6886 - accuracy: 0.7300 - val_loss: 1.0950 - val_accuracy: 0.5520\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6930 - accuracy: 0.7299 - val_loss: 1.0845 - val_accuracy: 0.5520\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.6930 - accuracy: 0.7274 - val_loss: 1.0972 - val_accuracy: 0.5532\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.6781 - accuracy: 0.7317 - val_loss: 1.1162 - val_accuracy: 0.5435\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6774 - accuracy: 0.7309 - val_loss: 1.1023 - val_accuracy: 0.5483\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.6746 - accuracy: 0.7325 - val_loss: 1.1007 - val_accuracy: 0.5664\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6703 - accuracy: 0.7351 - val_loss: 1.0806 - val_accuracy: 0.5790\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6626 - accuracy: 0.7359 - val_loss: 1.0429 - val_accuracy: 0.5814\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.6601 - accuracy: 0.7373 - val_loss: 1.1006 - val_accuracy: 0.5489\n",
      "\n",
      "Accuracy: 54.89%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 235us/sample - loss: 8.2943 - accuracy: 0.3236 - val_loss: 2.2183 - val_accuracy: 0.0613\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.6468 - accuracy: 0.4750 - val_loss: 1.7706 - val_accuracy: 0.2841\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.3397 - accuracy: 0.5587 - val_loss: 1.6100 - val_accuracy: 0.2408\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.2009 - accuracy: 0.5876 - val_loss: 1.5124 - val_accuracy: 0.4498\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.1336 - accuracy: 0.6014 - val_loss: 1.5010 - val_accuracy: 0.1249\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.0679 - accuracy: 0.6073 - val_loss: 1.4322 - val_accuracy: 0.5622\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.0304 - accuracy: 0.6126 - val_loss: 1.4255 - val_accuracy: 0.4979\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.9861 - accuracy: 0.6188 - val_loss: 1.4010 - val_accuracy: 0.2541\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.9673 - accuracy: 0.6210 - val_loss: 1.3503 - val_accuracy: 0.5417\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.9446 - accuracy: 0.6248 - val_loss: 1.3654 - val_accuracy: 0.4204\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.9350 - accuracy: 0.6299 - val_loss: 1.3775 - val_accuracy: 0.2691\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.9201 - accuracy: 0.6313 - val_loss: 1.3284 - val_accuracy: 0.3520\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.8964 - accuracy: 0.6355 - val_loss: 1.3522 - val_accuracy: 0.2348\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8886 - accuracy: 0.6340 - val_loss: 1.3102 - val_accuracy: 0.4330\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.8838 - accuracy: 0.6332 - val_loss: 1.3118 - val_accuracy: 0.4396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.8658 - accuracy: 0.6390 - val_loss: 1.3261 - val_accuracy: 0.3021\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.8612 - accuracy: 0.6372 - val_loss: 1.3076 - val_accuracy: 0.5934\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8589 - accuracy: 0.6392 - val_loss: 1.3027 - val_accuracy: 0.6486\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.8536 - accuracy: 0.6390 - val_loss: 1.3026 - val_accuracy: 0.5189\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8472 - accuracy: 0.6436 - val_loss: 1.3059 - val_accuracy: 0.2589\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.8421 - accuracy: 0.6421 - val_loss: 1.3067 - val_accuracy: 0.4102\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8405 - accuracy: 0.6390 - val_loss: 1.2990 - val_accuracy: 0.5489\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8440 - accuracy: 0.6356 - val_loss: 1.2815 - val_accuracy: 0.6060\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8235 - accuracy: 0.6458 - val_loss: 1.2880 - val_accuracy: 0.6390\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8219 - accuracy: 0.6451 - val_loss: 1.2768 - val_accuracy: 0.5682\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.8209 - accuracy: 0.6438 - val_loss: 1.2759 - val_accuracy: 0.6198\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.8191 - accuracy: 0.6453 - val_loss: 1.2754 - val_accuracy: 0.5580\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.8087 - accuracy: 0.6467 - val_loss: 1.2790 - val_accuracy: 0.6294\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.8100 - accuracy: 0.6466 - val_loss: 1.2768 - val_accuracy: 0.5952\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.8037 - accuracy: 0.6494 - val_loss: 1.2823 - val_accuracy: 0.5598\n",
      "\n",
      "Accuracy: 55.98%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 9s 245us/sample - loss: 10.4886 - accuracy: 0.3826 - val_loss: 2.4191 - val_accuracy: 0.2402\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 1.4759 - accuracy: 0.5923 - val_loss: 1.5672 - val_accuracy: 0.2312\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 1.0518 - accuracy: 0.6563 - val_loss: 1.4491 - val_accuracy: 0.2571\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.9289 - accuracy: 0.6764 - val_loss: 1.4007 - val_accuracy: 0.2883\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.8878 - accuracy: 0.6812 - val_loss: 1.2937 - val_accuracy: 0.5922\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.8294 - accuracy: 0.6955 - val_loss: 1.3418 - val_accuracy: 0.4270\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8030 - accuracy: 0.7019 - val_loss: 1.2889 - val_accuracy: 0.4901\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7720 - accuracy: 0.7100 - val_loss: 1.2639 - val_accuracy: 0.4913\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7520 - accuracy: 0.7130 - val_loss: 1.2669 - val_accuracy: 0.4288\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.7280 - accuracy: 0.7228 - val_loss: 1.2380 - val_accuracy: 0.4871\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 99us/sample - loss: 0.7129 - accuracy: 0.7245 - val_loss: 1.2420 - val_accuracy: 0.4366\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7019 - accuracy: 0.7303 - val_loss: 1.2123 - val_accuracy: 0.4979\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6911 - accuracy: 0.7331 - val_loss: 1.2057 - val_accuracy: 0.4997\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6835 - accuracy: 0.7370 - val_loss: 1.1976 - val_accuracy: 0.4937\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6714 - accuracy: 0.7372 - val_loss: 1.1811 - val_accuracy: 0.5039\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6608 - accuracy: 0.7397 - val_loss: 1.2090 - val_accuracy: 0.4793\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6643 - accuracy: 0.7400 - val_loss: 1.1959 - val_accuracy: 0.5033\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6491 - accuracy: 0.7441 - val_loss: 1.2167 - val_accuracy: 0.4553\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6444 - accuracy: 0.7453 - val_loss: 1.1579 - val_accuracy: 0.5165\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6427 - accuracy: 0.7472 - val_loss: 1.1741 - val_accuracy: 0.4847\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6269 - accuracy: 0.7516 - val_loss: 1.1504 - val_accuracy: 0.5003\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6241 - accuracy: 0.7521 - val_loss: 1.1201 - val_accuracy: 0.5471\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6202 - accuracy: 0.7544 - val_loss: 1.1349 - val_accuracy: 0.5309\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6148 - accuracy: 0.7562 - val_loss: 1.1514 - val_accuracy: 0.5057\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6132 - accuracy: 0.7552 - val_loss: 1.1270 - val_accuracy: 0.5177\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6115 - accuracy: 0.7581 - val_loss: 1.0924 - val_accuracy: 0.5399\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 104us/sample - loss: 0.6105 - accuracy: 0.7579 - val_loss: 1.0964 - val_accuracy: 0.5453\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6032 - accuracy: 0.7612 - val_loss: 1.0861 - val_accuracy: 0.5508\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.5961 - accuracy: 0.7621 - val_loss: 1.0929 - val_accuracy: 0.5363\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.5960 - accuracy: 0.7646 - val_loss: 1.0951 - val_accuracy: 0.5417\n",
      "\n",
      "Accuracy: 54.17%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 228us/sample - loss: 10.9238 - accuracy: 0.3557 - val_loss: 2.3455 - val_accuracy: 0.0835\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.4827 - accuracy: 0.5088 - val_loss: 1.6879 - val_accuracy: 0.1772\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.2244 - accuracy: 0.5461 - val_loss: 1.4032 - val_accuracy: 0.2973\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.1446 - accuracy: 0.5655 - val_loss: 1.3624 - val_accuracy: 0.5628\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.0905 - accuracy: 0.5747 - val_loss: 1.3357 - val_accuracy: 0.4162\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.0332 - accuracy: 0.5926 - val_loss: 1.3325 - val_accuracy: 0.4883\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.9917 - accuracy: 0.6131 - val_loss: 1.2721 - val_accuracy: 0.5243\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9688 - accuracy: 0.6185 - val_loss: 1.3092 - val_accuracy: 0.5009\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.9431 - accuracy: 0.6252 - val_loss: 1.2195 - val_accuracy: 0.6054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9236 - accuracy: 0.6341 - val_loss: 1.3048 - val_accuracy: 0.3922\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9064 - accuracy: 0.6431 - val_loss: 1.2505 - val_accuracy: 0.4709\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.8923 - accuracy: 0.6446 - val_loss: 1.2314 - val_accuracy: 0.5363\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8747 - accuracy: 0.6542 - val_loss: 1.2141 - val_accuracy: 0.5333\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.8565 - accuracy: 0.6610 - val_loss: 1.1768 - val_accuracy: 0.5802\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.8397 - accuracy: 0.6654 - val_loss: 1.1907 - val_accuracy: 0.5417\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8271 - accuracy: 0.6719 - val_loss: 1.2076 - val_accuracy: 0.5165\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8171 - accuracy: 0.6769 - val_loss: 1.1631 - val_accuracy: 0.5628\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7940 - accuracy: 0.6766 - val_loss: 1.1659 - val_accuracy: 0.5417\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7847 - accuracy: 0.6830 - val_loss: 1.1763 - val_accuracy: 0.5580\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.7838 - accuracy: 0.6850 - val_loss: 1.1609 - val_accuracy: 0.5129\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.7868 - accuracy: 0.6798 - val_loss: 1.1605 - val_accuracy: 0.5315\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7631 - accuracy: 0.6891 - val_loss: 1.1797 - val_accuracy: 0.4979\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7630 - accuracy: 0.6869 - val_loss: 1.1794 - val_accuracy: 0.5045\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7452 - accuracy: 0.6980 - val_loss: 1.1559 - val_accuracy: 0.5159\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7494 - accuracy: 0.6922 - val_loss: 1.1860 - val_accuracy: 0.4919\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7442 - accuracy: 0.6952 - val_loss: 1.1639 - val_accuracy: 0.5039\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7361 - accuracy: 0.6943 - val_loss: 1.1777 - val_accuracy: 0.5069\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.7259 - accuracy: 0.6998 - val_loss: 1.1740 - val_accuracy: 0.5105\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7269 - accuracy: 0.6965 - val_loss: 1.1244 - val_accuracy: 0.5622\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.7226 - accuracy: 0.6977 - val_loss: 1.1574 - val_accuracy: 0.5165\n",
      "\n",
      "Accuracy: 51.65%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 239us/sample - loss: 4.6729 - accuracy: 0.4418 - val_loss: 1.9141 - val_accuracy: 0.2402\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 1.4467 - accuracy: 0.5384 - val_loss: 1.6778 - val_accuracy: 0.2408\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 1.2872 - accuracy: 0.5670 - val_loss: 1.4544 - val_accuracy: 0.6042\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 1.2064 - accuracy: 0.6112 - val_loss: 1.5544 - val_accuracy: 0.5604\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 1.0845 - accuracy: 0.6494 - val_loss: 1.5342 - val_accuracy: 0.5592\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 1.0231 - accuracy: 0.6649 - val_loss: 1.5971 - val_accuracy: 0.1940\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.9637 - accuracy: 0.6736 - val_loss: 1.3464 - val_accuracy: 0.6150\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.9186 - accuracy: 0.6838 - val_loss: 1.3693 - val_accuracy: 0.5189\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8930 - accuracy: 0.6895 - val_loss: 1.4453 - val_accuracy: 0.4505\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8590 - accuracy: 0.6983 - val_loss: 1.3931 - val_accuracy: 0.4354\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.8365 - accuracy: 0.7074 - val_loss: 1.3329 - val_accuracy: 0.4985\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8138 - accuracy: 0.7113 - val_loss: 1.3085 - val_accuracy: 0.5147\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7886 - accuracy: 0.7159 - val_loss: 1.3344 - val_accuracy: 0.4553\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7830 - accuracy: 0.7191 - val_loss: 1.3217 - val_accuracy: 0.4787\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7710 - accuracy: 0.7220 - val_loss: 1.3479 - val_accuracy: 0.4456\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7581 - accuracy: 0.7254 - val_loss: 1.2871 - val_accuracy: 0.4979\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7412 - accuracy: 0.7295 - val_loss: 1.3946 - val_accuracy: 0.3604\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7275 - accuracy: 0.7333 - val_loss: 1.3379 - val_accuracy: 0.4312\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.7149 - accuracy: 0.7358 - val_loss: 1.2712 - val_accuracy: 0.5135\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.7039 - accuracy: 0.7400 - val_loss: 1.2054 - val_accuracy: 0.5375\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6943 - accuracy: 0.7421 - val_loss: 1.2018 - val_accuracy: 0.5135\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.6791 - accuracy: 0.7457 - val_loss: 1.1555 - val_accuracy: 0.5694\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6810 - accuracy: 0.7437 - val_loss: 1.2033 - val_accuracy: 0.5267\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6820 - accuracy: 0.7427 - val_loss: 1.2178 - val_accuracy: 0.5129\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6811 - accuracy: 0.7440 - val_loss: 1.1950 - val_accuracy: 0.5147\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6844 - accuracy: 0.7439 - val_loss: 1.1634 - val_accuracy: 0.5369\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6652 - accuracy: 0.7477 - val_loss: 1.2124 - val_accuracy: 0.5189\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.6613 - accuracy: 0.7494 - val_loss: 1.1674 - val_accuracy: 0.5508\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.6620 - accuracy: 0.7489 - val_loss: 1.1768 - val_accuracy: 0.5309\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.6566 - accuracy: 0.7519 - val_loss: 1.2325 - val_accuracy: 0.5033\n",
      "\n",
      "Accuracy: 50.33%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 228us/sample - loss: 6.2884 - accuracy: 0.3016 - val_loss: 2.0580 - val_accuracy: 0.0829\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.6268 - accuracy: 0.4222 - val_loss: 1.7085 - val_accuracy: 0.2150\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.4243 - accuracy: 0.4674 - val_loss: 1.4562 - val_accuracy: 0.2709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.3161 - accuracy: 0.4903 - val_loss: 1.4224 - val_accuracy: 0.2649\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.2588 - accuracy: 0.4966 - val_loss: 1.4187 - val_accuracy: 0.2541\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.2114 - accuracy: 0.5058 - val_loss: 1.3898 - val_accuracy: 0.2601\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 1.1706 - accuracy: 0.5177 - val_loss: 1.3750 - val_accuracy: 0.2697\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.1543 - accuracy: 0.5221 - val_loss: 1.3544 - val_accuracy: 0.2342\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.1281 - accuracy: 0.5346 - val_loss: 1.3113 - val_accuracy: 0.5159\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.0975 - accuracy: 0.5389 - val_loss: 1.2983 - val_accuracy: 0.5742\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.0898 - accuracy: 0.5439 - val_loss: 1.3501 - val_accuracy: 0.2541\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 1.0747 - accuracy: 0.5531 - val_loss: 1.2908 - val_accuracy: 0.5748\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 1.0515 - accuracy: 0.5574 - val_loss: 1.2874 - val_accuracy: 0.5453\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 1.0450 - accuracy: 0.5586 - val_loss: 1.2947 - val_accuracy: 0.3592\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 1.0236 - accuracy: 0.5668 - val_loss: 1.2993 - val_accuracy: 0.6240\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.0187 - accuracy: 0.5689 - val_loss: 1.3133 - val_accuracy: 0.4210\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 1.0023 - accuracy: 0.5750 - val_loss: 1.2919 - val_accuracy: 0.3826\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.9977 - accuracy: 0.5799 - val_loss: 1.2792 - val_accuracy: 0.6559\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9846 - accuracy: 0.5796 - val_loss: 1.2896 - val_accuracy: 0.5970\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9617 - accuracy: 0.5886 - val_loss: 1.2857 - val_accuracy: 0.5447\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.9653 - accuracy: 0.5845 - val_loss: 1.2733 - val_accuracy: 0.6420\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.9567 - accuracy: 0.5858 - val_loss: 1.2700 - val_accuracy: 0.2498\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9659 - accuracy: 0.5858 - val_loss: 1.2615 - val_accuracy: 0.5568\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.9485 - accuracy: 0.5915 - val_loss: 1.2768 - val_accuracy: 0.6228\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9374 - accuracy: 0.5941 - val_loss: 1.2711 - val_accuracy: 0.4084\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.9302 - accuracy: 0.5950 - val_loss: 1.2709 - val_accuracy: 0.1730\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9270 - accuracy: 0.5946 - val_loss: 1.2801 - val_accuracy: 0.2997\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.9280 - accuracy: 0.5958 - val_loss: 1.2650 - val_accuracy: 0.3225\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9339 - accuracy: 0.5934 - val_loss: 1.2601 - val_accuracy: 0.3748\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9237 - accuracy: 0.5913 - val_loss: 1.2687 - val_accuracy: 0.3021\n",
      "\n",
      "Accuracy: 30.21%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 239us/sample - loss: 47.9134 - accuracy: 0.1590 - val_loss: 33.9862 - val_accuracy: 0.0342\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 25.7348 - accuracy: 0.2060 - val_loss: 18.6578 - val_accuracy: 0.0360\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 14.2038 - accuracy: 0.2821 - val_loss: 10.5595 - val_accuracy: 0.0462\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 7.9800 - accuracy: 0.3861 - val_loss: 6.0941 - val_accuracy: 0.2859\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 4.5502 - accuracy: 0.4903 - val_loss: 3.6386 - val_accuracy: 0.3796\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 2.6919 - accuracy: 0.5732 - val_loss: 2.3360 - val_accuracy: 0.5718\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 1.7341 - accuracy: 0.6165 - val_loss: 1.7909 - val_accuracy: 0.4829\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 4s 101us/sample - loss: 1.2729 - accuracy: 0.6468 - val_loss: 1.6527 - val_accuracy: 0.4114\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 4s 103us/sample - loss: 1.0619 - accuracy: 0.6587 - val_loss: 1.4656 - val_accuracy: 0.4931\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.9615 - accuracy: 0.6697 - val_loss: 1.4438 - val_accuracy: 0.3892\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.9208 - accuracy: 0.6816 - val_loss: 1.4596 - val_accuracy: 0.4943\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.9021 - accuracy: 0.6776 - val_loss: 1.3499 - val_accuracy: 0.4727\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8869 - accuracy: 0.6817 - val_loss: 1.3347 - val_accuracy: 0.4991\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8708 - accuracy: 0.6873 - val_loss: 1.4371 - val_accuracy: 0.3724\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8566 - accuracy: 0.6896 - val_loss: 1.3501 - val_accuracy: 0.4529\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8544 - accuracy: 0.6928 - val_loss: 1.3751 - val_accuracy: 0.4258\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8409 - accuracy: 0.6954 - val_loss: 1.3101 - val_accuracy: 0.5177\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8337 - accuracy: 0.6968 - val_loss: 1.3214 - val_accuracy: 0.4535\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8342 - accuracy: 0.6962 - val_loss: 1.3354 - val_accuracy: 0.4625\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8281 - accuracy: 0.6991 - val_loss: 1.3243 - val_accuracy: 0.4889\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8261 - accuracy: 0.7001 - val_loss: 1.4244 - val_accuracy: 0.4216\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8366 - accuracy: 0.7000 - val_loss: 1.3543 - val_accuracy: 0.4619\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8276 - accuracy: 0.6992 - val_loss: 1.2648 - val_accuracy: 0.5351\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8203 - accuracy: 0.6989 - val_loss: 1.3034 - val_accuracy: 0.5201\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 98us/sample - loss: 0.8302 - accuracy: 0.6972 - val_loss: 1.3517 - val_accuracy: 0.4228\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.8238 - accuracy: 0.6979 - val_loss: 1.3227 - val_accuracy: 0.4793\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 4s 102us/sample - loss: 0.8218 - accuracy: 0.6997 - val_loss: 1.3650 - val_accuracy: 0.4529\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35252/35252 [==============================] - 3s 97us/sample - loss: 0.8242 - accuracy: 0.6976 - val_loss: 1.3637 - val_accuracy: 0.4432\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.8309 - accuracy: 0.6964 - val_loss: 1.3346 - val_accuracy: 0.4889\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.8236 - accuracy: 0.6952 - val_loss: 1.3192 - val_accuracy: 0.4799\n",
      "\n",
      "Accuracy: 47.99%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 220us/sample - loss: 13.3999 - accuracy: 0.2432 - val_loss: 4.1797 - val_accuracy: 0.4553\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 2.6305 - accuracy: 0.4514 - val_loss: 2.0857 - val_accuracy: 0.2697\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 1.5252 - accuracy: 0.5323 - val_loss: 1.6567 - val_accuracy: 0.2108\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 86us/sample - loss: 1.1884 - accuracy: 0.5772 - val_loss: 1.4349 - val_accuracy: 0.2811\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 1.0524 - accuracy: 0.5984 - val_loss: 1.3658 - val_accuracy: 0.2360\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 1.0087 - accuracy: 0.6067 - val_loss: 1.3709 - val_accuracy: 0.2336\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.9588 - accuracy: 0.6187 - val_loss: 1.3111 - val_accuracy: 0.6258\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.9288 - accuracy: 0.6242 - val_loss: 1.3360 - val_accuracy: 0.3105\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.9108 - accuracy: 0.6299 - val_loss: 1.3136 - val_accuracy: 0.6318\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.8919 - accuracy: 0.6343 - val_loss: 1.2815 - val_accuracy: 0.6396\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.8676 - accuracy: 0.6385 - val_loss: 1.3005 - val_accuracy: 0.5754\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 86us/sample - loss: 0.8613 - accuracy: 0.6412 - val_loss: 1.3008 - val_accuracy: 0.2390\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.8467 - accuracy: 0.6389 - val_loss: 1.3110 - val_accuracy: 0.2595\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.8317 - accuracy: 0.6436 - val_loss: 1.3023 - val_accuracy: 0.3015\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 87us/sample - loss: 0.8276 - accuracy: 0.6444 - val_loss: 1.3006 - val_accuracy: 0.2619\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.8203 - accuracy: 0.6450 - val_loss: 1.2964 - val_accuracy: 0.2907\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.8150 - accuracy: 0.6444 - val_loss: 1.3032 - val_accuracy: 0.2462\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.8015 - accuracy: 0.6449 - val_loss: 1.3121 - val_accuracy: 0.2288\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 0.7916 - accuracy: 0.6495 - val_loss: 1.2983 - val_accuracy: 0.2787\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.7989 - accuracy: 0.6489 - val_loss: 1.3005 - val_accuracy: 0.3171\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7906 - accuracy: 0.6462 - val_loss: 1.2869 - val_accuracy: 0.2577\n",
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.7892 - accuracy: 0.6492 - val_loss: 1.2863 - val_accuracy: 0.2517\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7807 - accuracy: 0.6496 - val_loss: 1.2831 - val_accuracy: 0.2535\n",
      "Epoch 24/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7808 - accuracy: 0.6511 - val_loss: 1.2915 - val_accuracy: 0.2673\n",
      "Epoch 25/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7806 - accuracy: 0.6466 - val_loss: 1.2778 - val_accuracy: 0.2661\n",
      "Epoch 26/30\n",
      "35252/35252 [==============================] - 3s 84us/sample - loss: 0.7740 - accuracy: 0.6477 - val_loss: 1.2739 - val_accuracy: 0.2745\n",
      "Epoch 27/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7730 - accuracy: 0.6525 - val_loss: 1.2770 - val_accuracy: 0.1285\n",
      "Epoch 28/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7691 - accuracy: 0.6501 - val_loss: 1.2697 - val_accuracy: 0.6505\n",
      "Epoch 29/30\n",
      "35252/35252 [==============================] - 3s 85us/sample - loss: 0.7644 - accuracy: 0.6534 - val_loss: 1.2790 - val_accuracy: 0.0979\n",
      "Epoch 30/30\n",
      "35252/35252 [==============================] - 3s 86us/sample - loss: 0.7634 - accuracy: 0.6552 - val_loss: 1.2556 - val_accuracy: 0.3039\n",
      "\n",
      "Accuracy: 30.39%\n",
      "\n",
      "Train on 35252 samples, validate on 1665 samples\n",
      "Epoch 1/30\n",
      "35252/35252 [==============================] - 8s 231us/sample - loss: 13.7783 - accuracy: 0.3207 - val_loss: 3.6548 - val_accuracy: 0.0559\n",
      "Epoch 2/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 2.0569 - accuracy: 0.4758 - val_loss: 1.8965 - val_accuracy: 0.1117\n",
      "Epoch 3/30\n",
      "35252/35252 [==============================] - 3s 88us/sample - loss: 1.3795 - accuracy: 0.5076 - val_loss: 1.5365 - val_accuracy: 0.4018\n",
      "Epoch 4/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 1.1896 - accuracy: 0.5314 - val_loss: 1.3744 - val_accuracy: 0.4739\n",
      "Epoch 5/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.1123 - accuracy: 0.5413 - val_loss: 1.3166 - val_accuracy: 0.5315\n",
      "Epoch 6/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.0599 - accuracy: 0.5512 - val_loss: 1.3093 - val_accuracy: 0.4198\n",
      "Epoch 7/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 1.0291 - accuracy: 0.5612 - val_loss: 1.2586 - val_accuracy: 0.5562\n",
      "Epoch 8/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.9998 - accuracy: 0.5659 - val_loss: 1.3203 - val_accuracy: 0.4432\n",
      "Epoch 9/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9694 - accuracy: 0.5731 - val_loss: 1.2300 - val_accuracy: 0.4877\n",
      "Epoch 10/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.9595 - accuracy: 0.5742 - val_loss: 1.2717 - val_accuracy: 0.4817\n",
      "Epoch 11/30\n",
      "35252/35252 [==============================] - 3s 89us/sample - loss: 0.9486 - accuracy: 0.5820 - val_loss: 1.2103 - val_accuracy: 0.5087\n",
      "Epoch 12/30\n",
      "35252/35252 [==============================] - 3s 90us/sample - loss: 0.9338 - accuracy: 0.5862 - val_loss: 1.1993 - val_accuracy: 0.5123\n",
      "Epoch 13/30\n",
      "35252/35252 [==============================] - 3s 91us/sample - loss: 0.9234 - accuracy: 0.5870 - val_loss: 1.1990 - val_accuracy: 0.4991\n",
      "Epoch 14/30\n",
      "35252/35252 [==============================] - 3s 92us/sample - loss: 0.9111 - accuracy: 0.5993 - val_loss: 1.1891 - val_accuracy: 0.5111\n",
      "Epoch 15/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.9055 - accuracy: 0.6006 - val_loss: 1.1582 - val_accuracy: 0.5592\n",
      "Epoch 16/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8963 - accuracy: 0.6025 - val_loss: 1.1730 - val_accuracy: 0.5405\n",
      "Epoch 17/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.8849 - accuracy: 0.6104 - val_loss: 1.1530 - val_accuracy: 0.5405\n",
      "Epoch 18/30\n",
      "35252/35252 [==============================] - 4s 111us/sample - loss: 0.8788 - accuracy: 0.6156 - val_loss: 1.1635 - val_accuracy: 0.5255\n",
      "Epoch 19/30\n",
      "35252/35252 [==============================] - 4s 100us/sample - loss: 0.8764 - accuracy: 0.6167 - val_loss: 1.1234 - val_accuracy: 0.5526\n",
      "Epoch 20/30\n",
      "35252/35252 [==============================] - 3s 96us/sample - loss: 0.8582 - accuracy: 0.6239 - val_loss: 1.1284 - val_accuracy: 0.5520\n",
      "Epoch 21/30\n",
      "35252/35252 [==============================] - 3s 93us/sample - loss: 0.8603 - accuracy: 0.6259 - val_loss: 1.1307 - val_accuracy: 0.5520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "35252/35252 [==============================] - 3s 94us/sample - loss: 0.8520 - accuracy: 0.6311 - val_loss: 1.1015 - val_accuracy: 0.5574\n",
      "Epoch 23/30\n",
      "35252/35252 [==============================] - 3s 95us/sample - loss: 0.8440 - accuracy: 0.6347 - val_loss: 1.0975 - val_accuracy: 0.5514\n",
      "Epoch 24/30\n",
      "11008/35252 [========>.....................] - ETA: 2s - loss: 0.8333 - accuracy: 0.63 - ETA: 2s - loss: 0.8326 - accuracy: 0.6381"
     ]
    }
   ],
   "source": [
    "gp_result = gp_minimize(func=fitness, dimensions=dimensions,\n",
    "                        n_calls=70, noise= 0.01, n_jobs=-1,\n",
    "                        kappa = 5, x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning rate</th>\n",
       "      <th>hidden layers</th>\n",
       "      <th>input layer nodes</th>\n",
       "      <th>hidden layer nodes FC2</th>\n",
       "      <th>hidden layer nodes FC3</th>\n",
       "      <th>hidden layer nodes FC4</th>\n",
       "      <th>hidden layer nodes FC5</th>\n",
       "      <th>adam learning rate decay</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>53.813816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>128</td>\n",
       "      <td>35</td>\n",
       "      <td>77</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>49.249249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>70</td>\n",
       "      <td>97</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>54.294292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "      <td>116</td>\n",
       "      <td>75</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>56.696693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>20</td>\n",
       "      <td>102</td>\n",
       "      <td>126</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>56.216217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>112</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>1.561562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>122</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>2.402402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>83</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "      <td>47</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>1.441442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>123</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>37.897896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>115</td>\n",
       "      <td>110</td>\n",
       "      <td>26</td>\n",
       "      <td>80</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>25.465466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.120120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>64.684685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>86</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>6.906907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>6.126126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>65</td>\n",
       "      <td>107</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>57.597595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>0.600601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>58.138138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>71</td>\n",
       "      <td>28</td>\n",
       "      <td>126</td>\n",
       "      <td>104</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>59.039040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>128</td>\n",
       "      <td>106</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>50.210209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>13</td>\n",
       "      <td>124</td>\n",
       "      <td>52</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>59.099102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>128</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>23.603603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>50.270271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>58.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>31.411413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>26.186186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>61</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>61.861862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.480480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>118</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>51.771770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>80</td>\n",
       "      <td>103</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>37.237236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning rate  hidden layers  input layer nodes  hidden layer nodes FC2  \\\n",
       "0        0.001000              1                128                      64   \n",
       "1        0.002169              2                 12                      33   \n",
       "2        0.002281              3                 61                      41   \n",
       "3        0.001455              2                115                      25   \n",
       "4        0.001809              4                 70                      96   \n",
       "5        0.000238              4                 16                     112   \n",
       "6        0.000768              4                  6                      81   \n",
       "7        0.000210              2                 58                      83   \n",
       "8        0.000610              4                 82                     123   \n",
       "9        0.000646              2                 40                     115   \n",
       "10       0.000252              4                 51                      39   \n",
       "11       0.010000              5                128                     121   \n",
       "12       0.001643              1                112                     102   \n",
       "13       0.006370              1                  1                      27   \n",
       "14       0.000100              5                128                       1   \n",
       "15       0.001864              1                128                     128   \n",
       "16       0.002217              1                128                       1   \n",
       "17       0.000752              1                 92                      19   \n",
       "18       0.001389              1                128                      71   \n",
       "19       0.001393              1                128                      68   \n",
       "20       0.001334              2                128                      13   \n",
       "21       0.001449              1                128                     104   \n",
       "22       0.001246              1                  3                       1   \n",
       "23       0.003410              4                 97                      67   \n",
       "24       0.001029              2                 71                      14   \n",
       "25       0.002730              2                 70                      32   \n",
       "26       0.001700              3                  1                     128   \n",
       "27       0.001649              3                  1                     128   \n",
       "28       0.001389              5                 60                      41   \n",
       "29       0.001921              2                108                      87   \n",
       "\n",
       "    hidden layer nodes FC3  hidden layer nodes FC4  hidden layer nodes FC5  \\\n",
       "0                       64                      32                      32   \n",
       "1                      128                      35                      77   \n",
       "2                       83                      70                      97   \n",
       "3                       67                     116                      75   \n",
       "4                       20                     102                     126   \n",
       "5                       37                      77                      65   \n",
       "6                      122                      23                      28   \n",
       "7                      128                      52                      47   \n",
       "8                       19                      16                      53   \n",
       "9                      110                      26                      80   \n",
       "10                     103                       1                      27   \n",
       "11                       1                       1                       1   \n",
       "12                       6                      72                     128   \n",
       "13                      86                     128                     121   \n",
       "14                       1                     128                     128   \n",
       "15                      65                     107                      37   \n",
       "16                     121                       1                       1   \n",
       "17                     128                     128                     128   \n",
       "18                      28                     126                     104   \n",
       "19                      47                     128                     106   \n",
       "20                     124                      52                     128   \n",
       "21                       1                     109                     128   \n",
       "22                      93                      82                      38   \n",
       "23                     103                       4                     128   \n",
       "24                      68                      40                     128   \n",
       "25                      14                       2                      87   \n",
       "26                      61                     128                     128   \n",
       "27                     128                       1                     128   \n",
       "28                      52                     118                      17   \n",
       "29                      94                      80                     103   \n",
       "\n",
       "    adam learning rate decay   accuracy  \n",
       "0                   0.001000  53.813816  \n",
       "1                   0.004302  49.249249  \n",
       "2                   0.009201  54.294292  \n",
       "3                   0.008691  56.696693  \n",
       "4                   0.008516  56.216217  \n",
       "5                   0.005046   1.561562  \n",
       "6                   0.008613   2.402402  \n",
       "7                   0.004857   1.441442  \n",
       "8                   0.000710  37.897896  \n",
       "9                   0.006965  25.465466  \n",
       "10                  0.002612   0.120120  \n",
       "11                  0.000001   0.540541  \n",
       "12                  0.000519  64.684685  \n",
       "13                  0.010000   6.906907  \n",
       "14                  0.004531   6.126126  \n",
       "15                  0.000001  57.597595  \n",
       "16                  0.007865   0.600601  \n",
       "17                  0.000001  58.138138  \n",
       "18                  0.000001  59.039040  \n",
       "19                  0.000018  50.210209  \n",
       "20                  0.000001  59.099102  \n",
       "21                  0.004661  23.603603  \n",
       "22                  0.000450  50.270271  \n",
       "23                  0.000001  58.918919  \n",
       "24                  0.010000  31.411413  \n",
       "25                  0.000777  26.186186  \n",
       "26                  0.000001  61.861862  \n",
       "27                  0.000001   0.480480  \n",
       "28                  0.000733  51.771770  \n",
       "29                  0.000001  37.237236  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.concat([pd.DataFrame(gp_result.x_iters, columns = [\"learning rate\",\"hidden layers\",\n",
    "                                                      \"input layer nodes\",\"hidden layer nodes FC2\",\n",
    "                                                      \"hidden layer nodes FC3\",\"hidden layer nodes FC4\",\n",
    "                                                      \"hidden layer nodes FC5\",\"adam learning rate decay\"]),\n",
    "(pd.Series(gp_result.func_vals*-100, name=\"accuracy\"))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_excel(\"hyperparam_search.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0016434051740089192, 1, 112, 102, 6, 72, 128, 0.0005188679603436311]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
