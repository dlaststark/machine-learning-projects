{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da616b5",
   "metadata": {
    "papermill": {
     "duration": 0.04917,
     "end_time": "2021-08-04T11:54:42.195738",
     "exception": false,
     "start_time": "2021-08-04T11:54:42.146568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63d2c4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:54:42.301936Z",
     "iopub.status.busy": "2021-08-04T11:54:42.300737Z",
     "iopub.status.idle": "2021-08-04T11:54:54.896506Z",
     "shell.execute_reply": "2021-08-04T11:54:54.895526Z",
     "shell.execute_reply.started": "2021-08-04T11:09:45.256740Z"
    },
    "papermill": {
     "duration": 12.650345,
     "end_time": "2021-08-04T11:54:54.896699",
     "exception": false,
     "start_time": "2021-08-04T11:54:42.246354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordninja\r\n",
      "  Downloading wordninja-2.0.0.tar.gz (541 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 541 kB 605 kB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: wordninja\r\n",
      "  Building wheel for wordninja (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541553 sha256=845a92f607cba7301cf2bd738e255369165f055e717d0d2cdf04e6eaa549e788\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\r\n",
      "Successfully built wordninja\r\n",
      "Installing collected packages: wordninja\r\n",
      "Successfully installed wordninja-2.0.0\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5b5d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:54:55.010628Z",
     "iopub.status.busy": "2021-08-04T11:54:55.009548Z",
     "iopub.status.idle": "2021-08-04T11:55:04.039571Z",
     "shell.execute_reply": "2021-08-04T11:55:04.038774Z",
     "shell.execute_reply.started": "2021-08-04T11:09:56.922694Z"
    },
    "papermill": {
     "duration": 9.090348,
     "end_time": "2021-08-04T11:55:04.039731",
     "exception": false,
     "start_time": "2021-08-04T11:54:54.949383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import operator\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import wordninja\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52bfce0",
   "metadata": {
    "papermill": {
     "duration": 0.050891,
     "end_time": "2021-08-04T11:55:04.142476",
     "exception": false,
     "start_time": "2021-08-04T11:55:04.091585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load source datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e6f059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:04.253608Z",
     "iopub.status.busy": "2021-08-04T11:55:04.252852Z",
     "iopub.status.idle": "2021-08-04T11:55:05.201203Z",
     "shell.execute_reply": "2021-08-04T11:55:05.201782Z",
     "shell.execute_reply.started": "2021-08-04T11:10:05.495988Z"
    },
    "papermill": {
     "duration": 1.007752,
     "end_time": "2021-08-04T11:55:05.201999",
     "exception": false,
     "start_time": "2021-08-04T11:55:04.194247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (44095, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39467</th>\n",
       "      <td>Today I'm working on my &amp;quot;Quirky Q&amp;quot; c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>@ShannonElizab dont ya know? people love the h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>ughhh rejected from the 09 mediation program. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>@petewentz im so jealous. i want an octo drive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>I remember all the hype around this movie when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Sentiment\n",
       "ID                                                                 \n",
       "39467  Today I'm working on my &quot;Quirky Q&quot; c...          2\n",
       "30154  @ShannonElizab dont ya know? people love the h...          1\n",
       "16767  ughhh rejected from the 09 mediation program. ...          0\n",
       "9334      @petewentz im so jealous. i want an octo drive          0\n",
       "61178  I remember all the hype around this movie when...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/mh-sentiment-classification/train.csv\")\n",
    "train_df = train_df[~((train_df['Review']=='10-Oct')|(train_df['Review']=='0'))].copy()\n",
    "train_df.drop(['author'], inplace=True, axis=1)\n",
    "train_df.set_index(\"ID\", inplace=True)\n",
    "print(f\"train_df: {train_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc6baa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:05.315506Z",
     "iopub.status.busy": "2021-08-04T11:55:05.314732Z",
     "iopub.status.idle": "2021-08-04T11:55:05.651399Z",
     "shell.execute_reply": "2021-08-04T11:55:05.650734Z",
     "shell.execute_reply.started": "2021-08-04T11:10:06.314568Z"
    },
    "papermill": {
     "duration": 0.396142,
     "end_time": "2021-08-04T11:55:05.651552",
     "exception": false,
     "start_time": "2021-08-04T11:55:05.255410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (18900, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29536</th>\n",
       "      <td>@amyswarren ahhh yay! I'm getting into it. Kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13442</th>\n",
       "      <td>@DeliverImHungry You are right.  If you ordere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54697</th>\n",
       "      <td>I'd heard a lot of bad things about this film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>I miss the old... HA, HA. I can't tell that pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34410</th>\n",
       "      <td>@dharshana anytime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review\n",
       "ID                                                      \n",
       "29536  @amyswarren ahhh yay! I'm getting into it. Kno...\n",
       "13442  @DeliverImHungry You are right.  If you ordere...\n",
       "54697  I'd heard a lot of bad things about this film ...\n",
       "7007   I miss the old... HA, HA. I can't tell that pe...\n",
       "34410                                 @dharshana anytime"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../input/mh-sentiment-classification/test.csv\")\n",
    "test_df.drop(['author'], inplace=True, axis=1)\n",
    "test_df.set_index(\"ID\", inplace=True)\n",
    "print(f\"test_df: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3fbef",
   "metadata": {
    "papermill": {
     "duration": 0.053653,
     "end_time": "2021-08-04T11:55:05.758342",
     "exception": false,
     "start_time": "2021-08-04T11:55:05.704689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96aaba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:05.875605Z",
     "iopub.status.busy": "2021-08-04T11:55:05.874485Z",
     "iopub.status.idle": "2021-08-04T11:55:05.887591Z",
     "shell.execute_reply": "2021-08-04T11:55:05.886930Z",
     "shell.execute_reply.started": "2021-08-04T11:10:06.589653Z"
    },
    "papermill": {
     "duration": 0.075133,
     "end_time": "2021-08-04T11:55:05.887751",
     "exception": false,
     "start_time": "2021-08-04T11:55:05.812618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment  Count\n",
       "0          0  19298\n",
       "1          1   6066\n",
       "2          2  18731"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['Sentiment']).size().reset_index().rename(columns={0:'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba1bff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:06.004139Z",
     "iopub.status.busy": "2021-08-04T11:55:06.003259Z",
     "iopub.status.idle": "2021-08-04T11:55:06.046672Z",
     "shell.execute_reply": "2021-08-04T11:55:06.045896Z",
     "shell.execute_reply.started": "2021-08-04T11:10:06.607033Z"
    },
    "papermill": {
     "duration": 0.101132,
     "end_time": "2021-08-04T11:55:06.046841",
     "exception": false,
     "start_time": "2021-08-04T11:55:05.945709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.3143330915120738, 1: 1.0, 2: 0.3238481661416902}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = train_df.groupby(['Sentiment']).size().reset_index().rename(columns={0:'count'})\n",
    "total_count = np.sum(temp_df['count'].values)\n",
    "temp_df['class%'] = (temp_df['count'] / total_count) * 100\n",
    "lowest_pct = min(temp_df['class%'])\n",
    "temp_df['class_weight'] = lowest_pct / temp_df['class%']\n",
    "class_weight = temp_df[['Sentiment', 'class_weight']].to_dict()['class_weight']\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14cf076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:06.166869Z",
     "iopub.status.busy": "2021-08-04T11:55:06.165824Z",
     "iopub.status.idle": "2021-08-04T11:55:06.175869Z",
     "shell.execute_reply": "2021-08-04T11:55:06.175283Z",
     "shell.execute_reply.started": "2021-08-04T11:10:06.645244Z"
    },
    "papermill": {
     "duration": 0.071214,
     "end_time": "2021-08-04T11:55:06.176032",
     "exception": false,
     "start_time": "2021-08-04T11:55:06.104818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ytrain: (44095,) \n",
      "Ytrain_oh: (44095, 3)\n"
     ]
    }
   ],
   "source": [
    "Ytrain = train_df['Sentiment'].values\n",
    "Ytrain_oh = pd.get_dummies(train_df['Sentiment']).values\n",
    "train_df.drop(['Sentiment'], inplace=True, axis=1)\n",
    "print(f\"Ytrain: {Ytrain.shape} \\nYtrain_oh: {Ytrain_oh.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98cf94",
   "metadata": {
    "papermill": {
     "duration": 0.055428,
     "end_time": "2021-08-04T11:55:06.287267",
     "exception": false,
     "start_time": "2021-08-04T11:55:06.231839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combine reviews from train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c51f27c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:06.404586Z",
     "iopub.status.busy": "2021-08-04T11:55:06.403884Z",
     "iopub.status.idle": "2021-08-04T11:55:06.686716Z",
     "shell.execute_reply": "2021-08-04T11:55:06.687253Z",
     "shell.execute_reply.started": "2021-08-04T11:10:06.661333Z"
    },
    "papermill": {
     "duration": 0.344183,
     "end_time": "2021-08-04T11:55:06.687447",
     "exception": false,
     "start_time": "2021-08-04T11:55:06.343264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39467</th>\n",
       "      <td>Today I'm working on my &amp;quot;Quirky Q&amp;quot; c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>@ShannonElizab dont ya know? people love the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>ughhh rejected from the 09 mediation program. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>@petewentz im so jealous. i want an octo drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>I remember all the hype around this movie when...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review\n",
       "ID                                                      \n",
       "39467  Today I'm working on my &quot;Quirky Q&quot; c...\n",
       "30154  @ShannonElizab dont ya know? people love the h...\n",
       "16767  ughhh rejected from the 09 mediation program. ...\n",
       "9334      @petewentz im so jealous. i want an octo drive\n",
       "61178  I remember all the hype around this movie when..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = train_df.append(test_df, sort=False, ignore_index=False)\n",
    "\n",
    "del train_df\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c98e87",
   "metadata": {
    "papermill": {
     "duration": 0.054174,
     "end_time": "2021-08-04T11:55:06.796008",
     "exception": false,
     "start_time": "2021-08-04T11:55:06.741834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract statistical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8201f",
   "metadata": {
    "papermill": {
     "duration": 0.055547,
     "end_time": "2021-08-04T11:55:06.906502",
     "exception": false,
     "start_time": "2021-08-04T11:55:06.850955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75bf0234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:07.027409Z",
     "iopub.status.busy": "2021-08-04T11:55:07.026554Z",
     "iopub.status.idle": "2021-08-04T11:55:07.029546Z",
     "shell.execute_reply": "2021-08-04T11:55:07.028978Z",
     "shell.execute_reply.started": "2021-08-04T11:10:10.118498Z"
    },
    "papermill": {
     "duration": 0.067621,
     "end_time": "2021-08-04T11:55:07.029702",
     "exception": false,
     "start_time": "2021-08-04T11:55:06.962081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contraction_count(sent):\n",
    "    count = 0\n",
    "    count += re.subn(r\"won\\'t\", '', sent)[1]\n",
    "    count += re.subn(r\"can\\'t\", '', sent)[1]\n",
    "    count += re.subn(r\"n\\'t\", '', sent)[1]\n",
    "    count += re.subn(r\"\\'re\", '', sent)[1]\n",
    "    count += re.subn(r\"\\'s\", '', sent)[1]\n",
    "    count += re.subn(r\"\\'d\", '', sent)[1]\n",
    "    count += re.subn(r\"\\'ll\", '', sent)[1]\n",
    "    count += re.subn(r\"\\'t\", '', sent)[1]\n",
    "    count += re.subn(r\"\\'ve\", '', sent)[1]\n",
    "    count += re.subn(r\"\\'m\", '', sent)[1]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03dad8b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:07.151931Z",
     "iopub.status.busy": "2021-08-04T11:55:07.150850Z",
     "iopub.status.idle": "2021-08-04T11:55:07.153027Z",
     "shell.execute_reply": "2021-08-04T11:55:07.153560Z",
     "shell.execute_reply.started": "2021-08-04T11:10:10.857231Z"
    },
    "papermill": {
     "duration": 0.068661,
     "end_time": "2021-08-04T11:55:07.153756",
     "exception": false,
     "start_time": "2021-08-04T11:55:07.085095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_count(sent):\n",
    "    nn_count = 0   #Noun\n",
    "    pr_count = 0   #Pronoun\n",
    "    vb_count = 0   #Verb\n",
    "    jj_count = 0   #Adjective\n",
    "    uh_count = 0   #Interjection\n",
    "    cd_count = 0   #Numerics\n",
    "    \n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "\n",
    "    for token in sent:\n",
    "        if token[1] in ['NN','NNP','NNS']:\n",
    "            nn_count += 1\n",
    "\n",
    "        if token[1] in ['PRP','PRP$']:\n",
    "            pr_count += 1\n",
    "\n",
    "        if token[1] in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "            vb_count += 1\n",
    "\n",
    "        if token[1] in ['JJ','JJR','JJS']:\n",
    "            jj_count += 1\n",
    "\n",
    "        if token[1] in ['UH']:\n",
    "            uh_count += 1\n",
    "\n",
    "        if token[1] in ['CD']:\n",
    "            cd_count += 1\n",
    "    \n",
    "    return pd.Series([nn_count, pr_count, vb_count, jj_count, uh_count, cd_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f048587f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:07.268233Z",
     "iopub.status.busy": "2021-08-04T11:55:07.267161Z",
     "iopub.status.idle": "2021-08-04T11:55:07.281381Z",
     "shell.execute_reply": "2021-08-04T11:55:07.281863Z",
     "shell.execute_reply.started": "2021-08-04T11:10:11.655539Z"
    },
    "papermill": {
     "duration": 0.073531,
     "end_time": "2021-08-04T11:55:07.282103",
     "exception": false,
     "start_time": "2021-08-04T11:55:07.208572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dialog_parser(text):\n",
    "    \n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    \n",
    "    # let's set up some lists to hold our pieces of narrative and dialog\n",
    "    parsed_dialog = []\n",
    "    parsed_narrative = []\n",
    "    \n",
    "    # and this list will be a bucket for the text we're currently exploring\n",
    "    current = []\n",
    "\n",
    "    # now let's set up values that will help us loop through the text\n",
    "    length = len(tokenized)\n",
    "    found_q = False\n",
    "    counter = 0\n",
    "    quote_open, quote_close = '``', \"''\"\n",
    "\n",
    "    # now we'll start our loop saying that as long as our sentence is...\n",
    "    while counter < length:\n",
    "        word = tokenized[counter]\n",
    "\n",
    "        # until we find a quotation mark, we're working with narrative\n",
    "        if quote_open not in word and quote_close not in word:\n",
    "            current.append(word)\n",
    "\n",
    "        # here's what we do when we find a closed quote\n",
    "        else:\n",
    "            # we append the narrative we've collected & clear our our\n",
    "            # current variable\n",
    "            parsed_narrative.append(current)\n",
    "            current = []\n",
    "            \n",
    "            # now current is ready to hold dialog and we're working on\n",
    "            # a piece of dialog\n",
    "            current.append(word)\n",
    "            found_q = True\n",
    "\n",
    "            # while we're in the quote, we're going to increment the counter\n",
    "            # and append to current in this while loop\n",
    "            while found_q and counter < length-1:\n",
    "                counter += 1\n",
    "                if quote_close not in tokenized[counter]:\n",
    "                    current.append(tokenized[counter])\n",
    "                else:\n",
    "                    # if we find a closing quote, we add our dialog to the\n",
    "                    # appropriate list, clear current and flip our found_q\n",
    "                    # variable to False\n",
    "                    current.append(tokenized[counter])\n",
    "                    parsed_dialog.append(current)\n",
    "                    current = []\n",
    "                    found_q = False\n",
    "\n",
    "        # increment the counter to move us through the text\n",
    "        counter += 1\n",
    "    \n",
    "    if len(parsed_narrative) == 0:\n",
    "        parsed_narrative.append(current)\n",
    "    \n",
    "    mean_dialog_word_len = 0\n",
    "    \n",
    "    if len(parsed_dialog) > 0:\n",
    "        for text in parsed_dialog:\n",
    "            join_text = \" \".join(text)\n",
    "            join_text = join_text.replace('\"','')\n",
    "            join_text = join_text.replace(\"''\",\"\")\n",
    "            mean_dialog_word_len += len(join_text.split())\n",
    "        \n",
    "        mean_dialog_word_len /= float(len(parsed_dialog))\n",
    "    \n",
    "    mean_narrative_word_len = 0\n",
    "    \n",
    "    if len(parsed_narrative) > 0:\n",
    "        for text in parsed_narrative:\n",
    "            join_text = \" \".join(text)\n",
    "            join_text = join_text.replace('\"','')\n",
    "            join_text = join_text.replace(\"''\",\"\")\n",
    "            mean_narrative_word_len += len(join_text.split())\n",
    "        \n",
    "        mean_narrative_word_len /= float(len(parsed_narrative))\n",
    "\n",
    "    return pd.Series([len(parsed_dialog), len(parsed_narrative), mean_dialog_word_len, mean_narrative_word_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45f4827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T11:55:07.399682Z",
     "iopub.status.busy": "2021-08-04T11:55:07.398404Z",
     "iopub.status.idle": "2021-08-04T12:18:03.661941Z",
     "shell.execute_reply": "2021-08-04T12:18:03.661202Z",
     "shell.execute_reply.started": "2021-08-04T11:10:11.903600Z"
    },
    "papermill": {
     "duration": 1376.323432,
     "end_time": "2021-08-04T12:18:03.662138",
     "exception": false,
     "start_time": "2021-08-04T11:55:07.338706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:00<00:00, 126748.38it/s]\n",
      " 10%|█         | 6363/62995 [00:00<00:00, 63622.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_words...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:01<00:00, 61199.97it/s]\n",
      "100%|██████████| 62995/62995 [00:00<00:00, 413080.91it/s]\n",
      "  0%|          | 0/62995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_unique_words...Completed\n",
      "Review_num_chars...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [11:03<00:00, 94.87it/s] \n",
      "  4%|▎         | 2264/62995 [00:00<00:02, 22574.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_stopwords...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:02<00:00, 21512.83it/s]\n",
      "  4%|▎         | 2306/62995 [00:00<00:02, 22963.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_@...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:02<00:00, 21403.11it/s]\n",
      " 10%|▉         | 6230/62995 [00:00<00:00, 62298.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_#...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:01<00:00, 62516.63it/s]\n",
      " 41%|████      | 25571/62995 [00:00<00:00, 255708.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_urls...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:00<00:00, 247851.33it/s]\n",
      "  0%|          | 116/62995 [00:00<00:54, 1145.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_tags...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:40<00:00, 1558.98it/s]\n",
      " 12%|█▏        | 7553/62995 [00:00<00:00, 75507.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_punctuations...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:00<00:00, 74525.69it/s]\n",
      " 11%|█         | 6719/62995 [00:00<00:00, 67158.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_words_upper...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:00<00:00, 66794.68it/s]\n",
      "  3%|▎         | 2086/62995 [00:00<00:02, 20850.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_words_title...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:03<00:00, 19920.84it/s]\n",
      "100%|██████████| 62995/62995 [00:00<00:00, 412005.86it/s]\n",
      "  0%|          | 0/62995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_mean_word_len...Completed\n",
      "Review_num_paragraphs...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:01<00:00, 48093.43it/s]\n",
      "  0%|          | 55/62995 [00:00<01:54, 549.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_num_contractions...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [01:40<00:00, 629.03it/s]\n",
      "  0%|          | 43/62995 [00:00<02:26, 428.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog Parser...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:56<00:00, 1114.35it/s]\n",
      "  0%|          | 85/62995 [00:00<01:15, 833.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_polarity...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:56<00:00, 1105.96it/s]\n",
      "  0%|          | 2/62995 [00:00<1:08:48, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review_subjectivity...Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [07:22<00:00, 142.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Count...Completed\n",
      "\n",
      "combined_df: (62995, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_num_words</th>\n",
       "      <th>Review_num_unique_words</th>\n",
       "      <th>Review_num_chars</th>\n",
       "      <th>Review_num_stopwords</th>\n",
       "      <th>Review_num_@</th>\n",
       "      <th>Review_num_#</th>\n",
       "      <th>Review_num_urls</th>\n",
       "      <th>Review_num_tags</th>\n",
       "      <th>Review_num_punctuations</th>\n",
       "      <th>...</th>\n",
       "      <th>Review_dialog_mean_word_len</th>\n",
       "      <th>Review_narrative_mean_word_len</th>\n",
       "      <th>Review_polarity</th>\n",
       "      <th>Review_subjectivity</th>\n",
       "      <th>nn_count</th>\n",
       "      <th>pr_count</th>\n",
       "      <th>vb_count</th>\n",
       "      <th>jj_count</th>\n",
       "      <th>uh_count</th>\n",
       "      <th>cd_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39467</th>\n",
       "      <td>Today I'm working on my &amp;quot;Quirky Q&amp;quot; c...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>@ShannonElizab dont ya know? people love the h...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>ughhh rejected from the 09 mediation program. ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>@petewentz im so jealous. i want an octo drive</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>I remember all the hype around this movie when...</td>\n",
       "      <td>574</td>\n",
       "      <td>339</td>\n",
       "      <td>3190</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.095471</td>\n",
       "      <td>0.478622</td>\n",
       "      <td>223</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Review_num_words  \\\n",
       "ID                                                                           \n",
       "39467  Today I'm working on my &quot;Quirky Q&quot; c...                15   \n",
       "30154  @ShannonElizab dont ya know? people love the h...                 9   \n",
       "16767  ughhh rejected from the 09 mediation program. ...                 8   \n",
       "9334      @petewentz im so jealous. i want an octo drive                 9   \n",
       "61178  I remember all the hype around this movie when...               574   \n",
       "\n",
       "       Review_num_unique_words  Review_num_chars  Review_num_stopwords  \\\n",
       "ID                                                                       \n",
       "39467                       15                83                     6   \n",
       "30154                        9                58                     1   \n",
       "16767                        8                55                     2   \n",
       "9334                         9                46                     3   \n",
       "61178                      339              3190                   272   \n",
       "\n",
       "       Review_num_@  Review_num_#  Review_num_urls  Review_num_tags  \\\n",
       "ID                                                                    \n",
       "39467             0             0                0                0   \n",
       "30154             1             0                0                0   \n",
       "16767             0             0                0                0   \n",
       "9334              1             0                0                0   \n",
       "61178             0             0                0               18   \n",
       "\n",
       "       Review_num_punctuations  ...  Review_dialog_mean_word_len  \\\n",
       "ID                              ...                                \n",
       "39467                        5  ...                     0.000000   \n",
       "30154                        2  ...                     0.000000   \n",
       "16767                        2  ...                     0.000000   \n",
       "9334                         2  ...                     0.000000   \n",
       "61178                      152  ...                    67.333333   \n",
       "\n",
       "       Review_narrative_mean_word_len  Review_polarity  Review_subjectivity  \\\n",
       "ID                                                                            \n",
       "39467                            22.0         0.000000             0.000000   \n",
       "30154                            11.0         0.250000             0.350000   \n",
       "16767                            10.0         0.000000             0.000000   \n",
       "9334                             11.0         0.000000             0.000000   \n",
       "61178                            95.0         0.095471             0.478622   \n",
       "\n",
       "       nn_count  pr_count  vb_count  jj_count  uh_count  cd_count  \n",
       "ID                                                                 \n",
       "39467         7         3         4         0         0         0  \n",
       "30154         5         0         2         2         0         0  \n",
       "16767         3         0         1         0         0         1  \n",
       "9334          5         0         1         2         0         0  \n",
       "61178       223        40       100        38         0         7  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"Review_num_words\"] = combined_df[\"Review\"].progress_apply(lambda x: len(str(x).split()))\n",
    "print(\"Review_num_words...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_unique_words\"] = combined_df[\"Review\"].progress_apply(lambda x: len(set(str(x).split())))\n",
    "print(\"Review_num_unique_words...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_chars\"] = combined_df[\"Review\"].progress_apply(lambda x: len(str(x)))\n",
    "print(\"Review_num_chars...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_stopwords\"] = combined_df[\"Review\"].progress_apply(lambda x: len([w for w in str(x).lower().split() if w in stopwords.words('english')]))\n",
    "print(\"Review_num_stopwords...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_@\"] = combined_df[\"Review\"].progress_apply(lambda x: len(re.findall(\"(?<![@\\w])@(\\w{1,25})\", x)))\n",
    "print(\"Review_num_@...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_#\"] = combined_df[\"Review\"].progress_apply(lambda x: len(re.findall(\"(?<![#\\w])#(\\w{1,25})\", x)))\n",
    "print(\"Review_num_#...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_urls\"] = combined_df[\"Review\"].progress_apply(lambda x: len(re.findall(\"https?://\\S+|www\\.\\S+\", x)))\n",
    "print(\"Review_num_urls...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_tags\"] = combined_df[\"Review\"].progress_apply(lambda x: len(re.findall(\"<.*?>\", x)))\n",
    "print(\"Review_num_tags...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_punctuations\"] =combined_df['Review'].progress_apply(lambda x: len([c for c in str(x) if c in list(string.punctuation)]))\n",
    "print(\"Review_num_punctuations...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_words_upper\"] = combined_df[\"Review\"].progress_apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "print(\"Review_num_words_upper...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_words_title\"] = combined_df[\"Review\"].progress_apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "print(\"Review_num_words_title...Completed\")\n",
    "\n",
    "combined_df[\"Review_mean_word_len\"] = combined_df[\"Review\"].progress_apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "print(\"Review_mean_word_len...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_paragraphs\"] = combined_df[\"Review\"].progress_apply(lambda x: len(x.split('\\n')))\n",
    "print(\"Review_num_paragraphs...Completed\")\n",
    "\n",
    "combined_df[\"Review_num_contractions\"] = combined_df[\"Review\"].progress_apply(contraction_count)\n",
    "print(\"Review_num_contractions...Completed\")\n",
    "\n",
    "combined_df[[\"Review_num_dialog\",\n",
    "             \"Review_num_narrative\",\n",
    "             \"Review_dialog_mean_word_len\",\n",
    "             \"Review_narrative_mean_word_len\"]] = combined_df[\"Review\"].progress_apply(dialog_parser)\n",
    "print(\"Dialog Parser...Completed\")\n",
    "\n",
    "combined_df['Review_polarity'] = combined_df['Review'].progress_apply(lambda x: TextBlob(x).sentiment[0])\n",
    "print(\"Review_polarity...Completed\")\n",
    "\n",
    "combined_df['Review_subjectivity'] = combined_df['Review'].progress_apply(lambda x: TextBlob(x).sentiment[1])\n",
    "print(\"Review_subjectivity...Completed\")\n",
    "\n",
    "combined_df[['nn_count','pr_count','vb_count','jj_count','uh_count','cd_count']] = combined_df['Review'].progress_apply(pos_count)\n",
    "print(\"POS Count...Completed\")\n",
    "\n",
    "print(f\"\\ncombined_df: {combined_df.shape}\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246c02a",
   "metadata": {
    "papermill": {
     "duration": 3.231517,
     "end_time": "2021-08-04T12:18:10.218665",
     "exception": false,
     "start_time": "2021-08-04T12:18:06.987148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd7451e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:18:16.937132Z",
     "iopub.status.busy": "2021-08-04T12:18:16.936253Z",
     "iopub.status.idle": "2021-08-04T12:19:05.540290Z",
     "shell.execute_reply": "2021-08-04T12:19:05.539697Z",
     "shell.execute_reply.started": "2021-08-04T11:33:04.710036Z"
    },
    "papermill": {
     "duration": 51.907298,
     "end_time": "2021-08-04T12:19:05.540456",
     "exception": false,
     "start_time": "2021-08-04T12:18:13.633158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Word vectors found: 2196017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../input/nlp-word-embeddings/Glove_Embeddings.txt\", 'rb') as handle: \n",
    "    data = handle.read()\n",
    "\n",
    "processed_data = pickle.loads(data)\n",
    "glove_embeddings_index = processed_data['glove_embeddings_index']\n",
    "print(f'Glove Word vectors found: {len(glove_embeddings_index)}')\n",
    "\n",
    "del processed_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62ff06f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:19:12.217475Z",
     "iopub.status.busy": "2021-08-04T12:19:12.216662Z",
     "iopub.status.idle": "2021-08-04T12:19:34.809842Z",
     "shell.execute_reply": "2021-08-04T12:19:34.810365Z",
     "shell.execute_reply.started": "2021-08-04T11:33:50.784205Z"
    },
    "papermill": {
     "duration": 25.886352,
     "end_time": "2021-08-04T12:19:34.810594",
     "exception": false,
     "start_time": "2021-08-04T12:19:08.924242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText Word vectors found: 1000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../input/nlp-word-embeddings/FastText_Embeddings.txt\", 'rb') as handle: \n",
    "    data = handle.read()\n",
    "\n",
    "processed_data = pickle.loads(data)\n",
    "fasttext_embeddings_index = processed_data['fasttext_embeddings_index']\n",
    "print(f'FastText Word vectors found: {len(fasttext_embeddings_index)}')\n",
    "\n",
    "del processed_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "635f57c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:19:41.390292Z",
     "iopub.status.busy": "2021-08-04T12:19:41.389587Z",
     "iopub.status.idle": "2021-08-04T12:20:21.299654Z",
     "shell.execute_reply": "2021-08-04T12:20:21.299067Z",
     "shell.execute_reply.started": "2021-08-04T11:34:12.792814Z"
    },
    "papermill": {
     "duration": 43.244589,
     "end_time": "2021-08-04T12:20:21.299822",
     "exception": false,
     "start_time": "2021-08-04T12:19:38.055233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragram Word vectors found: 1703755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../input/nlp-word-embeddings/Para_Embeddings.txt\", 'rb') as handle: \n",
    "    data = handle.read()\n",
    "\n",
    "processed_data = pickle.loads(data)\n",
    "para_embeddings_index = processed_data['para_embeddings_index']\n",
    "print(f'Paragram Word vectors found: {len(para_embeddings_index)}')\n",
    "\n",
    "del processed_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d1ffc",
   "metadata": {
    "papermill": {
     "duration": 3.214585,
     "end_time": "2021-08-04T12:20:27.946756",
     "exception": false,
     "start_time": "2021-08-04T12:20:24.732171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ae55f",
   "metadata": {
    "papermill": {
     "duration": 3.232774,
     "end_time": "2021-08-04T12:20:34.484289",
     "exception": false,
     "start_time": "2021-08-04T12:20:31.251515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab92139f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:20:40.985644Z",
     "iopub.status.busy": "2021-08-04T12:20:40.983742Z",
     "iopub.status.idle": "2021-08-04T12:20:40.986540Z",
     "shell.execute_reply": "2021-08-04T12:20:40.984777Z",
     "shell.execute_reply.started": "2021-08-04T11:35:02.728251Z"
    },
    "papermill": {
     "duration": 3.297678,
     "end_time": "2021-08-04T12:20:40.986762",
     "exception": false,
     "start_time": "2021-08-04T12:20:37.689084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a26e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:20:47.576789Z",
     "iopub.status.busy": "2021-08-04T12:20:47.576092Z",
     "iopub.status.idle": "2021-08-04T12:20:47.578184Z",
     "shell.execute_reply": "2021-08-04T12:20:47.578647Z",
     "shell.execute_reply.started": "2021-08-04T11:35:03.448218Z"
    },
    "papermill": {
     "duration": 3.324771,
     "end_time": "2021-08-04T12:20:47.578857",
     "exception": false,
     "start_time": "2021-08-04T12:20:44.254086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    \n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    \n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "295789c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:20:57.684534Z",
     "iopub.status.busy": "2021-08-04T12:20:57.683843Z",
     "iopub.status.idle": "2021-08-04T12:20:57.689007Z",
     "shell.execute_reply": "2021-08-04T12:20:57.689571Z",
     "shell.execute_reply.started": "2021-08-04T11:35:04.207466Z"
    },
    "papermill": {
     "duration": 3.331487,
     "end_time": "2021-08-04T12:20:57.689766",
     "exception": false,
     "start_time": "2021-08-04T12:20:54.358279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_lower(embedding, vocab):\n",
    "    count = 0\n",
    "    \n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:  \n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"Added {count} words to embedding\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e35eea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:21:04.280422Z",
     "iopub.status.busy": "2021-08-04T12:21:04.279448Z",
     "iopub.status.idle": "2021-08-04T12:21:04.282589Z",
     "shell.execute_reply": "2021-08-04T12:21:04.282080Z",
     "shell.execute_reply.started": "2021-08-04T11:35:05.300544Z"
    },
    "papermill": {
     "duration": 3.333819,
     "end_time": "2021-08-04T12:21:04.282747",
     "exception": false,
     "start_time": "2021-08-04T12:21:00.948928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_contractions(text):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "        \n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d96249f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:21:10.814970Z",
     "iopub.status.busy": "2021-08-04T12:21:10.814261Z",
     "iopub.status.idle": "2021-08-04T12:21:10.816590Z",
     "shell.execute_reply": "2021-08-04T12:21:10.817197Z",
     "shell.execute_reply.started": "2021-08-04T11:35:07.180951Z"
    },
    "papermill": {
     "duration": 3.291693,
     "end_time": "2021-08-04T12:21:10.817397",
     "exception": false,
     "start_time": "2021-08-04T12:21:07.525704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unknown_punct(embed):\n",
    "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "    unknown = ''\n",
    "    \n",
    "    for p in punct:\n",
    "        if p not in embed:\n",
    "            unknown += p\n",
    "            unknown += ' '\n",
    "            \n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83dcdc87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:21:17.417921Z",
     "iopub.status.busy": "2021-08-04T12:21:17.416787Z",
     "iopub.status.idle": "2021-08-04T12:21:17.419308Z",
     "shell.execute_reply": "2021-08-04T12:21:17.419788Z",
     "shell.execute_reply.started": "2021-08-04T11:35:07.986881Z"
    },
    "papermill": {
     "duration": 3.315955,
     "end_time": "2021-08-04T12:21:17.419986",
     "exception": false,
     "start_time": "2021-08-04T12:21:14.104031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_special_chars(text):\n",
    "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "    mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }    \n",
    "    \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': '', '':'', '·':'', '¿':'', '¨':'', '»':'', '«':''}\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb8b7bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:21:24.029948Z",
     "iopub.status.busy": "2021-08-04T12:21:24.029278Z",
     "iopub.status.idle": "2021-08-04T12:21:24.037659Z",
     "shell.execute_reply": "2021-08-04T12:21:24.037102Z",
     "shell.execute_reply.started": "2021-08-04T11:35:09.202463Z"
    },
    "papermill": {
     "duration": 3.336722,
     "end_time": "2021-08-04T12:21:24.037822",
     "exception": false,
     "start_time": "2021-08-04T12:21:20.701100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sep_combined(text, glove_embed, fasttext_embed, para_embed):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if not((word in glove_embed) or (word in fasttext_embed) or (word in para_embed)):\n",
    "            wn_token = wordninja.split(word)\n",
    "        \n",
    "            if len(wn_token) > 1:\n",
    "                for w in wn_token:\n",
    "                    new_text.append(w)\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        \n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    \n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691772d0",
   "metadata": {
    "papermill": {
     "duration": 3.295382,
     "end_time": "2021-08-04T12:21:30.588882",
     "exception": false,
     "start_time": "2021-08-04T12:21:27.293500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get initial word coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d8a2c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:21:37.022572Z",
     "iopub.status.busy": "2021-08-04T12:21:37.021845Z",
     "iopub.status.idle": "2021-08-04T12:21:41.378633Z",
     "shell.execute_reply": "2021-08-04T12:21:41.377918Z",
     "shell.execute_reply.started": "2021-08-04T11:35:10.467778Z"
    },
    "papermill": {
     "duration": 7.574361,
     "end_time": "2021-08-04T12:21:41.378784",
     "exception": false,
     "start_time": "2021-08-04T12:21:33.804423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:01<00:00, 33848.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove : \n",
      "Found embeddings for 30.39% of vocab\n",
      "Found embeddings for  87.34% of all text\n",
      "\n",
      "Paragram : \n",
      "Found embeddings for 18.63% of vocab\n",
      "Found embeddings for  77.71% of all text\n",
      "\n",
      "FastText : \n",
      "Found embeddings for 28.64% of vocab\n",
      "Found embeddings for  86.14% of all text\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(combined_df['Review'])\n",
    "\n",
    "print(\"\\nGlove : \")\n",
    "oov_glove = check_coverage(vocab, glove_embeddings_index)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "oov_paragram = check_coverage(vocab, para_embeddings_index)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "oov_fasttext = check_coverage(vocab, fasttext_embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f86e766b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:21:47.912739Z",
     "iopub.status.busy": "2021-08-04T12:21:47.907609Z",
     "iopub.status.idle": "2021-08-04T12:21:48.411942Z",
     "shell.execute_reply": "2021-08-04T12:21:48.411301Z",
     "shell.execute_reply.started": "2021-08-04T11:35:16.278192Z"
    },
    "papermill": {
     "duration": 3.741055,
     "end_time": "2021-08-04T12:21:48.412136",
     "exception": false,
     "start_time": "2021-08-04T12:21:44.671081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Added 5126 words to embedding\n",
      "\n",
      "Paragram : \n",
      "Added 4 words to embedding\n",
      "\n",
      "FastText : \n",
      "Added 9876 words to embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "glove_embeddings_index = add_lower(glove_embeddings_index, vocab)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "para_embeddings_index = add_lower(para_embeddings_index, vocab)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "fasttext_embeddings_index = add_lower(fasttext_embeddings_index, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3c0951f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:21:55.028731Z",
     "iopub.status.busy": "2021-08-04T12:21:55.027812Z",
     "iopub.status.idle": "2021-08-04T12:21:59.755944Z",
     "shell.execute_reply": "2021-08-04T12:21:59.755246Z",
     "shell.execute_reply.started": "2021-08-04T11:35:19.007996Z"
    },
    "papermill": {
     "duration": 8.019822,
     "end_time": "2021-08-04T12:21:59.756115",
     "exception": false,
     "start_time": "2021-08-04T12:21:51.736293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:00<00:00, 419258.02it/s]\n",
      "100%|██████████| 62995/62995 [00:01<00:00, 34312.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove : \n",
      "Found embeddings for 27.67% of vocab\n",
      "Found embeddings for  87.47% of all text\n",
      "\n",
      "Paragram : \n",
      "Found embeddings for 27.89% of vocab\n",
      "Found embeddings for  87.49% of all text\n",
      "\n",
      "FastText : \n",
      "Found embeddings for 26.26% of vocab\n",
      "Found embeddings for  86.26% of all text\n"
     ]
    }
   ],
   "source": [
    "combined_df['processed_review'] = combined_df['Review'].progress_apply(lambda x: x.lower())\n",
    "vocab = build_vocab(combined_df['processed_review'])\n",
    "\n",
    "print(\"\\nGlove : \")\n",
    "oov_glove = check_coverage(vocab, glove_embeddings_index)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "oov_paragram = check_coverage(vocab, para_embeddings_index)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "oov_fasttext = check_coverage(vocab, fasttext_embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c095f85",
   "metadata": {
    "papermill": {
     "duration": 3.332738,
     "end_time": "2021-08-04T12:22:06.553052",
     "exception": false,
     "start_time": "2021-08-04T12:22:03.220314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Remove contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b472edac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:22:13.130787Z",
     "iopub.status.busy": "2021-08-04T12:22:13.129962Z",
     "iopub.status.idle": "2021-08-04T12:22:18.920226Z",
     "shell.execute_reply": "2021-08-04T12:22:18.920710Z",
     "shell.execute_reply.started": "2021-08-04T11:35:25.860121Z"
    },
    "papermill": {
     "duration": 9.056073,
     "end_time": "2021-08-04T12:22:18.920913",
     "exception": false,
     "start_time": "2021-08-04T12:22:09.864840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:01<00:00, 38431.81it/s]\n",
      "100%|██████████| 62995/62995 [00:01<00:00, 34341.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove : \n",
      "Found embeddings for 27.70% of vocab\n",
      "Found embeddings for  88.10% of all text\n",
      "\n",
      "Paragram : \n",
      "Found embeddings for 27.93% of vocab\n",
      "Found embeddings for  88.11% of all text\n",
      "\n",
      "FastText : \n",
      "Found embeddings for 26.29% of vocab\n",
      "Found embeddings for  87.88% of all text\n"
     ]
    }
   ],
   "source": [
    "combined_df['processed_review'] = combined_df['processed_review'].progress_apply(lambda x: clean_contractions(x))\n",
    "vocab = build_vocab(combined_df['processed_review'])\n",
    "\n",
    "print(\"\\nGlove : \")\n",
    "oov_glove = check_coverage(vocab, glove_embeddings_index)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "oov_paragram = check_coverage(vocab, para_embeddings_index)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "oov_fasttext = check_coverage(vocab, fasttext_embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5986b",
   "metadata": {
    "papermill": {
     "duration": 3.341083,
     "end_time": "2021-08-04T12:22:25.647860",
     "exception": false,
     "start_time": "2021-08-04T12:22:22.306777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Handle punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b455c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:22:32.404168Z",
     "iopub.status.busy": "2021-08-04T12:22:32.403349Z",
     "iopub.status.idle": "2021-08-04T12:22:32.407032Z",
     "shell.execute_reply": "2021-08-04T12:22:32.407570Z",
     "shell.execute_reply.started": "2021-08-04T11:35:33.475991Z"
    },
    "papermill": {
     "duration": 3.283866,
     "end_time": "2021-08-04T12:22:32.407770",
     "exception": false,
     "start_time": "2021-08-04T12:22:29.123904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove :\n",
      "₹ \n",
      "\n",
      "Paragram :\n",
      "₹ \n",
      "\n",
      "FastText :\n",
      "_ ` \n"
     ]
    }
   ],
   "source": [
    "print(\"Glove :\")\n",
    "print(unknown_punct(glove_embeddings_index))\n",
    "\n",
    "print(\"\\nParagram :\")\n",
    "print(unknown_punct(para_embeddings_index))\n",
    "\n",
    "print(\"\\nFastText :\")\n",
    "print(unknown_punct(fasttext_embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e4c87d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:22:39.026131Z",
     "iopub.status.busy": "2021-08-04T12:22:39.025092Z",
     "iopub.status.idle": "2021-08-04T12:22:46.009631Z",
     "shell.execute_reply": "2021-08-04T12:22:46.008983Z",
     "shell.execute_reply.started": "2021-08-04T11:35:34.698081Z"
    },
    "papermill": {
     "duration": 10.305621,
     "end_time": "2021-08-04T12:22:46.009813",
     "exception": false,
     "start_time": "2021-08-04T12:22:35.704192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:03<00:00, 20991.39it/s]\n",
      "100%|██████████| 62995/62995 [00:01<00:00, 34482.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove : \n",
      "Found embeddings for 71.74% of vocab\n",
      "Found embeddings for  99.47% of all text\n",
      "\n",
      "Paragram : \n",
      "Found embeddings for 74.31% of vocab\n",
      "Found embeddings for  99.52% of all text\n",
      "\n",
      "FastText : \n",
      "Found embeddings for 64.77% of vocab\n",
      "Found embeddings for  99.31% of all text\n"
     ]
    }
   ],
   "source": [
    "combined_df['processed_review'] = combined_df['processed_review'].progress_apply(lambda x: clean_special_chars(x))\n",
    "vocab = build_vocab(combined_df['processed_review'])\n",
    "\n",
    "print(\"\\nGlove : \")\n",
    "oov_glove = check_coverage(vocab, glove_embeddings_index)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "oov_paragram = check_coverage(vocab, para_embeddings_index)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "oov_fasttext = check_coverage(vocab, fasttext_embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27011e",
   "metadata": {
    "papermill": {
     "duration": 3.317481,
     "end_time": "2021-08-04T12:22:52.568721",
     "exception": false,
     "start_time": "2021-08-04T12:22:49.251240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Separate combined words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b27aafea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:22:59.166390Z",
     "iopub.status.busy": "2021-08-04T12:22:59.165644Z",
     "iopub.status.idle": "2021-08-04T12:23:08.514950Z",
     "shell.execute_reply": "2021-08-04T12:23:08.514398Z",
     "shell.execute_reply.started": "2021-08-04T11:35:43.413843Z"
    },
    "papermill": {
     "duration": 12.681731,
     "end_time": "2021-08-04T12:23:08.515130",
     "exception": false,
     "start_time": "2021-08-04T12:22:55.833399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:06<00:00, 10469.68it/s]\n",
      "100%|██████████| 62995/62995 [00:01<00:00, 32733.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove : \n",
      "Found embeddings for 95.67% of vocab\n",
      "Found embeddings for  99.93% of all text\n",
      "\n",
      "Paragram : \n",
      "Found embeddings for 99.26% of vocab\n",
      "Found embeddings for  99.99% of all text\n",
      "\n",
      "FastText : \n",
      "Found embeddings for 85.65% of vocab\n",
      "Found embeddings for  99.75% of all text\n"
     ]
    }
   ],
   "source": [
    "combined_df['processed_review'] = combined_df['processed_review'].progress_apply(lambda x: sep_combined(x, glove_embeddings_index, \n",
    "                                                                                                        fasttext_embeddings_index, \n",
    "                                                                                                        para_embeddings_index))\n",
    "vocab = build_vocab(combined_df['processed_review'])\n",
    "\n",
    "print(\"\\nGlove : \")\n",
    "oov_glove = check_coverage(vocab, glove_embeddings_index)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "oov_paragram = check_coverage(vocab, para_embeddings_index)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "oov_fasttext = check_coverage(vocab, fasttext_embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261937f2",
   "metadata": {
    "papermill": {
     "duration": 3.336323,
     "end_time": "2021-08-04T12:23:15.130077",
     "exception": false,
     "start_time": "2021-08-04T12:23:11.793754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "234de5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:23:21.879299Z",
     "iopub.status.busy": "2021-08-04T12:23:21.878591Z",
     "iopub.status.idle": "2021-08-04T12:23:26.423142Z",
     "shell.execute_reply": "2021-08-04T12:23:26.422201Z",
     "shell.execute_reply.started": "2021-08-04T11:36:01.678440Z"
    },
    "papermill": {
     "duration": 8.013897,
     "end_time": "2021-08-04T12:23:26.423309",
     "exception": false,
     "start_time": "2021-08-04T12:23:18.409412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:01<00:00, 47165.64it/s]\n",
      "100%|██████████| 62995/62995 [00:01<00:00, 34330.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove : \n",
      "Found embeddings for 95.78% of vocab\n",
      "Found embeddings for  99.93% of all text\n",
      "\n",
      "Paragram : \n",
      "Found embeddings for 99.41% of vocab\n",
      "Found embeddings for  99.99% of all text\n",
      "\n",
      "FastText : \n",
      "Found embeddings for 85.87% of vocab\n",
      "Found embeddings for  99.76% of all text\n"
     ]
    }
   ],
   "source": [
    "combined_df['processed_review'] = combined_df['processed_review'].progress_apply(lambda x: re.sub('[0-9]+', '', x))\n",
    "vocab = build_vocab(combined_df['processed_review'])\n",
    "\n",
    "print(\"\\nGlove : \")\n",
    "oov_glove = check_coverage(vocab, glove_embeddings_index)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "oov_paragram = check_coverage(vocab, para_embeddings_index)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "oov_fasttext = check_coverage(vocab, fasttext_embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746deb9",
   "metadata": {
    "papermill": {
     "duration": 3.403837,
     "end_time": "2021-08-04T12:23:33.120985",
     "exception": false,
     "start_time": "2021-08-04T12:23:29.717148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f800e407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:23:39.767268Z",
     "iopub.status.busy": "2021-08-04T12:23:39.766245Z",
     "iopub.status.idle": "2021-08-04T12:24:00.420331Z",
     "shell.execute_reply": "2021-08-04T12:24:00.419763Z",
     "shell.execute_reply.started": "2021-08-04T11:36:09.338049Z"
    },
    "papermill": {
     "duration": 24.004247,
     "end_time": "2021-08-04T12:24:00.420548",
     "exception": false,
     "start_time": "2021-08-04T12:23:36.416301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [00:03<00:00, 18752.58it/s]\n",
      "100%|██████████| 62995/62995 [00:13<00:00, 4751.17it/s]\n",
      "100%|██████████| 62995/62995 [00:02<00:00, 29182.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove : \n",
      "Found embeddings for 95.77% of vocab\n",
      "Found embeddings for  99.93% of all text\n",
      "\n",
      "Paragram : \n",
      "Found embeddings for 99.40% of vocab\n",
      "Found embeddings for  99.99% of all text\n",
      "\n",
      "FastText : \n",
      "Found embeddings for 86.38% of vocab\n",
      "Found embeddings for  99.76% of all text\n"
     ]
    }
   ],
   "source": [
    "# Remove double spaces\n",
    "combined_df['processed_review'] = combined_df['processed_review'].progress_apply(lambda x: re.sub('\\s+',  ' ', x))\n",
    "\n",
    "# Remove repetitive characters\n",
    "combined_df['processed_review'] = combined_df['processed_review'].progress_apply(lambda x: ''.join(''.join(s)[:2] for _, s in itertools.groupby(x)))\n",
    "\n",
    "vocab = build_vocab(combined_df['processed_review'])\n",
    "\n",
    "print(\"\\nGlove : \")\n",
    "oov_glove = check_coverage(vocab, glove_embeddings_index)\n",
    "\n",
    "print(\"\\nParagram : \")\n",
    "oov_paragram = check_coverage(vocab, para_embeddings_index)\n",
    "\n",
    "print(\"\\nFastText : \")\n",
    "oov_fasttext = check_coverage(vocab, fasttext_embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef8dae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:24:07.373557Z",
     "iopub.status.busy": "2021-08-04T12:24:07.372780Z",
     "iopub.status.idle": "2021-08-04T12:24:07.376718Z",
     "shell.execute_reply": "2021-08-04T12:24:07.376094Z",
     "shell.execute_reply.started": "2021-08-04T11:36:29.766696Z"
    },
    "papermill": {
     "duration": 3.507375,
     "end_time": "2021-08-04T12:24:07.376866",
     "exception": false,
     "start_time": "2021-08-04T12:24:03.869491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 62995 \n",
      "MAX_LEN: 1840\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = combined_df['Review_num_words'].max() + 1\n",
    "text_list = combined_df['processed_review'].tolist()\n",
    "print(f\"Total number of reviews: {len(text_list)} \\nMAX_LEN: {MAX_LEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036471ac",
   "metadata": {
    "papermill": {
     "duration": 3.494407,
     "end_time": "2021-08-04T12:24:14.237830",
     "exception": false,
     "start_time": "2021-08-04T12:24:10.743423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17977896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:24:20.996455Z",
     "iopub.status.busy": "2021-08-04T12:24:20.995690Z",
     "iopub.status.idle": "2021-08-04T12:24:20.998380Z",
     "shell.execute_reply": "2021-08-04T12:24:20.997725Z",
     "shell.execute_reply.started": "2021-08-04T11:36:44.865709Z"
    },
    "papermill": {
     "duration": 3.417202,
     "end_time": "2021-08-04T12:24:20.998538",
     "exception": false,
     "start_time": "2021-08-04T12:24:17.581336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sent2vec(text, embeddings_index):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    \n",
    "    M = []\n",
    "    for w in words:\n",
    "        wn_token = wordninja.split(w)\n",
    "        \n",
    "        if len(wn_token) > 1:\n",
    "            for token in wn_token:\n",
    "                try:\n",
    "                    M.append(embeddings_index[token])\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        else:\n",
    "            try:\n",
    "                M.append(embeddings_index[w])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    \n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7922518b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:24:27.784400Z",
     "iopub.status.busy": "2021-08-04T12:24:27.783727Z",
     "iopub.status.idle": "2021-08-04T12:29:43.151721Z",
     "shell.execute_reply": "2021-08-04T12:29:43.151181Z",
     "shell.execute_reply.started": "2021-08-04T11:36:47.417553Z"
    },
    "papermill": {
     "duration": 318.809796,
     "end_time": "2021-08-04T12:29:43.151912",
     "exception": false,
     "start_time": "2021-08-04T12:24:24.342116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [05:14<00:00, 200.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_vec_df: (62995, 300)\n",
      "combined_df: (62995, 328)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_num_words</th>\n",
       "      <th>Review_num_unique_words</th>\n",
       "      <th>Review_num_chars</th>\n",
       "      <th>Review_num_stopwords</th>\n",
       "      <th>Review_num_@</th>\n",
       "      <th>Review_num_#</th>\n",
       "      <th>Review_num_urls</th>\n",
       "      <th>Review_num_tags</th>\n",
       "      <th>Review_num_punctuations</th>\n",
       "      <th>...</th>\n",
       "      <th>glove_290</th>\n",
       "      <th>glove_291</th>\n",
       "      <th>glove_292</th>\n",
       "      <th>glove_293</th>\n",
       "      <th>glove_294</th>\n",
       "      <th>glove_295</th>\n",
       "      <th>glove_296</th>\n",
       "      <th>glove_297</th>\n",
       "      <th>glove_298</th>\n",
       "      <th>glove_299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39467</th>\n",
       "      <td>Today I'm working on my &amp;quot;Quirky Q&amp;quot; c...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025311</td>\n",
       "      <td>-0.029377</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>-0.036219</td>\n",
       "      <td>0.060338</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>-0.010671</td>\n",
       "      <td>-0.003606</td>\n",
       "      <td>0.027269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>@ShannonElizab dont ya know? people love the h...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030972</td>\n",
       "      <td>-0.020399</td>\n",
       "      <td>-0.036216</td>\n",
       "      <td>-0.057353</td>\n",
       "      <td>0.076628</td>\n",
       "      <td>0.018635</td>\n",
       "      <td>-0.047100</td>\n",
       "      <td>-0.008823</td>\n",
       "      <td>-0.033038</td>\n",
       "      <td>0.018111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>ughhh rejected from the 09 mediation program. ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083348</td>\n",
       "      <td>-0.017254</td>\n",
       "      <td>0.028144</td>\n",
       "      <td>-0.019560</td>\n",
       "      <td>0.045730</td>\n",
       "      <td>-0.055121</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>-0.003762</td>\n",
       "      <td>-0.025701</td>\n",
       "      <td>0.018935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>@petewentz im so jealous. i want an octo drive</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013177</td>\n",
       "      <td>-0.032647</td>\n",
       "      <td>-0.010192</td>\n",
       "      <td>-0.053474</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.016696</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>I remember all the hype around this movie when...</td>\n",
       "      <td>574</td>\n",
       "      <td>339</td>\n",
       "      <td>3190</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057244</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>-0.008276</td>\n",
       "      <td>-0.028325</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>-0.018981</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.019957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Review_num_words  \\\n",
       "ID                                                                           \n",
       "39467  Today I'm working on my &quot;Quirky Q&quot; c...                15   \n",
       "30154  @ShannonElizab dont ya know? people love the h...                 9   \n",
       "16767  ughhh rejected from the 09 mediation program. ...                 8   \n",
       "9334      @petewentz im so jealous. i want an octo drive                 9   \n",
       "61178  I remember all the hype around this movie when...               574   \n",
       "\n",
       "       Review_num_unique_words  Review_num_chars  Review_num_stopwords  \\\n",
       "ID                                                                       \n",
       "39467                       15                83                     6   \n",
       "30154                        9                58                     1   \n",
       "16767                        8                55                     2   \n",
       "9334                         9                46                     3   \n",
       "61178                      339              3190                   272   \n",
       "\n",
       "       Review_num_@  Review_num_#  Review_num_urls  Review_num_tags  \\\n",
       "ID                                                                    \n",
       "39467             0             0                0                0   \n",
       "30154             1             0                0                0   \n",
       "16767             0             0                0                0   \n",
       "9334              1             0                0                0   \n",
       "61178             0             0                0               18   \n",
       "\n",
       "       Review_num_punctuations  ...  glove_290  glove_291  glove_292  \\\n",
       "ID                              ...                                    \n",
       "39467                        5  ...  -0.025311  -0.029377   0.012820   \n",
       "30154                        2  ...  -0.030972  -0.020399  -0.036216   \n",
       "16767                        2  ...   0.083348  -0.017254   0.028144   \n",
       "9334                         2  ...   0.013177  -0.032647  -0.010192   \n",
       "61178                      152  ...  -0.057244   0.004598  -0.008276   \n",
       "\n",
       "       glove_293  glove_294  glove_295  glove_296  glove_297  glove_298  \\\n",
       "ID                                                                        \n",
       "39467  -0.036219   0.060338  -0.000761   0.012377  -0.010671  -0.003606   \n",
       "30154  -0.057353   0.076628   0.018635  -0.047100  -0.008823  -0.033038   \n",
       "16767  -0.019560   0.045730  -0.055121   0.023674  -0.003762  -0.025701   \n",
       "9334   -0.053474   0.104402   0.003210   0.013642   0.016696   0.031464   \n",
       "61178  -0.028325   0.014552   0.007510  -0.018981  -0.003701   0.003828   \n",
       "\n",
       "       glove_299  \n",
       "ID                \n",
       "39467   0.027269  \n",
       "30154   0.018111  \n",
       "16767   0.018935  \n",
       "9334    0.000176  \n",
       "61178   0.019957  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vec = [sent2vec(x, glove_embeddings_index) for x in tqdm(combined_df[\"processed_review\"].values)]\n",
    "col_list = ['glove_'+str(i) for i in range(300)]\n",
    "glove_vec_df = pd.DataFrame(np.array(glove_vec), columns=col_list, index=combined_df.index)\n",
    "print(f\"glove_vec_df: {glove_vec_df.shape}\")\n",
    "\n",
    "combined_df = pd.merge(combined_df, glove_vec_df, \n",
    "                       how=\"inner\", on=\"ID\", sort=False)\n",
    "\n",
    "del glove_vec, glove_vec_df\n",
    "gc.collect()\n",
    "\n",
    "print(f\"combined_df: {combined_df.shape}\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ccdffdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:29:51.535930Z",
     "iopub.status.busy": "2021-08-04T12:29:51.535177Z",
     "iopub.status.idle": "2021-08-04T12:35:07.613026Z",
     "shell.execute_reply": "2021-08-04T12:35:07.613517Z",
     "shell.execute_reply.started": "2021-08-04T11:41:31.383003Z"
    },
    "papermill": {
     "duration": 320.26907,
     "end_time": "2021-08-04T12:35:07.613724",
     "exception": false,
     "start_time": "2021-08-04T12:29:47.344654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [05:14<00:00, 200.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext_vec_df: (62995, 300)\n",
      "combined_df: (62995, 628)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_num_words</th>\n",
       "      <th>Review_num_unique_words</th>\n",
       "      <th>Review_num_chars</th>\n",
       "      <th>Review_num_stopwords</th>\n",
       "      <th>Review_num_@</th>\n",
       "      <th>Review_num_#</th>\n",
       "      <th>Review_num_urls</th>\n",
       "      <th>Review_num_tags</th>\n",
       "      <th>Review_num_punctuations</th>\n",
       "      <th>...</th>\n",
       "      <th>fasttext_290</th>\n",
       "      <th>fasttext_291</th>\n",
       "      <th>fasttext_292</th>\n",
       "      <th>fasttext_293</th>\n",
       "      <th>fasttext_294</th>\n",
       "      <th>fasttext_295</th>\n",
       "      <th>fasttext_296</th>\n",
       "      <th>fasttext_297</th>\n",
       "      <th>fasttext_298</th>\n",
       "      <th>fasttext_299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39467</th>\n",
       "      <td>Today I'm working on my &amp;quot;Quirky Q&amp;quot; c...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048533</td>\n",
       "      <td>-0.011358</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>-0.010735</td>\n",
       "      <td>-0.015227</td>\n",
       "      <td>-0.024497</td>\n",
       "      <td>0.106152</td>\n",
       "      <td>0.070438</td>\n",
       "      <td>-0.026371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>@ShannonElizab dont ya know? people love the h...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>-0.024766</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>-0.019488</td>\n",
       "      <td>0.069116</td>\n",
       "      <td>-0.015891</td>\n",
       "      <td>0.021862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>ughhh rejected from the 09 mediation program. ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>-0.035302</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.035808</td>\n",
       "      <td>-0.039154</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>0.103939</td>\n",
       "      <td>-0.011758</td>\n",
       "      <td>-0.010508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>@petewentz im so jealous. i want an octo drive</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>-0.005114</td>\n",
       "      <td>-0.009848</td>\n",
       "      <td>0.050676</td>\n",
       "      <td>0.040232</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>-0.053034</td>\n",
       "      <td>0.069739</td>\n",
       "      <td>0.047785</td>\n",
       "      <td>-0.008926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>I remember all the hype around this movie when...</td>\n",
       "      <td>574</td>\n",
       "      <td>339</td>\n",
       "      <td>3190</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>-0.011245</td>\n",
       "      <td>-0.000872</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>-0.019694</td>\n",
       "      <td>0.120882</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>-0.008850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Review_num_words  \\\n",
       "ID                                                                           \n",
       "39467  Today I'm working on my &quot;Quirky Q&quot; c...                15   \n",
       "30154  @ShannonElizab dont ya know? people love the h...                 9   \n",
       "16767  ughhh rejected from the 09 mediation program. ...                 8   \n",
       "9334      @petewentz im so jealous. i want an octo drive                 9   \n",
       "61178  I remember all the hype around this movie when...               574   \n",
       "\n",
       "       Review_num_unique_words  Review_num_chars  Review_num_stopwords  \\\n",
       "ID                                                                       \n",
       "39467                       15                83                     6   \n",
       "30154                        9                58                     1   \n",
       "16767                        8                55                     2   \n",
       "9334                         9                46                     3   \n",
       "61178                      339              3190                   272   \n",
       "\n",
       "       Review_num_@  Review_num_#  Review_num_urls  Review_num_tags  \\\n",
       "ID                                                                    \n",
       "39467             0             0                0                0   \n",
       "30154             1             0                0                0   \n",
       "16767             0             0                0                0   \n",
       "9334              1             0                0                0   \n",
       "61178             0             0                0               18   \n",
       "\n",
       "       Review_num_punctuations  ...  fasttext_290  fasttext_291  fasttext_292  \\\n",
       "ID                              ...                                             \n",
       "39467                        5  ...      0.048533     -0.011358      0.009693   \n",
       "30154                        2  ...      0.015877     -0.024766     -0.002248   \n",
       "16767                        2  ...     -0.005525     -0.035302      0.007879   \n",
       "9334                         2  ...      0.027068     -0.005114     -0.009848   \n",
       "61178                      152  ...      0.005544     -0.011245     -0.000872   \n",
       "\n",
       "       fasttext_293  fasttext_294  fasttext_295  fasttext_296  fasttext_297  \\\n",
       "ID                                                                            \n",
       "39467     -0.001183     -0.010735     -0.015227     -0.024497      0.106152   \n",
       "30154      0.031481      0.024051      0.019621     -0.019488      0.069116   \n",
       "16767      0.035808     -0.039154      0.014443      0.018690      0.103939   \n",
       "9334       0.050676      0.040232      0.009613     -0.053034      0.069739   \n",
       "61178     -0.001933      0.005125      0.002126     -0.019694      0.120882   \n",
       "\n",
       "       fasttext_298  fasttext_299  \n",
       "ID                                 \n",
       "39467      0.070438     -0.026371  \n",
       "30154     -0.015891      0.021862  \n",
       "16767     -0.011758     -0.010508  \n",
       "9334       0.047785     -0.008926  \n",
       "61178      0.013285     -0.008850  \n",
       "\n",
       "[5 rows x 628 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_vec = [sent2vec(x, fasttext_embeddings_index) for x in tqdm(combined_df[\"processed_review\"].values)]\n",
    "col_list = ['fasttext_'+str(i) for i in range(300)]\n",
    "fasttext_vec_df = pd.DataFrame(np.array(fasttext_vec), columns=col_list, index=combined_df.index)\n",
    "print(f\"fasttext_vec_df: {fasttext_vec_df.shape}\")\n",
    "\n",
    "combined_df = pd.merge(combined_df, fasttext_vec_df, \n",
    "                       how=\"inner\", on=\"ID\", sort=False)\n",
    "\n",
    "del fasttext_vec, fasttext_vec_df\n",
    "gc.collect()\n",
    "\n",
    "print(f\"combined_df: {combined_df.shape}\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a302896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:35:17.606973Z",
     "iopub.status.busy": "2021-08-04T12:35:17.606243Z",
     "iopub.status.idle": "2021-08-04T12:40:42.029296Z",
     "shell.execute_reply": "2021-08-04T12:40:42.028664Z",
     "shell.execute_reply.started": "2021-08-04T11:46:18.561394Z"
    },
    "papermill": {
     "duration": 329.430504,
     "end_time": "2021-08-04T12:40:42.029483",
     "exception": false,
     "start_time": "2021-08-04T12:35:12.598979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62995/62995 [05:13<00:00, 200.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para_vec_df: (62995, 300)\n",
      "combined_df: (62995, 926)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_num_words</th>\n",
       "      <th>Review_num_unique_words</th>\n",
       "      <th>Review_num_chars</th>\n",
       "      <th>Review_num_stopwords</th>\n",
       "      <th>Review_num_@</th>\n",
       "      <th>Review_num_#</th>\n",
       "      <th>Review_num_urls</th>\n",
       "      <th>Review_num_tags</th>\n",
       "      <th>Review_num_punctuations</th>\n",
       "      <th>Review_num_words_upper</th>\n",
       "      <th>...</th>\n",
       "      <th>para_290</th>\n",
       "      <th>para_291</th>\n",
       "      <th>para_292</th>\n",
       "      <th>para_293</th>\n",
       "      <th>para_294</th>\n",
       "      <th>para_295</th>\n",
       "      <th>para_296</th>\n",
       "      <th>para_297</th>\n",
       "      <th>para_298</th>\n",
       "      <th>para_299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39467</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>-0.005075</td>\n",
       "      <td>0.045606</td>\n",
       "      <td>-0.006415</td>\n",
       "      <td>0.120375</td>\n",
       "      <td>-0.040410</td>\n",
       "      <td>0.051157</td>\n",
       "      <td>-0.070714</td>\n",
       "      <td>-0.016637</td>\n",
       "      <td>0.049064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015699</td>\n",
       "      <td>-0.012129</td>\n",
       "      <td>-0.013994</td>\n",
       "      <td>-0.077154</td>\n",
       "      <td>0.160594</td>\n",
       "      <td>-0.003633</td>\n",
       "      <td>-0.064221</td>\n",
       "      <td>-0.074613</td>\n",
       "      <td>-0.030375</td>\n",
       "      <td>0.017418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16767</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>-0.007336</td>\n",
       "      <td>0.037052</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>0.084572</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>-0.061503</td>\n",
       "      <td>0.047610</td>\n",
       "      <td>0.080746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>-0.031743</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>-0.050673</td>\n",
       "      <td>0.086777</td>\n",
       "      <td>0.026475</td>\n",
       "      <td>0.023857</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.059255</td>\n",
       "      <td>0.029460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>574</td>\n",
       "      <td>339</td>\n",
       "      <td>3190</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>-0.020648</td>\n",
       "      <td>-0.030807</td>\n",
       "      <td>0.109541</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>-0.068012</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>0.033139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 926 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review_num_words  Review_num_unique_words  Review_num_chars  \\\n",
       "ID                                                                   \n",
       "39467                15                       15                83   \n",
       "30154                 9                        9                58   \n",
       "16767                 8                        8                55   \n",
       "9334                  9                        9                46   \n",
       "61178               574                      339              3190   \n",
       "\n",
       "       Review_num_stopwords  Review_num_@  Review_num_#  Review_num_urls  \\\n",
       "ID                                                                         \n",
       "39467                     6             0             0                0   \n",
       "30154                     1             1             0                0   \n",
       "16767                     2             0             0                0   \n",
       "9334                      3             1             0                0   \n",
       "61178                   272             0             0                0   \n",
       "\n",
       "       Review_num_tags  Review_num_punctuations  Review_num_words_upper  ...  \\\n",
       "ID                                                                       ...   \n",
       "39467                0                        5                       0  ...   \n",
       "30154                0                        2                       0  ...   \n",
       "16767                0                        2                       1  ...   \n",
       "9334                 0                        2                       0  ...   \n",
       "61178               18                      152                       8  ...   \n",
       "\n",
       "       para_290  para_291  para_292  para_293  para_294  para_295  para_296  \\\n",
       "ID                                                                            \n",
       "39467  0.060111 -0.005075  0.045606 -0.006415  0.120375 -0.040410  0.051157   \n",
       "30154  0.015699 -0.012129 -0.013994 -0.077154  0.160594 -0.003633 -0.064221   \n",
       "16767  0.154424 -0.007336  0.037052 -0.003967  0.084572  0.002754  0.066411   \n",
       "9334   0.002801 -0.031743  0.002923 -0.050673  0.086777  0.026475  0.023857   \n",
       "61178  0.006492  0.003607 -0.020648 -0.030807  0.109541  0.022207  0.012477   \n",
       "\n",
       "       para_297  para_298  para_299  \n",
       "ID                                   \n",
       "39467 -0.070714 -0.016637  0.049064  \n",
       "30154 -0.074613 -0.030375  0.017418  \n",
       "16767 -0.061503  0.047610  0.080746  \n",
       "9334   0.009329  0.059255  0.029460  \n",
       "61178 -0.068012  0.013718  0.033139  \n",
       "\n",
       "[5 rows x 926 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_vec = [sent2vec(x, para_embeddings_index) for x in tqdm(combined_df[\"processed_review\"].values)]\n",
    "col_list = ['para_'+str(i) for i in range(300)]\n",
    "para_vec_df = pd.DataFrame(np.array(para_vec), columns=col_list, index=combined_df.index)\n",
    "print(f\"para_vec_df: {para_vec_df.shape}\")\n",
    "\n",
    "combined_df = pd.merge(combined_df, para_vec_df, \n",
    "                       how=\"inner\", on=\"ID\", sort=False)\n",
    "\n",
    "del para_vec, para_vec_df\n",
    "gc.collect()\n",
    "\n",
    "combined_df.drop(['Review','processed_review'], axis=1, inplace=True)\n",
    "print(f\"combined_df: {combined_df.shape}\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d609fcf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:40:53.691973Z",
     "iopub.status.busy": "2021-08-04T12:40:53.691264Z",
     "iopub.status.idle": "2021-08-04T12:40:54.188503Z",
     "shell.execute_reply": "2021-08-04T12:40:54.188962Z",
     "shell.execute_reply.started": "2021-08-04T11:51:39.113287Z"
    },
    "papermill": {
     "duration": 6.363938,
     "end_time": "2021-08-04T12:40:54.189179",
     "exception": false,
     "start_time": "2021-08-04T12:40:47.825241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain: (44095, 926) \n",
      "Xtest: (18900, 926)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = combined_df[:Ytrain.shape[0]].copy()\n",
    "Xtest = combined_df[Ytrain.shape[0]:].copy()\n",
    "print(f\"Xtrain: {Xtrain.shape} \\nXtest: {Xtest.shape}\")\n",
    "\n",
    "del combined_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891500f",
   "metadata": {
    "papermill": {
     "duration": 5.876607,
     "end_time": "2021-08-04T12:41:05.807195",
     "exception": false,
     "start_time": "2021-08-04T12:40:59.930588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate word sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c41ecd3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:41:17.229218Z",
     "iopub.status.busy": "2021-08-04T12:41:17.228151Z",
     "iopub.status.idle": "2021-08-04T12:41:17.231100Z",
     "shell.execute_reply": "2021-08-04T12:41:17.230588Z",
     "shell.execute_reply.started": "2021-08-04T11:51:41.287889Z"
    },
    "papermill": {
     "duration": 5.762877,
     "end_time": "2021-08-04T12:41:17.231258",
     "exception": false,
     "start_time": "2021-08-04T12:41:11.468381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    wordnet_map = {\n",
    "        \"N\": wordnet.NOUN, \n",
    "        \"V\": wordnet.VERB, \n",
    "        \"J\": wordnet.ADJ, \n",
    "        \"R\": wordnet.ADV\n",
    "    }\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2dd5e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:41:28.758716Z",
     "iopub.status.busy": "2021-08-04T12:41:28.757728Z",
     "iopub.status.idle": "2021-08-04T12:41:39.107373Z",
     "shell.execute_reply": "2021-08-04T12:41:39.106710Z",
     "shell.execute_reply.started": "2021-08-04T11:51:42.577600Z"
    },
    "papermill": {
     "duration": 16.169665,
     "end_time": "2021-08-04T12:41:39.107542",
     "exception": false,
     "start_time": "2021-08-04T12:41:22.937877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', disable=['parser','ner','tagger'])\n",
    "nlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\n",
    "docs = nlp.pipe(text_list, n_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "505c42e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:41:50.527343Z",
     "iopub.status.busy": "2021-08-04T12:41:50.526526Z",
     "iopub.status.idle": "2021-08-04T12:42:50.180958Z",
     "shell.execute_reply": "2021-08-04T12:42:50.180043Z",
     "shell.execute_reply.started": "2021-08-04T11:52:11.167668Z"
    },
    "papermill": {
     "duration": 65.388662,
     "end_time": "2021-08-04T12:42:50.181149",
     "exception": false,
     "start_time": "2021-08-04T12:41:44.792487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62995it [00:59, 1063.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {}\n",
    "word_index = 1\n",
    "lemma_dict = {}\n",
    "word_sequences = []\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "    word_seq = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.text not in word_dict) and (token.pos_ is not \"PUNCT\"):\n",
    "            word_dict[token.text] = word_index\n",
    "            word_index += 1\n",
    "            lemma_dict[token.text] = token.lemma_\n",
    "            \n",
    "        if token.pos_ is not \"PUNCT\":\n",
    "            word_seq.append(word_dict[token.text])\n",
    "            \n",
    "    word_sequences.append(word_seq)\n",
    "\n",
    "del docs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ba93b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:43:02.005172Z",
     "iopub.status.busy": "2021-08-04T12:43:02.004431Z",
     "iopub.status.idle": "2021-08-04T12:43:04.960445Z",
     "shell.execute_reply": "2021-08-04T12:43:04.959431Z",
     "shell.execute_reply.started": "2021-08-04T11:53:30.375824Z"
    },
    "papermill": {
     "duration": 8.864063,
     "end_time": "2021-08-04T12:43:04.960614",
     "exception": false,
     "start_time": "2021-08-04T12:42:56.096551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_sequences = word_sequences[:Ytrain.shape[0]]\n",
    "test_word_sequences = word_sequences[Ytrain.shape[0]:]\n",
    "\n",
    "train_word_sequences = pad_sequences(train_word_sequences, maxlen=MAX_LEN, padding='post')\n",
    "test_word_sequences = pad_sequences(test_word_sequences, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "del word_sequences\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305a296",
   "metadata": {
    "papermill": {
     "duration": 5.897393,
     "end_time": "2021-08-04T12:43:16.774596",
     "exception": false,
     "start_time": "2021-08-04T12:43:10.877203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72a574a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:43:28.558681Z",
     "iopub.status.busy": "2021-08-04T12:43:28.554952Z",
     "iopub.status.idle": "2021-08-04T12:43:28.560573Z",
     "shell.execute_reply": "2021-08-04T12:43:28.561187Z",
     "shell.execute_reply.started": "2021-08-04T11:53:37.882829Z"
    },
    "papermill": {
     "duration": 5.916729,
     "end_time": "2021-08-04T12:43:28.561386",
     "exception": false,
     "start_time": "2021-08-04T12:43:22.644657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word_embeddings(word_dict, lemma_dict, embeddings_index):\n",
    "    embed_size = 300\n",
    "    nb_words = len(word_dict)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
    "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
    "    unknown_words = []\n",
    "    \n",
    "    for key in tqdm(word_dict):\n",
    "        word = key\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        \n",
    "        word = key.lower()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        \n",
    "        word = key.upper()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        \n",
    "        word = key.capitalize()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        \n",
    "        word = lemma_dict[key]\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        \n",
    "        embedding_matrix[word_dict[key]] = unknown_vector\n",
    "        unknown_words.append(key)\n",
    "        \n",
    "    return embedding_matrix, nb_words, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84ca3a97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:43:40.344204Z",
     "iopub.status.busy": "2021-08-04T12:43:40.343495Z",
     "iopub.status.idle": "2021-08-04T12:43:47.474737Z",
     "shell.execute_reply": "2021-08-04T12:43:47.474155Z",
     "shell.execute_reply.started": "2021-08-04T11:53:40.368149Z"
    },
    "papermill": {
     "duration": 13.124458,
     "end_time": "2021-08-04T12:43:47.474923",
     "exception": false,
     "start_time": "2021-08-04T12:43:34.350465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76543/76543 [00:00<00:00, 193293.01it/s]\n",
      "100%|██████████| 76543/76543 [00:00<00:00, 152685.20it/s]\n",
      "100%|██████████| 76543/76543 [00:00<00:00, 165476.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown words: 4918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix_glove, nb_words, unknown_words_glove = word_embeddings(word_dict, lemma_dict, glove_embeddings_index)\n",
    "embed_matrix_fasttext, nb_words, unknown_words_fasttext = word_embeddings(word_dict, lemma_dict, fasttext_embeddings_index)\n",
    "embed_matrix_para, nb_words, unknown_words_para = word_embeddings(word_dict, lemma_dict, para_embeddings_index)\n",
    "\n",
    "embedding_matrix1 = np.concatenate((embed_matrix_glove, embed_matrix_fasttext, embed_matrix_para), axis=1)\n",
    "embedding_matrix2 = (embed_matrix_glove * 0.7) + (embed_matrix_fasttext * 0.3)\n",
    "embedding_matrix3 = (embed_matrix_glove * 0.6) + (embed_matrix_para * 0.4)\n",
    "embedding_matrix4 = (embed_matrix_glove * 0.4) + (embed_matrix_para * 0.4) + (embed_matrix_fasttext * 0.2)\n",
    "\n",
    "unknown_words = list(set(unknown_words_glove + unknown_words_fasttext + unknown_words_para))\n",
    "print(f\"Unknown words: {len(unknown_words)}\")\n",
    "\n",
    "del glove_embeddings_index, fasttext_embeddings_index, para_embeddings_index\n",
    "del embed_matrix_glove, embed_matrix_fasttext, embed_matrix_para\n",
    "del unknown_words_glove, unknown_words_fasttext, unknown_words_para\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8076b628",
   "metadata": {
    "papermill": {
     "duration": 5.903226,
     "end_time": "2021-08-04T12:43:59.287204",
     "exception": false,
     "start_time": "2021-08-04T12:43:53.383978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ba19892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:44:11.508132Z",
     "iopub.status.busy": "2021-08-04T12:44:11.507363Z",
     "iopub.status.idle": "2021-08-04T12:44:11.986914Z",
     "shell.execute_reply": "2021-08-04T12:44:11.987902Z",
     "shell.execute_reply.started": "2021-08-04T11:53:56.472638Z"
    },
    "papermill": {
     "duration": 6.61749,
     "end_time": "2021-08-04T12:44:11.988230",
     "exception": false,
     "start_time": "2021-08-04T12:44:05.370740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'train_word_sequences': train_word_sequences,\n",
    "    'test_word_sequences': test_word_sequences,\n",
    "    'nb_words': nb_words,\n",
    "    'MAX_LEN': MAX_LEN\n",
    "}\n",
    "\n",
    "file = open(\"./MH_New_Dawn_Set1.txt\", 'wb')\n",
    "pickle.dump(data_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a62075ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:44:24.044028Z",
     "iopub.status.busy": "2021-08-04T12:44:24.043238Z",
     "iopub.status.idle": "2021-08-04T12:44:24.803502Z",
     "shell.execute_reply": "2021-08-04T12:44:24.804506Z",
     "shell.execute_reply.started": "2021-08-04T11:53:59.522611Z"
    },
    "papermill": {
     "duration": 6.675438,
     "end_time": "2021-08-04T12:44:24.804834",
     "exception": false,
     "start_time": "2021-08-04T12:44:18.129396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Xtrain': Xtrain,\n",
    "    'Xtest': Xtest,\n",
    "    'Ytrain': Ytrain,\n",
    "    'Ytrain_oh': Ytrain_oh,\n",
    "    'class_weight': class_weight\n",
    "}\n",
    "\n",
    "file = open(\"./MH_New_Dawn_Set2.txt\", 'wb')\n",
    "pickle.dump(data_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d6f1847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T12:44:36.759340Z",
     "iopub.status.busy": "2021-08-04T12:44:36.758615Z",
     "iopub.status.idle": "2021-08-04T12:44:37.549691Z",
     "shell.execute_reply": "2021-08-04T12:44:37.550236Z",
     "shell.execute_reply.started": "2021-08-04T11:54:02.903109Z"
    },
    "papermill": {
     "duration": 6.725245,
     "end_time": "2021-08-04T12:44:37.550472",
     "exception": false,
     "start_time": "2021-08-04T12:44:30.825227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'embedding_matrix1': embedding_matrix1,\n",
    "    'embedding_matrix2': embedding_matrix2,\n",
    "    'embedding_matrix3': embedding_matrix3,\n",
    "    'embedding_matrix4': embedding_matrix4\n",
    "}\n",
    "\n",
    "file = open(\"./MH_New_Dawn_Set3.txt\", 'wb')\n",
    "pickle.dump(data_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c899096",
   "metadata": {
    "papermill": {
     "duration": 5.949604,
     "end_time": "2021-08-04T12:44:49.476177",
     "exception": false,
     "start_time": "2021-08-04T12:44:43.526573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3025.976069,
   "end_time": "2021-08-04T12:44:59.302983",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-04T11:54:33.326914",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
