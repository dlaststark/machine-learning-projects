{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss, f1_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import lightgbm as lgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set file paths for train and predict datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"Dataset/Train.csv\"\n",
    "predict_dataset = \"Dataset/Test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get train dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_dataset)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predict dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.read_csv(predict_dataset)\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count plot of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x=\"IsUnderRisk\", data=train_df).set_title('Count plot of \"IsUnderRisk\" data')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(train_df['IsUnderRisk'])\n",
    "total = neg + pos\n",
    "print('Total: {}\\n  Positive: {} ({:.2f}% of total)\\n  Negative: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total, neg, 100 * neg / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get correlation between different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "ax = sns.heatmap(train_df.corr(), annot=True, linewidth = 0.5, cmap='coolwarm', \n",
    "                 fmt='.1g', vmin=-1, vmax=1, center= 0, square=True)\n",
    "plt.show()\n",
    "#figure = ax.get_figure()    \n",
    "#figure.savefig('correlation_heatmap.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read train and predict datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (543, 8)\n",
      "predict_df: (233, 7)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_dataset)\n",
    "predict_df = pd.read_csv(predict_dataset)\n",
    "print(\"train_df: {}\".format(train_df.shape))\n",
    "print(\"predict_df: {}\".format(predict_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract \"IsUnderRisk\" field from train_df into NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: (543, 1)\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array([train_df['IsUnderRisk'].values]).T\n",
    "train_df.drop(['IsUnderRisk'], inplace=True, axis=1)\n",
    "print(\"train_y: {}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(776, 7)\n"
     ]
    }
   ],
   "source": [
    "# Combine train and predict dataframes\n",
    "combined_df = train_df.append(predict_df, sort=False, ignore_index=True)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation of all score values\n",
    "combined_df['Location_Score_STD'] = np.std(combined_df['Location_Score'])\n",
    "combined_df['Internal_Audit_Score_STD'] = np.std(combined_df['Internal_Audit_Score'])\n",
    "combined_df['External_Audit_Score_STD'] = np.std(combined_df['External_Audit_Score'])\n",
    "combined_df['Fin_Score_STD'] = np.std(combined_df['Fin_Score'])\n",
    "combined_df['Loss_score_STD'] = np.std(combined_df['Loss_score'])\n",
    "combined_df['Past_Results_STD'] = np.std(combined_df['Past_Results'])\n",
    "\n",
    "# Binning\n",
    "combined_df['Past_Results_bin'] = combined_df['Past_Results'].apply(lambda x: \"[0-2]\" if 0<=x<2 else \"[2-4]\" if 2<=x<4 else \"[4-10]\")\n",
    "combined_df['Loss_Score_bin'] = combined_df['Loss_score'].apply(lambda x: \"[0-5]\" if 0<=x<5 else \"[5-9]\" if 5<=x<9 else \"[9-15]\")\n",
    "\n",
    "# One-hot encoding\n",
    "one_hot = pd.get_dummies(combined_df['City'])\n",
    "combined_df.drop('City', axis = 1, inplace=True)\n",
    "combined_df = combined_df.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(combined_df['Past_Results_bin'])\n",
    "combined_df.drop('Past_Results_bin', axis = 1, inplace=True)\n",
    "combined_df = combined_df.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(combined_df['Loss_Score_bin'])\n",
    "combined_df.drop('Loss_Score_bin', axis = 1, inplace=True)\n",
    "combined_df = combined_df.join(one_hot)\n",
    "\n",
    "# Convert all scores to log scale\n",
    "combined_df['Location_Score'] = np.log1p(combined_df['Location_Score'])\n",
    "combined_df['Internal_Audit_Score'] = np.log1p(combined_df['Internal_Audit_Score'])\n",
    "combined_df['External_Audit_Score'] = np.log1p(combined_df['External_Audit_Score'])\n",
    "combined_df['Fin_Score'] = np.log1p(combined_df['Fin_Score'])\n",
    "combined_df['Loss_score'] = np.log1p(combined_df['Loss_score'])\n",
    "combined_df['Past_Results'] = np.log1p(combined_df['Past_Results'])\n",
    "\n",
    "# Get difference and mean of different scores\n",
    "combined_df[\"Audit_Score_Diff\"] = np.power(combined_df[\"Internal_Audit_Score\"] - combined_df[\"External_Audit_Score\"], 2)\n",
    "combined_df[\"Average_Audit_Score\"] = (combined_df[\"Internal_Audit_Score\"] + combined_df[\"External_Audit_Score\"]) / 2\n",
    "combined_df[\"Score_diff1\"] = np.power(combined_df[\"Fin_Score\"] - combined_df[\"Loss_score\"], 2)\n",
    "combined_df[\"Score_diff2\"] = np.power(combined_df[\"Fin_Score\"] - combined_df[\"Average_Audit_Score\"], 2)\n",
    "combined_df[\"Score_diff3\"] = np.power(combined_df[\"Loss_score\"] - combined_df[\"Average_Audit_Score\"], 2)\n",
    "combined_df[\"Cumulative_Score\"] = (combined_df['Location_Score'] + combined_df[\"Internal_Audit_Score\"] + combined_df[\"External_Audit_Score\"] + combined_df[\"Fin_Score\"] + combined_df[\"Loss_score\"]) / 5\n",
    "\n",
    "# Calculate different score ratios\n",
    "combined_df[\"Fin_Score/Average_Audit_Score\"] = combined_df[\"Fin_Score\"] / combined_df[\"Average_Audit_Score\"]\n",
    "combined_df[\"Loss_score/Average_Audit_Score\"] = combined_df[\"Loss_score\"] / combined_df[\"Average_Audit_Score\"]\n",
    "combined_df[\"Loss_score/Fin_Score\"] = combined_df[\"Loss_score\"] / combined_df[\"Fin_Score\"]\n",
    "combined_df[\"Fin_Score/Location_Score\"] = combined_df[\"Fin_Score\"] / combined_df[\"Location_Score\"]\n",
    "combined_df[\"Loss_score/Location_Score\"] = combined_df[\"Loss_score\"] / combined_df[\"Location_Score\"]\n",
    "combined_df[\"Average_Audit_Score/Location_Score\"] = combined_df[\"Average_Audit_Score\"] / combined_df[\"Location_Score\"]\n",
    "combined_df[\"Past_Results/Location_Score\"] = combined_df[\"Past_Results\"] / combined_df[\"Location_Score\"]\n",
    "\n",
    "# Box-cox transformation\n",
    "_, opt_lambda = boxcox(combined_df[\"Location_Score\"])\n",
    "combined_df['Location_boxcox_lambda_0'] = boxcox((1+combined_df['Location_Score']), lmbda=0)\n",
    "combined_df['Location_boxcox_lambda_opt'] = boxcox(combined_df['Location_Score'], lmbda=opt_lambda)\n",
    "\n",
    "_, opt_lambda = boxcox(combined_df[\"Internal_Audit_Score\"])\n",
    "combined_df['IAS_boxcox_lambda_0'] = boxcox((1+combined_df['Internal_Audit_Score']), lmbda=0)\n",
    "combined_df['IAS_boxcox_lambda_opt'] = boxcox(combined_df['Internal_Audit_Score'], lmbda=opt_lambda)\n",
    "\n",
    "_, opt_lambda = boxcox(combined_df[\"External_Audit_Score\"])\n",
    "combined_df['EAS_boxcox_lambda_0'] = boxcox((1+combined_df['External_Audit_Score']), lmbda=0)\n",
    "combined_df['EAS_boxcox_lambda_opt'] = boxcox(combined_df['External_Audit_Score'], lmbda=opt_lambda)\n",
    "\n",
    "_, opt_lambda = boxcox(combined_df[\"Fin_Score\"])\n",
    "combined_df['Fin_boxcox_lambda_0'] = boxcox((1+combined_df['Fin_Score']), lmbda=0)\n",
    "combined_df['Fin_boxcox_lambda_opt'] = boxcox(combined_df['Fin_Score'], lmbda=opt_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train and predict Numpy arrays and scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x: (543, 84)\n",
      "predict_x: (233, 84)\n"
     ]
    }
   ],
   "source": [
    "# Segregate combined_df into train/predict datasets\n",
    "train_x = combined_df[:543]\n",
    "predict_x = combined_df[543:]\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"predict_x: {}\".format(predict_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the train_x/predict_x arrays\n",
    "scaler = MinMaxScaler().fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "predict_x = scaler.transform(predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_full = train_x.copy()\n",
    "train_y_full = train_y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training data into train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "train_x shape: (491, 84)\n",
      "train_y shape: (491, 1)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "test_x shape: (52, 84)\n",
      "test_y shape: (52, 1)\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.095, random_state=1)\n",
    "for train_index, test_index in sss.split(train_x, train_y):\n",
    "    train_x, test_x = train_x[train_index], train_x[test_index]\n",
    "    train_y, test_y = train_y[train_index], train_y[test_index]\n",
    "\n",
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"train_x shape: {}\".format(train_x.shape))\n",
    "print(\"train_y shape: {}\".format(train_y.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"test_x shape: {}\".format(test_x.shape))\n",
    "print(\"test_y shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "Xtrain_full shape: (543, 84)\n",
      "Ytrain_full shape: (543, 1)\n",
      "Xtrain shape: (491, 84)\n",
      "Ytrain shape: (491, 1)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "Xtest shape: (52, 84)\n",
      "Ytest shape: (52, 1)\n",
      "\n",
      "------------------------- Prediction Dataset -------------------------\n",
      "Xpredict shape: (233, 84)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_full, Ytrain_full = train_x_full.copy(), train_y_full.copy()\n",
    "Xtrain, Ytrain = train_x.copy(), train_y.copy()\n",
    "Xtest, Ytest = test_x.copy(), test_y.copy()\n",
    "Xpredict = predict_x.copy()\n",
    "\n",
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"Xtrain_full shape: {}\".format(Xtrain_full.shape))\n",
    "print(\"Ytrain_full shape: {}\".format(Ytrain_full.shape))\n",
    "print(\"Xtrain shape: {}\".format(Xtrain.shape))\n",
    "print(\"Ytrain shape: {}\".format(Ytrain.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"Xtest shape: {}\".format(Xtest.shape))\n",
    "print(\"Ytest shape: {}\".format(Ytest.shape))\n",
    "\n",
    "print(\"\\n------------------------- Prediction Dataset -------------------------\")\n",
    "print(\"Xpredict shape: {}\".format(Xpredict.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Ytest to one-hot encoding\n",
    "df = pd.DataFrame(Ytest, columns=[\"IsUnderRisk\"])\n",
    "test_y = pd.get_dummies(df['IsUnderRisk']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"num_class\": 2,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"is_unbalance\": True,\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-2, 1e-1),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-4, 1.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 35, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 25),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 5, 20),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 20),\n",
    "    }\n",
    "    \n",
    "    y_pred = 0\n",
    "    counter = 0\n",
    "    for train, val in kfold.split(Xtrain, Ytrain):\n",
    "        counter += 1\n",
    "    \n",
    "        train_x, train_y = Xtrain[train], Ytrain[train]\n",
    "        val_x, val_y = Xtrain[val], Ytrain[val]\n",
    "\n",
    "        lgtrain = lgb.Dataset(train_x, label=train_y.ravel())\n",
    "        lgvalidation = lgb.Dataset(val_x, label=val_y.ravel())\n",
    "\n",
    "        model = lgb.train(params, lgtrain, valid_sets=[lgvalidation], \n",
    "                          num_boost_round=5000, early_stopping_rounds=200, verbose_eval=False)\n",
    "        pred = model.predict(Xtest, num_iteration=model.best_iteration)\n",
    "\n",
    "        y_pred += pred\n",
    "\n",
    "    y_pred /= float(counter)\n",
    "    loss = log_loss(test_y, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-17 18:36:12,998] Finished trial#0 with value: 0.246493482372785 with parameters: {'learning_rate': 0.07195551211067949, 'lambda_l2': 0.24930400666346547, 'num_leaves': 167, 'max_depth': 23, 'feature_fraction': 0.81893454182465, 'bagging_fraction': 0.8067354629805283, 'bagging_freq': 12, 'min_child_samples': 7}. Best is trial#0 with value: 0.246493482372785.\n",
      "[I 2020-05-17 18:36:15,543] Finished trial#1 with value: 0.3017543228884818 with parameters: {'learning_rate': 0.013501557739583881, 'lambda_l2': 0.0032146154741599328, 'num_leaves': 136, 'max_depth': 8, 'feature_fraction': 0.8247659930439812, 'bagging_fraction': 0.622483821439892, 'bagging_freq': 14, 'min_child_samples': 20}. Best is trial#0 with value: 0.246493482372785.\n",
      "[I 2020-05-17 18:36:24,543] Finished trial#2 with value: 0.22863513083938264 with parameters: {'learning_rate': 0.020022106734999004, 'lambda_l2': 0.18504421567002546, 'num_leaves': 186, 'max_depth': 11, 'feature_fraction': 0.8458746856011641, 'bagging_fraction': 0.6159463302219492, 'bagging_freq': 8, 'min_child_samples': 1}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:28,218] Finished trial#3 with value: 0.26648343053835405 with parameters: {'learning_rate': 0.021766183205498144, 'lambda_l2': 0.03027505597708032, 'num_leaves': 93, 'max_depth': 9, 'feature_fraction': 0.7077054651730572, 'bagging_fraction': 0.7545919513282392, 'bagging_freq': 8, 'min_child_samples': 11}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:32,378] Finished trial#4 with value: 0.24175090305092997 with parameters: {'learning_rate': 0.03526211659076113, 'lambda_l2': 0.5927166025346076, 'num_leaves': 166, 'max_depth': 24, 'feature_fraction': 0.6648460903282956, 'bagging_fraction': 0.9097573632985965, 'bagging_freq': 20, 'min_child_samples': 5}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:37,134] Finished trial#5 with value: 0.23790206451413004 with parameters: {'learning_rate': 0.05518881929912348, 'lambda_l2': 0.006023320908700295, 'num_leaves': 117, 'max_depth': 9, 'feature_fraction': 0.7657139318098851, 'bagging_fraction': 0.8468282623998493, 'bagging_freq': 8, 'min_child_samples': 4}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:39,402] Finished trial#6 with value: 0.2630214764285548 with parameters: {'learning_rate': 0.04103576765102714, 'lambda_l2': 0.1664847562564905, 'num_leaves': 193, 'max_depth': 25, 'feature_fraction': 0.6134591412810366, 'bagging_fraction': 0.6259733634732251, 'bagging_freq': 16, 'min_child_samples': 14}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:41,766] Finished trial#7 with value: 0.2618062580630433 with parameters: {'learning_rate': 0.03842310354738627, 'lambda_l2': 0.07983276173596933, 'num_leaves': 73, 'max_depth': 22, 'feature_fraction': 0.5040947865015148, 'bagging_fraction': 0.9186853081067561, 'bagging_freq': 9, 'min_child_samples': 13}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:43,929] Finished trial#8 with value: 0.2800543442194236 with parameters: {'learning_rate': 0.08612182905610341, 'lambda_l2': 0.005125130699582976, 'num_leaves': 42, 'max_depth': 25, 'feature_fraction': 0.9160551137160358, 'bagging_fraction': 0.5773552811741927, 'bagging_freq': 18, 'min_child_samples': 10}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:49,654] Finished trial#9 with value: 0.24542836860503878 with parameters: {'learning_rate': 0.04168884994144751, 'lambda_l2': 0.280308444503004, 'num_leaves': 188, 'max_depth': 20, 'feature_fraction': 0.9529021830594366, 'bagging_fraction': 0.9575603804698547, 'bagging_freq': 7, 'min_child_samples': 3}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:36:52,310] Finished trial#10 with value: 0.3193566440245048 with parameters: {'learning_rate': 0.010373809438267373, 'lambda_l2': 0.00012009133138059558, 'num_leaves': 142, 'max_depth': 14, 'feature_fraction': 0.8859778358865378, 'bagging_fraction': 0.5175527204479157, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:37:02,095] Finished trial#11 with value: 0.2342080050181082 with parameters: {'learning_rate': 0.02013718304206999, 'lambda_l2': 0.0011773281790309323, 'num_leaves': 101, 'max_depth': 12, 'feature_fraction': 0.7629369951835244, 'bagging_fraction': 0.8440656206239775, 'bagging_freq': 11, 'min_child_samples': 1}. Best is trial#2 with value: 0.22863513083938264.\n",
      "[I 2020-05-17 18:37:13,541] Finished trial#12 with value: 0.22323624431237749 with parameters: {'learning_rate': 0.020313707052380853, 'lambda_l2': 0.0006496357018860513, 'num_leaves': 89, 'max_depth': 13, 'feature_fraction': 0.8275870651611018, 'bagging_fraction': 0.7210202938212826, 'bagging_freq': 11, 'min_child_samples': 1}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:37:25,719] Finished trial#13 with value: 0.24260662108860695 with parameters: {'learning_rate': 0.021216089453502528, 'lambda_l2': 0.0001906371271039465, 'num_leaves': 55, 'max_depth': 16, 'feature_fraction': 0.9878028699040505, 'bagging_fraction': 0.7058791613492641, 'bagging_freq': 10, 'min_child_samples': 1}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:37:38,590] Finished trial#14 with value: 0.23351162957421218 with parameters: {'learning_rate': 0.015078085294068766, 'lambda_l2': 0.00032644539023382683, 'num_leaves': 79, 'max_depth': 12, 'feature_fraction': 0.8526194187819329, 'bagging_fraction': 0.6782005482888309, 'bagging_freq': 5, 'min_child_samples': 1}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:37:42,123] Finished trial#15 with value: 0.2790961177195686 with parameters: {'learning_rate': 0.025914474941966425, 'lambda_l2': 0.03114890868852868, 'num_leaves': 121, 'max_depth': 12, 'feature_fraction': 0.8055132259423089, 'bagging_fraction': 0.515958360799454, 'bagging_freq': 14, 'min_child_samples': 7}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:37:48,039] Finished trial#16 with value: 0.2554520305416514 with parameters: {'learning_rate': 0.014599377547944152, 'lambda_l2': 0.0007727341923536624, 'num_leaves': 62, 'max_depth': 18, 'feature_fraction': 0.9199430693977579, 'bagging_fraction': 0.7252347448608104, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:37:50,631] Finished trial#17 with value: 0.3009928363111252 with parameters: {'learning_rate': 0.026432745602982713, 'lambda_l2': 0.9615064804105372, 'num_leaves': 93, 'max_depth': 15, 'feature_fraction': 0.7255685079502256, 'bagging_fraction': 0.6470762011595207, 'bagging_freq': 14, 'min_child_samples': 17}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:38:01,659] Finished trial#18 with value: 0.23720630763277037 with parameters: {'learning_rate': 0.01023754423175538, 'lambda_l2': 0.01925055990228215, 'num_leaves': 160, 'max_depth': 11, 'feature_fraction': 0.9924081301788261, 'bagging_fraction': 0.5776461546813998, 'bagging_freq': 10, 'min_child_samples': 3}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:38:14,023] Finished trial#19 with value: 0.23098541911453024 with parameters: {'learning_rate': 0.017216295140448715, 'lambda_l2': 0.0011979111083007393, 'num_leaves': 112, 'max_depth': 14, 'feature_fraction': 0.8584466998932211, 'bagging_fraction': 0.7529581711915445, 'bagging_freq': 12, 'min_child_samples': 1}. Best is trial#12 with value: 0.22323624431237749.\n",
      "[I 2020-05-17 18:38:17,927] Finished trial#20 with value: 0.2526789985741191 with parameters: {'learning_rate': 0.027522555472434797, 'lambda_l2': 0.05858881543079762, 'num_leaves': 141, 'max_depth': 18, 'feature_fraction': 0.6586708330821245, 'bagging_fraction': 0.5778821358334275, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial#12 with value: 0.22323624431237749.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-17 18:38:29,934] Finished trial#21 with value: 0.21952376732803872 with parameters: {'learning_rate': 0.017455491608048095, 'lambda_l2': 0.0011391506979238364, 'num_leaves': 115, 'max_depth': 14, 'feature_fraction': 0.850097964218496, 'bagging_fraction': 0.7477052820661827, 'bagging_freq': 13, 'min_child_samples': 1}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:38:36,865] Finished trial#22 with value: 0.23309276411321272 with parameters: {'learning_rate': 0.01763728320349444, 'lambda_l2': 0.00047835136717570023, 'num_leaves': 79, 'max_depth': 10, 'feature_fraction': 0.779638624643137, 'bagging_fraction': 0.7889635966652238, 'bagging_freq': 13, 'min_child_samples': 3}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:38:46,625] Finished trial#23 with value: 0.23449818395857713 with parameters: {'learning_rate': 0.023711445750699167, 'lambda_l2': 0.0027188794527594432, 'num_leaves': 104, 'max_depth': 14, 'feature_fraction': 0.8852505256791875, 'bagging_fraction': 0.6762094279906213, 'bagging_freq': 16, 'min_child_samples': 1}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:38:52,124] Finished trial#24 with value: 0.2457379896760815 with parameters: {'learning_rate': 0.030239978551667424, 'lambda_l2': 0.0119381139024241, 'num_leaves': 128, 'max_depth': 17, 'feature_fraction': 0.8492261499524689, 'bagging_fraction': 0.7848970196033853, 'bagging_freq': 10, 'min_child_samples': 3}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:05,536] Finished trial#25 with value: 0.24086485972218677 with parameters: {'learning_rate': 0.011979696827199833, 'lambda_l2': 0.00010155271752117441, 'num_leaves': 151, 'max_depth': 13, 'feature_fraction': 0.9485046583888473, 'bagging_fraction': 0.7138604015278787, 'bagging_freq': 16, 'min_child_samples': 2}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:11,509] Finished trial#26 with value: 0.24709739822632185 with parameters: {'learning_rate': 0.018278285275875206, 'lambda_l2': 0.0018637919298971368, 'num_leaves': 90, 'max_depth': 10, 'feature_fraction': 0.8810324395899092, 'bagging_fraction': 0.6670856676729962, 'bagging_freq': 11, 'min_child_samples': 5}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:16,170] Finished trial#27 with value: 0.2581021489665535 with parameters: {'learning_rate': 0.012504853784258599, 'lambda_l2': 0.00029360842593282227, 'num_leaves': 175, 'max_depth': 16, 'feature_fraction': 0.7973295012350825, 'bagging_fraction': 0.8279631949750383, 'bagging_freq': 13, 'min_child_samples': 9}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:21,347] Finished trial#28 with value: 0.25715519347088417 with parameters: {'learning_rate': 0.015855618172265763, 'lambda_l2': 0.0007696652049587333, 'num_leaves': 108, 'max_depth': 13, 'feature_fraction': 0.7403920696953864, 'bagging_fraction': 0.5977797850449352, 'bagging_freq': 9, 'min_child_samples': 6}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:25,056] Finished trial#29 with value: 0.25668258890278983 with parameters: {'learning_rate': 0.032661837891583965, 'lambda_l2': 0.007600370385823665, 'num_leaves': 128, 'max_depth': 8, 'feature_fraction': 0.8316318784898613, 'bagging_fraction': 0.8786321645217774, 'bagging_freq': 12, 'min_child_samples': 8}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:34,127] Finished trial#30 with value: 0.23401673930076522 with parameters: {'learning_rate': 0.01893965978062132, 'lambda_l2': 0.0018923628373632183, 'num_leaves': 66, 'max_depth': 11, 'feature_fraction': 0.697343605937887, 'bagging_fraction': 0.5461330885388284, 'bagging_freq': 11, 'min_child_samples': 2}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:46,859] Finished trial#31 with value: 0.2327991344526507 with parameters: {'learning_rate': 0.016418630101724015, 'lambda_l2': 0.0009182553115618363, 'num_leaves': 110, 'max_depth': 14, 'feature_fraction': 0.8464638160760886, 'bagging_fraction': 0.7518253008869272, 'bagging_freq': 13, 'min_child_samples': 1}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:39:57,454] Finished trial#32 with value: 0.23183687251867888 with parameters: {'learning_rate': 0.013114855321915272, 'lambda_l2': 0.0003853606851896106, 'num_leaves': 118, 'max_depth': 15, 'feature_fraction': 0.8099685111831331, 'bagging_fraction': 0.7710021163055369, 'bagging_freq': 12, 'min_child_samples': 2}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:03,138] Finished trial#33 with value: 0.23980399702521019 with parameters: {'learning_rate': 0.023312673618285484, 'lambda_l2': 0.0016080950367425842, 'num_leaves': 89, 'max_depth': 13, 'feature_fraction': 0.8672346633331496, 'bagging_fraction': 0.8140438354547576, 'bagging_freq': 15, 'min_child_samples': 4}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:09,304] Finished trial#34 with value: 0.24943133158444755 with parameters: {'learning_rate': 0.02047139256923548, 'lambda_l2': 0.002972464430874311, 'num_leaves': 130, 'max_depth': 15, 'feature_fraction': 0.9190252998604128, 'bagging_fraction': 0.7323375078115703, 'bagging_freq': 12, 'min_child_samples': 4}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:18,207] Finished trial#35 with value: 0.23828110753117454 with parameters: {'learning_rate': 0.011569691623440684, 'lambda_l2': 0.0043142431049140815, 'num_leaves': 101, 'max_depth': 11, 'feature_fraction': 0.8181166964306849, 'bagging_fraction': 0.6871655702497674, 'bagging_freq': 9, 'min_child_samples': 2}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:32,337] Finished trial#36 with value: 0.2292751836689629 with parameters: {'learning_rate': 0.01681902385650791, 'lambda_l2': 0.00017842050702785358, 'num_leaves': 115, 'max_depth': 9, 'feature_fraction': 0.7873029777073642, 'bagging_fraction': 0.627732356345822, 'bagging_freq': 14, 'min_child_samples': 1}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:37,436] Finished trial#37 with value: 0.26596769057527025 with parameters: {'learning_rate': 0.023156150900650076, 'lambda_l2': 0.00018216350415195328, 'num_leaves': 155, 'max_depth': 9, 'feature_fraction': 0.7771768236139379, 'bagging_fraction': 0.6460613079860809, 'bagging_freq': 17, 'min_child_samples': 6}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:41,346] Finished trial#38 with value: 0.29178055449783946 with parameters: {'learning_rate': 0.014424625622975546, 'lambda_l2': 0.0005135912253846162, 'num_leaves': 138, 'max_depth': 8, 'feature_fraction': 0.6950780762168475, 'bagging_fraction': 0.6287931646932646, 'bagging_freq': 15, 'min_child_samples': 13}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:45,182] Finished trial#39 with value: 0.2557363984102208 with parameters: {'learning_rate': 0.04615440091211383, 'lambda_l2': 0.0002002942074023134, 'num_leaves': 82, 'max_depth': 10, 'feature_fraction': 0.7404093762022806, 'bagging_fraction': 0.5966560333289685, 'bagging_freq': 8, 'min_child_samples': 4}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:40:51,228] Finished trial#40 with value: 0.24916247514638115 with parameters: {'learning_rate': 0.01944901245255764, 'lambda_l2': 0.1872323892363279, 'num_leaves': 42, 'max_depth': 8, 'feature_fraction': 0.7964101507501187, 'bagging_fraction': 0.5409970944035072, 'bagging_freq': 15, 'min_child_samples': 2}. Best is trial#21 with value: 0.21952376732803872.\n",
      "[I 2020-05-17 18:41:02,268] Finished trial#41 with value: 0.21729107501309106 with parameters: {'learning_rate': 0.016250686178424446, 'lambda_l2': 0.0005813577850228519, 'num_leaves': 115, 'max_depth': 12, 'feature_fraction': 0.8386351678825856, 'bagging_fraction': 0.7456424540252927, 'bagging_freq': 14, 'min_child_samples': 1}. Best is trial#41 with value: 0.21729107501309106.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-17 18:41:11,543] Finished trial#42 with value: 0.2514428095468876 with parameters: {'learning_rate': 0.013476541999830527, 'lambda_l2': 0.0001455709041724295, 'num_leaves': 121, 'max_depth': 12, 'feature_fraction': 0.8262807181700286, 'bagging_fraction': 0.6980308962313827, 'bagging_freq': 19, 'min_child_samples': 3}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:41:22,937] Finished trial#43 with value: 0.2417858299082517 with parameters: {'learning_rate': 0.016690523400352535, 'lambda_l2': 0.0005694936163665529, 'num_leaves': 97, 'max_depth': 10, 'feature_fraction': 0.8993309920777763, 'bagging_fraction': 0.7350283829742368, 'bagging_freq': 14, 'min_child_samples': 1}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:41:28,389] Finished trial#44 with value: 0.23758063115109113 with parameters: {'learning_rate': 0.021447219185030047, 'lambda_l2': 0.3666210377250154, 'num_leaves': 146, 'max_depth': 9, 'feature_fraction': 0.834070782418773, 'bagging_fraction': 0.6539729916826387, 'bagging_freq': 14, 'min_child_samples': 2}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:41:33,842] Finished trial#45 with value: 0.2516065194877023 with parameters: {'learning_rate': 0.014916739241467214, 'lambda_l2': 0.0002523716437650082, 'num_leaves': 127, 'max_depth': 11, 'feature_fraction': 0.5018508687427338, 'bagging_fraction': 0.6091016206604963, 'bagging_freq': 17, 'min_child_samples': 5}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:41:43,138] Finished trial#46 with value: 0.23293753552086485 with parameters: {'learning_rate': 0.02930478147543275, 'lambda_l2': 0.0006856288095175688, 'num_leaves': 116, 'max_depth': 13, 'feature_fraction': 0.7597627818456976, 'bagging_fraction': 0.8036758305882453, 'bagging_freq': 13, 'min_child_samples': 1}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:41:52,854] Finished trial#47 with value: 0.2386255073111294 with parameters: {'learning_rate': 0.011054171528069735, 'lambda_l2': 0.00010134784254095717, 'num_leaves': 174, 'max_depth': 12, 'feature_fraction': 0.790378088359859, 'bagging_fraction': 0.7621863345215392, 'bagging_freq': 11, 'min_child_samples': 4}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:00,334] Finished trial#48 with value: 0.22713133033226507 with parameters: {'learning_rate': 0.01862336428246413, 'lambda_l2': 0.0013188833917076308, 'num_leaves': 199, 'max_depth': 9, 'feature_fraction': 0.9368606015373057, 'bagging_fraction': 0.7074856976519054, 'bagging_freq': 15, 'min_child_samples': 3}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:03,877] Finished trial#49 with value: 0.25797487700041216 with parameters: {'learning_rate': 0.02435527568042326, 'lambda_l2': 0.0012820191452562442, 'num_leaves': 187, 'max_depth': 13, 'feature_fraction': 0.965021539780395, 'bagging_fraction': 0.7125445563789428, 'bagging_freq': 16, 'min_child_samples': 11}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:09,227] Finished trial#50 with value: 0.25049669210907965 with parameters: {'learning_rate': 0.036172771571438826, 'lambda_l2': 0.08461934036584516, 'num_leaves': 188, 'max_depth': 11, 'feature_fraction': 0.9333506531400997, 'bagging_fraction': 0.7354192177850767, 'bagging_freq': 6, 'min_child_samples': 3}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:18,382] Finished trial#51 with value: 0.24557402067459114 with parameters: {'learning_rate': 0.01854036189749407, 'lambda_l2': 0.0003990353864848555, 'num_leaves': 194, 'max_depth': 9, 'feature_fraction': 0.8714253774144961, 'bagging_fraction': 0.68879958441035, 'bagging_freq': 15, 'min_child_samples': 1}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:25,593] Finished trial#52 with value: 0.24352354639979998 with parameters: {'learning_rate': 0.02097798225736854, 'lambda_l2': 0.0009776831454717133, 'num_leaves': 197, 'max_depth': 10, 'feature_fraction': 0.9038472402181233, 'bagging_fraction': 0.631365637487463, 'bagging_freq': 14, 'min_child_samples': 2}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:27,900] Finished trial#53 with value: 0.29535040628022435 with parameters: {'learning_rate': 0.01603500570607119, 'lambda_l2': 0.0024377969912576067, 'num_leaves': 52, 'max_depth': 12, 'feature_fraction': 0.5531626865101171, 'bagging_fraction': 0.6653919902605099, 'bagging_freq': 17, 'min_child_samples': 17}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:38,042] Finished trial#54 with value: 0.23573972466064155 with parameters: {'learning_rate': 0.014300924342607997, 'lambda_l2': 0.00433837034448506, 'num_leaves': 133, 'max_depth': 9, 'feature_fraction': 0.8365487752090185, 'bagging_fraction': 0.7148323960510468, 'bagging_freq': 14, 'min_child_samples': 1}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:44,675] Finished trial#55 with value: 0.24271794388318965 with parameters: {'learning_rate': 0.017602708651923402, 'lambda_l2': 0.013412217333829584, 'num_leaves': 108, 'max_depth': 11, 'feature_fraction': 0.974848328815582, 'bagging_fraction': 0.771940351661024, 'bagging_freq': 13, 'min_child_samples': 3}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:42:55,488] Finished trial#56 with value: 0.2337449748020773 with parameters: {'learning_rate': 0.02516586521943528, 'lambda_l2': 0.0006177326063863644, 'num_leaves': 200, 'max_depth': 14, 'feature_fraction': 0.8953145143924589, 'bagging_fraction': 0.5465789352708668, 'bagging_freq': 15, 'min_child_samples': 1}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:43:04,266] Finished trial#57 with value: 0.23873520848449384 with parameters: {'learning_rate': 0.021969853628955073, 'lambda_l2': 0.0002861364430642388, 'num_leaves': 96, 'max_depth': 12, 'feature_fraction': 0.7721798495204585, 'bagging_fraction': 0.7966582202195132, 'bagging_freq': 12, 'min_child_samples': 2}. Best is trial#41 with value: 0.21729107501309106.\n",
      "[I 2020-05-17 18:43:10,528] Finished trial#58 with value: 0.2410256289353372 with parameters: {'learning_rate': 0.019215806438451208, 'lambda_l2': 0.8714899237556653, 'num_leaves': 116, 'max_depth': 15, 'feature_fraction': 0.863108260243222, 'bagging_fraction': 0.7426472066172269, 'bagging_freq': 9, 'min_child_samples': 3}. Best is trial#41 with value: 0.21729107501309106.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9acc1a5fa752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[1;32m--> 334\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m                 )\n\u001b[0;32m    336\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    646\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[1;32m<ipython-input-34-65121ae16038>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         model = lgb.train(params, lgtrain, valid_sets=[lgvalidation], \n\u001b[1;32m---> 32\u001b[1;33m                           num_boost_round=5000, early_stopping_rounds=200, verbose_eval=False)\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 200\n",
      "Best trial:\n",
      "Value: 0.20152153538527245\n",
      "Params: \n",
      " learning_rate: 0.06429437878342074\n",
      " lambda_l2: 0.0008997726071095372\n",
      " num_leaves: 200\n",
      " max_depth: 9\n",
      " feature_fraction: 0.6883384481523004\n",
      " bagging_fraction: 0.798563706360225\n",
      " bagging_freq: 13\n",
      " min_child_samples: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\" {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "params = {}\n",
    "params[\"objective\"] = 'multiclass'\n",
    "params[\"metric\"] = 'multi_logloss'\n",
    "params[\"num_class\"] = 2\n",
    "params[\"is_unbalance\"] = True\n",
    "params[\"boosting\"] = 'gbdt'\n",
    "params[\"max_depth\"] = 9\n",
    "params[\"num_leaves\"] = 200\n",
    "params[\"learning_rate\"] = 0.06\n",
    "params[\"bagging_fraction\"] = 0.8\n",
    "params[\"feature_fraction\"] = 0.8\n",
    "params[\"bagging_freq\"] = 13\n",
    "params[\"bagging_seed\"] = 10\n",
    "params[\"lambda_l2\"] = 0.009\n",
    "params[\"min_data_in_leaf\"] = 1\n",
    "params[\"verbosity\"] = -1\n",
    "num_rounds = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "y_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_logloss: 0.371732\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's multi_logloss: 0.317244\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's multi_logloss: 0.341795\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 0.241932\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 0.32197\n"
     ]
    }
   ],
   "source": [
    "# Train the model using K-fold\n",
    "counter = 0\n",
    "\n",
    "for train, val in kfold.split(Xtrain, Ytrain):\n",
    "    counter += 1\n",
    "\n",
    "    train_x, train_y = Xtrain[train], Ytrain[train]\n",
    "    val_x, val_y = Xtrain[val], Ytrain[val]\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_x, label=train_y.ravel())\n",
    "    lgvalidation = lgb.Dataset(val_x, label=val_y.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgvalidation], early_stopping_rounds=200, verbose_eval=1000)\n",
    "    pred = model.predict(Xtest, num_iteration=model.best_iteration)\n",
    "\n",
    "    y_pred += pred\n",
    "\n",
    "y_pred /= float(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall log_loss of model: 0.2632133063224379\n"
     ]
    }
   ],
   "source": [
    "#Print log_loss\n",
    "loss = log_loss(test_y, y_pred)\n",
    "print('Overall log_loss of model:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.8846153846153846\n",
      "Overall F1-Score: 0.90625\n"
     ]
    }
   ],
   "source": [
    "#Print accuracy\n",
    "y_pred_binary = np.array([np.argmax(y_pred, axis=1)]).T\n",
    "acc_score = accuracy_score(Ytest, y_pred_binary)\n",
    "f1 = f1_score(Ytest, y_pred_binary)\n",
    "print('Overall accuracy:', acc_score)\n",
    "print('Overall F1-Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Area Under Curve\n",
    "plt.figure()\n",
    "false_positive_rate, recall, thresholds = roc_curve(Ytest, y_pred_binary)\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out (1-Specificity)')\n",
    "plt.show()\n",
    "\n",
    "print('AUC score:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Confusion Matrix\n",
    "cm = confusion_matrix(Ytest, y_pred_binary)\n",
    "labels = ['0', '1']\n",
    "sns.heatmap(cm, xticklabels = labels, yticklabels = labels, annot = True, fmt='d', cmap=\"Blues\", vmin = 0.5);\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "y_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using K-fold\n",
    "counter = 0\n",
    "\n",
    "for train, val in kfold.split(Xtrain_full, Ytrain_full):\n",
    "    counter += 1\n",
    "\n",
    "    train_x, train_y = Xtrain_full[train], Ytrain_full[train]\n",
    "    val_x, val_y = Xtrain_full[val], Ytrain_full[val]\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_x, label=train_y.ravel())\n",
    "    lgvalidation = lgb.Dataset(val_x, label=val_y.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgvalidation], early_stopping_rounds=200, verbose_eval=1000)\n",
    "    pred = model.predict(Xpredict, num_iteration=model.best_iteration)\n",
    "\n",
    "    y_pred += pred\n",
    "\n",
    "y_pred /= float(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(y_pred, columns=['0','1'])\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_excel(\"Predictions/predictions_v13.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
