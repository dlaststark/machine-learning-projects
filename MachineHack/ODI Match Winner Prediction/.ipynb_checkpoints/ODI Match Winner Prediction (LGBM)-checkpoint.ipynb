{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import lightgbm as lgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set file paths for train and predict datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"Dataset/Train.csv\"\n",
    "predict_dataset = \"Dataset/Test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train and predict datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (2508, 10)\n",
      "predict_df: (1075, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_dataset)\n",
    "predict_df = pd.read_csv(predict_dataset)\n",
    "print(\"train_df: {}\".format(train_df.shape))\n",
    "print(\"predict_df: {}\".format(predict_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract \"MatchWinner\" field from train_df into NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: (2508, 1)\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array([train_df['MatchWinner'].values]).T\n",
    "train_df.drop(['MatchWinner'], inplace=True, axis=1)\n",
    "print(\"train_y: {}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine train and predict dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>HostCountry</th>\n",
       "      <th>Team1_Venue</th>\n",
       "      <th>Team2_Venue</th>\n",
       "      <th>Team1_Innings</th>\n",
       "      <th>Team2_Innings</th>\n",
       "      <th>MonthOfMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>Second</td>\n",
       "      <td>First</td>\n",
       "      <td>Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Sep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>Home</td>\n",
       "      <td>Away</td>\n",
       "      <td>First</td>\n",
       "      <td>Second</td>\n",
       "      <td>Aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1  Team2  Stadium  HostCountry Team1_Venue Team2_Venue Team1_Innings  \\\n",
       "0      5      4       37            4        Home        Away        Second   \n",
       "1      1     14       84            7     Neutral     Neutral         First   \n",
       "2      9     15       47            9        Home        Away         First   \n",
       "3      7      2      102            6        Home        Away         First   \n",
       "4      6      8       46            5        Home        Away         First   \n",
       "\n",
       "  Team2_Innings MonthOfMatch  \n",
       "0         First          Dec  \n",
       "1        Second          Sep  \n",
       "2        Second          Feb  \n",
       "3        Second          Aug  \n",
       "4        Second          Aug  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = train_df.append(predict_df, sort=False, ignore_index=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Team1_Venue'] = combined_df['Team1_Venue'].apply(lambda x: 1 if x=='Home' else -1 if x=='Away' else 0)\n",
    "combined_df['Team2_Venue'] = combined_df['Team2_Venue'].apply(lambda x: 1 if x=='Home' else -1 if x=='Away' else 0)\n",
    "\n",
    "combined_df['Team1_Innings'] = combined_df['Team1_Innings'].apply(lambda x: 1 if x=='First' else 0)\n",
    "combined_df['Team2_Innings'] = combined_df['Team2_Innings'].apply(lambda x: 1 if x=='First' else 0)\n",
    "\n",
    "combined_df['MonthOfMatch'] = combined_df['MonthOfMatch'].apply(lambda x: {\n",
    "        'Jan' : 1,\n",
    "        'Feb' : 2,\n",
    "        'Mar' : 3,\n",
    "        'Apr' : 4,\n",
    "        'May' : 5,\n",
    "        'Jun' : 6,\n",
    "        'Jul' : 7,\n",
    "        'Aug' : 8,\n",
    "        'Sep' : 9, \n",
    "        'Oct' : 10,\n",
    "        'Nov' : 11,\n",
    "        'Dec' : 12\n",
    "}[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>HostCountry</th>\n",
       "      <th>Team1_Venue</th>\n",
       "      <th>Team2_Venue</th>\n",
       "      <th>Team1_Innings</th>\n",
       "      <th>Team2_Innings</th>\n",
       "      <th>MonthOfMatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1  Team2  Stadium  HostCountry  Team1_Venue  Team2_Venue  \\\n",
       "0      5      4       37            4            1           -1   \n",
       "1      1     14       84            7            0            0   \n",
       "2      9     15       47            9            1           -1   \n",
       "3      7      2      102            6            1           -1   \n",
       "4      6      8       46            5            1           -1   \n",
       "\n",
       "   Team1_Innings  Team2_Innings  MonthOfMatch  \n",
       "0              0              1            12  \n",
       "1              1              0             9  \n",
       "2              1              0             2  \n",
       "3              1              0             8  \n",
       "4              1              0             8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and predict Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x: (2508, 9)\n",
      "predict_x: (1075, 9)\n"
     ]
    }
   ],
   "source": [
    "# Segregate combined_df into train/predict datasets\n",
    "train_x = combined_df[:2508].values\n",
    "predict_x = combined_df[2508:].values\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"predict_x: {}\".format(predict_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the train_x/predict_x arrays\n",
    "scaler = MinMaxScaler().fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "predict_x = scaler.transform(predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_full = train_x.copy()\n",
    "train_y_full = train_y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training data into train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "train_x shape: (2319, 9)\n",
      "train_y shape: (2319, 1)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "test_x shape: (189, 9)\n",
      "test_y shape: (189, 1)\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.075, random_state=1)\n",
    "for train_index, test_index in sss.split(train_x, train_y):\n",
    "    train_x, test_x = train_x[train_index], train_x[test_index]\n",
    "    train_y, test_y = train_y[train_index], train_y[test_index]\n",
    "\n",
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"train_x shape: {}\".format(train_x.shape))\n",
    "print(\"train_y shape: {}\".format(train_y.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"test_x shape: {}\".format(test_x.shape))\n",
    "print(\"test_y shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "Xtrain_full shape: (2508, 9)\n",
      "Ytrain_full shape: (2508, 1)\n",
      "Xtrain shape: (2319, 9)\n",
      "Ytrain shape: (2319, 1)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "Xtest shape: (189, 9)\n",
      "Ytest shape: (189, 1)\n",
      "\n",
      "------------------------- Prediction Dataset -------------------------\n",
      "Xpredict shape: (1075, 9)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_full, Ytrain_full = train_x_full.copy(), train_y_full.copy()\n",
    "Xtrain, Ytrain = train_x.copy(), train_y.copy()\n",
    "Xtest, Ytest = test_x.copy(), test_y.copy()\n",
    "Xpredict = predict_x.copy()\n",
    "\n",
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"Xtrain_full shape: {}\".format(Xtrain_full.shape))\n",
    "print(\"Ytrain_full shape: {}\".format(Ytrain_full.shape))\n",
    "print(\"Xtrain shape: {}\".format(Xtrain.shape))\n",
    "print(\"Ytrain shape: {}\".format(Ytrain.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"Xtest shape: {}\".format(Xtest.shape))\n",
    "print(\"Ytest shape: {}\".format(Ytest.shape))\n",
    "\n",
    "print(\"\\n------------------------- Prediction Dataset -------------------------\")\n",
    "print(\"Xpredict shape: {}\".format(Xpredict.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Ytest to one-hot encoding\n",
    "df = pd.DataFrame(Ytest, columns=[\"target\"])\n",
    "test_y = pd.get_dummies(df['target']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"num_class\": 16,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"is_unbalance\": True,\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 256, 512),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-2, 1e-1),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-4, 1.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 35, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 25),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 5, 20),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 20)\n",
    "    }\n",
    "    \n",
    "    y_pred = 0\n",
    "    counter = 0\n",
    "    for train, val in kfold.split(Xtrain, Ytrain):\n",
    "        counter += 1\n",
    "    \n",
    "        train_x, train_y = Xtrain[train], Ytrain[train]\n",
    "        val_x, val_y = Xtrain[val], Ytrain[val]\n",
    "\n",
    "        lgtrain = lgb.Dataset(train_x, label=train_y.ravel())\n",
    "        lgvalidation = lgb.Dataset(val_x, label=val_y.ravel())\n",
    "\n",
    "        model = lgb.train(params, lgtrain, valid_sets=[lgvalidation], \n",
    "                          num_boost_round=5000, early_stopping_rounds=200, verbose_eval=False)\n",
    "        pred = model.predict(Xtest, num_iteration=model.best_iteration)\n",
    "\n",
    "        y_pred += pred\n",
    "\n",
    "    y_pred /= float(counter)\n",
    "    loss = log_loss(test_y, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-20 00:30:48,141] Finished trial#0 with value: 0.8880055772335186 with parameters: {'max_bin': 304, 'learning_rate': 0.020493613738234266, 'lambda_l2': 0.02111274952348149, 'num_leaves': 50, 'max_depth': 11, 'feature_fraction': 0.7189085574832109, 'bagging_fraction': 0.9387269619942173, 'bagging_freq': 16, 'min_child_samples': 7}. Best is trial#0 with value: 0.8880055772335186.\n",
      "[I 2020-06-20 00:31:14,613] Finished trial#1 with value: 0.8125526870780237 with parameters: {'max_bin': 445, 'learning_rate': 0.02917560784435104, 'lambda_l2': 0.2689026873865235, 'num_leaves': 105, 'max_depth': 8, 'feature_fraction': 0.7317006255850408, 'bagging_fraction': 0.6075296725596281, 'bagging_freq': 20, 'min_child_samples': 20}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:32:19,083] Finished trial#2 with value: 0.8152039384475309 with parameters: {'max_bin': 485, 'learning_rate': 0.010200631892092277, 'lambda_l2': 0.380641839757444, 'num_leaves': 132, 'max_depth': 24, 'feature_fraction': 0.998484815705553, 'bagging_fraction': 0.9438098976477387, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:33:56,908] Finished trial#3 with value: 0.9434568951316129 with parameters: {'max_bin': 336, 'learning_rate': 0.013883292759689792, 'lambda_l2': 0.0014093411763327825, 'num_leaves': 94, 'max_depth': 20, 'feature_fraction': 0.6386579647876394, 'bagging_fraction': 0.5968270869911654, 'bagging_freq': 19, 'min_child_samples': 4}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:34:47,862] Finished trial#4 with value: 0.8715791932371137 with parameters: {'max_bin': 504, 'learning_rate': 0.04485712255811474, 'lambda_l2': 0.01373215591589004, 'num_leaves': 169, 'max_depth': 15, 'feature_fraction': 0.5137313959504306, 'bagging_fraction': 0.9543138385058332, 'bagging_freq': 8, 'min_child_samples': 20}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:35:14,139] Finished trial#5 with value: 0.9162342105361099 with parameters: {'max_bin': 301, 'learning_rate': 0.04911849779051494, 'lambda_l2': 0.030268596500815505, 'num_leaves': 183, 'max_depth': 8, 'feature_fraction': 0.7262280150401749, 'bagging_fraction': 0.7267090039462467, 'bagging_freq': 14, 'min_child_samples': 3}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:36:47,571] Finished trial#6 with value: 0.8670290895909912 with parameters: {'max_bin': 354, 'learning_rate': 0.010590299352233346, 'lambda_l2': 0.12542461260245177, 'num_leaves': 167, 'max_depth': 22, 'feature_fraction': 0.6461705533192121, 'bagging_fraction': 0.720027130762693, 'bagging_freq': 13, 'min_child_samples': 8}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:37:18,984] Finished trial#7 with value: 0.8468161389432965 with parameters: {'max_bin': 309, 'learning_rate': 0.057509339316375016, 'lambda_l2': 0.9198121114973267, 'num_leaves': 68, 'max_depth': 11, 'feature_fraction': 0.6287376261900164, 'bagging_fraction': 0.5200568304785896, 'bagging_freq': 8, 'min_child_samples': 4}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:38:51,416] Finished trial#8 with value: 0.8298675767593804 with parameters: {'max_bin': 378, 'learning_rate': 0.012337336383410436, 'lambda_l2': 0.00046755089649834497, 'num_leaves': 100, 'max_depth': 9, 'feature_fraction': 0.7997538803349837, 'bagging_fraction': 0.7740591703850874, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:39:29,536] Finished trial#9 with value: 0.9045633764228617 with parameters: {'max_bin': 486, 'learning_rate': 0.026281977825172765, 'lambda_l2': 0.00023181922078346312, 'num_leaves': 92, 'max_depth': 15, 'feature_fraction': 0.6183510999651032, 'bagging_fraction': 0.9912969471718112, 'bagging_freq': 18, 'min_child_samples': 8}. Best is trial#1 with value: 0.8125526870780237.\n",
      "[I 2020-06-20 00:39:44,581] Finished trial#10 with value: 0.8213585921206373 with parameters: {'max_bin': 439, 'learning_rate': 0.03311634227630398, 'lambda_l2': 0.11478924086354093, 'num_leaves': 134, 'max_depth': 18, 'feature_fraction': 0.8851050679445505, 'bagging_fraction': 0.5734973315774358, 'bagging_freq': 20, 'min_child_samples': 20}. Best is trial#1 with value: 0.8125526870780237.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-782b8c616d8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 339\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 )\n\u001b[1;32m    341\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    680\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-15-990476b708ef>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         model = lgb.train(params, lgtrain, valid_sets=[lgvalidation], \n\u001b[0;32m---> 33\u001b[0;31m                           num_boost_round=5000, early_stopping_rounds=200, verbose_eval=False)\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \"\"\"\n\u001b[0;32m-> 2187\u001b[0;31m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   2188\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \"\"\"\n\u001b[1;32m   2187\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 2188\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2648\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\" {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "params = {}\n",
    "params[\"objective\"] = 'multiclass'\n",
    "params[\"metric\"] = 'multi_logloss'\n",
    "params[\"num_class\"] = 16\n",
    "params[\"is_unbalance\"] = True\n",
    "params[\"boosting\"] = 'gbdt'\n",
    "params[\"max_bin\"] = 396\n",
    "params[\"learning_rate\"] = 0.017\n",
    "params[\"lambda_l2\"] = 0.053\n",
    "params[\"num_leaves\"] = 51\n",
    "params[\"max_depth\"] = 12\n",
    "params[\"feature_fraction\"] = 0.95\n",
    "params[\"bagging_fraction\"] = 0.94\n",
    "params[\"bagging_freq\"] = 17\n",
    "params[\"min_data_in_leaf\"] = 1\n",
    "params[\"verbosity\"] = -1\n",
    "num_rounds = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "y_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using K-fold\n",
    "counter = 0\n",
    "\n",
    "for train, val in kfold.split(Xtrain, Ytrain):\n",
    "    counter += 1\n",
    "\n",
    "    train_x, train_y = Xtrain[train], Ytrain[train]\n",
    "    val_x, val_y = Xtrain[val], Ytrain[val]\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_x, label=train_y.ravel())\n",
    "    lgvalidation = lgb.Dataset(val_x, label=val_y.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgvalidation], early_stopping_rounds=200, verbose_eval=1000)\n",
    "    pred = model.predict(Xtest, num_iteration=model.best_iteration)\n",
    "\n",
    "    y_pred += pred\n",
    "\n",
    "y_pred /= float(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print log_loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_loss(test_y, y_pred)\n",
    "y_pred_label = np.array([np.argmax(y_pred, axis=1)]).T\n",
    "acc_score = accuracy_score(Ytest, y_pred_label)\n",
    "print('Overall log_loss:', loss)\n",
    "print('Overall accuracy:', acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(Ytest, y_pred_label, \n",
    "                      labels=['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "y_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using K-fold\n",
    "counter = 0\n",
    "\n",
    "for train, val in kfold.split(Xtrain_full, Ytrain_full):\n",
    "    counter += 1\n",
    "\n",
    "    train_x, train_y = Xtrain_full[train], Ytrain_full[train]\n",
    "    val_x, val_y = Xtrain_full[val], Ytrain_full[val]\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_x, label=train_y.ravel())\n",
    "    lgvalidation = lgb.Dataset(val_x, label=val_y.ravel())\n",
    "\n",
    "    model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgvalidation], early_stopping_rounds=200, verbose_eval=1000)\n",
    "    pred = model.predict(Xpredict, num_iteration=model.best_iteration)\n",
    "\n",
    "    y_pred += pred\n",
    "\n",
    "y_pred /= float(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(y_pred, columns=['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15'])\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_excel(\"Predictions/predictions_v1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
