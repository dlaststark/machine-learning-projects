{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consistent-fisher",
   "metadata": {
    "papermill": {
     "duration": 0.038044,
     "end_time": "2021-06-24T18:39:16.279986",
     "exception": false,
     "start_time": "2021-06-24T18:39:16.241942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "changing-policy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:16.373021Z",
     "iopub.status.busy": "2021-06-24T18:39:16.372313Z",
     "iopub.status.idle": "2021-06-24T18:39:22.254910Z",
     "shell.execute_reply": "2021-06-24T18:39:22.253916Z",
     "shell.execute_reply.started": "2021-06-19T14:00:28.338157Z"
    },
    "papermill": {
     "duration": 5.936775,
     "end_time": "2021-06-24T18:39:22.255074",
     "exception": false,
     "start_time": "2021-06-24T18:39:16.318299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Input, Dropout, Activation\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "from transformers import RobertaTokenizer, TFRobertaModel, RobertaConfig\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n",
    "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel, XLMRobertaConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-flooring",
   "metadata": {
    "papermill": {
     "duration": 0.036129,
     "end_time": "2021-06-24T18:39:22.327650",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.291521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load source datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demanding-stupid",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:22.406502Z",
     "iopub.status.busy": "2021-06-24T18:39:22.405985Z",
     "iopub.status.idle": "2021-06-24T18:39:22.517792Z",
     "shell.execute_reply": "2021-06-24T18:39:22.518330Z",
     "shell.execute_reply.started": "2021-06-19T14:00:34.150488Z"
    },
    "papermill": {
     "duration": 0.154,
     "end_time": "2021-06-24T18:39:22.518488",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.364488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (2834, 3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>excerpt_wordlen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85aa80a4c</th>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b69ac6792</th>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd1000b26</th>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37c1b32fb</th>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "85aa80a4c  All through dinner time, Mrs. Fayre was somewh... -0.315372   \n",
       "b69ac6792  As Roger had predicted, the snow departed as q... -0.580118   \n",
       "dd1000b26  And outside before the palace a great garden w... -1.054013   \n",
       "37c1b32fb  Once upon a time there were Three Bears who li...  0.247197   \n",
       "\n",
       "           excerpt_wordlen  \n",
       "id                          \n",
       "c12129c31              179  \n",
       "85aa80a4c              169  \n",
       "b69ac6792              166  \n",
       "dd1000b26              164  \n",
       "37c1b32fb              147  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\n",
    "train_df[\"excerpt_wordlen\"] = train_df[\"excerpt\"].apply(lambda x: len(str(x).split()))\n",
    "train_df.drop(['url_legal','license','standard_error'], inplace=True, axis=1)\n",
    "train_df.set_index(\"id\", inplace=True)\n",
    "print(f\"train_df: {train_df.shape}\\n\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exclusive-guatemala",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:22.599462Z",
     "iopub.status.busy": "2021-06-24T18:39:22.598966Z",
     "iopub.status.idle": "2021-06-24T18:39:22.613774Z",
     "shell.execute_reply": "2021-06-24T18:39:22.614348Z",
     "shell.execute_reply.started": "2021-06-19T14:00:34.288049Z"
    },
    "papermill": {
     "duration": 0.057715,
     "end_time": "2021-06-24T18:39:22.614507",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.556792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (7, 2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>excerpt_wordlen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0f722661</th>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0953f0a5</th>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0df072751</th>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04caf4e0c</th>\n",
       "      <td>Cell division is the process by which a parent...</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0e63f8bea</th>\n",
       "      <td>Debugging is the process of finding and resolv...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt  excerpt_wordlen\n",
       "id                                                                           \n",
       "c0f722661  My hope lay in Jack's promise that he would ke...              149\n",
       "f0953f0a5  Dotty continued to go to Mrs. Gray's every nig...              181\n",
       "0df072751  It was a bright and cheerful scene that greete...              174\n",
       "04caf4e0c  Cell division is the process by which a parent...              180\n",
       "0e63f8bea  Debugging is the process of finding and resolv...              168"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n",
    "test_df[\"excerpt_wordlen\"] = test_df[\"excerpt\"].apply(lambda x: len(str(x).split()))\n",
    "test_df.drop(['url_legal','license'], inplace=True, axis=1)\n",
    "test_df.set_index(\"id\", inplace=True)\n",
    "print(f\"test_df: {test_df.shape}\\n\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-brunswick",
   "metadata": {
    "papermill": {
     "duration": 0.038262,
     "end_time": "2021-06-24T18:39:22.690476",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.652214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hungry-occasions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:22.769956Z",
     "iopub.status.busy": "2021-06-24T18:39:22.769236Z",
     "iopub.status.idle": "2021-06-24T18:39:22.775728Z",
     "shell.execute_reply": "2021-06-24T18:39:22.776424Z",
     "shell.execute_reply.started": "2021-06-19T14:00:34.309927Z"
    },
    "papermill": {
     "duration": 0.048859,
     "end_time": "2021-06-24T18:39:22.776592",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.727733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ytrain: (2834,)\n"
     ]
    }
   ],
   "source": [
    "Ytrain = train_df['target'].values\n",
    "Ytrain_strat = pd.qcut(train_df['target'].values, q=5, labels=range(0,5))\n",
    "train_df.drop(['target'], inplace=True, axis=1)\n",
    "print(f\"Ytrain: {Ytrain.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-measurement",
   "metadata": {
    "papermill": {
     "duration": 0.037237,
     "end_time": "2021-06-24T18:39:22.851999",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.814762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "necessary-subscriber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:22.933450Z",
     "iopub.status.busy": "2021-06-24T18:39:22.932749Z",
     "iopub.status.idle": "2021-06-24T18:39:22.935043Z",
     "shell.execute_reply": "2021-06-24T18:39:22.935447Z",
     "shell.execute_reply.started": "2021-06-19T14:00:34.321645Z"
    },
    "papermill": {
     "duration": 0.046053,
     "end_time": "2021-06-24T18:39:22.935566",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.889513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLD = 5\n",
    "NUM_SEED = 1\n",
    "VERBOSE = 1\n",
    "MINI_BATCH_SIZE = 16\n",
    "NUM_EPOCH = 20\n",
    "MAX_LEN = max(train_df['excerpt_wordlen'].max(), \n",
    "              test_df['excerpt_wordlen'].max()) + 11\n",
    "\n",
    "ROBERTA_BASE = \"../input/huggingface-roberta-variants/roberta-base/roberta-base\"\n",
    "BERT_BASE_UNCASED = \"../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased\"\n",
    "XLM_ROBERTA_BASE = \"../input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base\"\n",
    "DISTILROBERTA_BASE = \"../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base\"\n",
    "DISTILBERT_BASE_UNCASED = \"../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-thousand",
   "metadata": {
    "papermill": {
     "duration": 0.037507,
     "end_time": "2021-06-24T18:39:23.010624",
     "exception": false,
     "start_time": "2021-06-24T18:39:22.973117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conceptual-fishing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:23.092009Z",
     "iopub.status.busy": "2021-06-24T18:39:23.091264Z",
     "iopub.status.idle": "2021-06-24T18:39:23.093925Z",
     "shell.execute_reply": "2021-06-24T18:39:23.093511Z",
     "shell.execute_reply.started": "2021-06-19T14:00:34.871920Z"
    },
    "papermill": {
     "duration": 0.045737,
     "end_time": "2021-06-24T18:39:23.094028",
     "exception": false,
     "start_time": "2021-06-24T18:39:23.048291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sent_encode(texts, tokenizer):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    token_type_ids = []\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        tokens = tokenizer.encode_plus(text, max_length=MAX_LEN, truncation=True, \n",
    "                                       padding='max_length', add_special_tokens=True, \n",
    "                                       return_attention_mask=True, return_token_type_ids=True, \n",
    "                                       return_tensors='tf')\n",
    "        \n",
    "        input_ids.append(tokens['input_ids'])\n",
    "        attention_mask.append(tokens['attention_mask'])\n",
    "        token_type_ids.append(tokens['token_type_ids'])\n",
    "\n",
    "    return np.array(input_ids), np.array(attention_mask), np.array(token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "modified-reality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:23.173367Z",
     "iopub.status.busy": "2021-06-24T18:39:23.172594Z",
     "iopub.status.idle": "2021-06-24T18:39:23.175120Z",
     "shell.execute_reply": "2021-06-24T18:39:23.174718Z",
     "shell.execute_reply.started": "2021-06-19T14:00:34.982229Z"
    },
    "papermill": {
     "duration": 0.043761,
     "end_time": "2021-06-24T18:39:23.175221",
     "exception": false,
     "start_time": "2021-06-24T18:39:23.131460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    return tf.math.sqrt(tf.math.reduce_mean((y_true - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "failing-empty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:23.261778Z",
     "iopub.status.busy": "2021-06-24T18:39:23.260996Z",
     "iopub.status.idle": "2021-06-24T18:39:23.263427Z",
     "shell.execute_reply": "2021-06-24T18:39:23.263038Z",
     "shell.execute_reply.started": "2021-06-19T14:00:35.416964Z"
    },
    "papermill": {
     "duration": 0.050304,
     "end_time": "2021-06-24T18:39:23.263529",
     "exception": false,
     "start_time": "2021-06-24T18:39:23.213225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def commonlit_model(transformer_model, use_tokens_type_ids=True):\n",
    "    \n",
    "    input_id = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    token_type_id = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"token_type_ids\")\n",
    "\n",
    "    if use_tokens_type_ids:\n",
    "        embed = transformer_model(input_id, token_type_ids=token_type_id, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    else:\n",
    "        embed = transformer_model(input_id, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    embed = LayerNormalization()(embed)\n",
    "    \n",
    "    x = WeightNormalization(\n",
    "            Conv1D(filters=384, kernel_size=5, \n",
    "                   strides=2, padding='same', \n",
    "                   kernel_regularizer=l2(0.0001),\n",
    "                   kernel_initializer='he_uniform'))(embed)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SpatialDropout1D(rate=0.25)(x)\n",
    "    \n",
    "    x = WeightNormalization(\n",
    "            Conv1D(filters=192, kernel_size=5, \n",
    "                   strides=2, padding='same', \n",
    "                   kernel_regularizer=l2(0.0001),\n",
    "                   kernel_initializer='he_uniform'))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SpatialDropout1D(rate=0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = Dense(units=1, kernel_initializer='lecun_normal')(x)\n",
    "\n",
    "    model = Model(inputs=[input_id, attention_mask, token_type_id], outputs=x, \n",
    "                  name='CommonLit_Readability_Model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-monthly",
   "metadata": {
    "papermill": {
     "duration": 0.037275,
     "end_time": "2021-06-24T18:39:23.337990",
     "exception": false,
     "start_time": "2021-06-24T18:39:23.300715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Roberta-Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-forum",
   "metadata": {
    "papermill": {
     "duration": 0.037426,
     "end_time": "2021-06-24T18:39:23.413156",
     "exception": false,
     "start_time": "2021-06-24T18:39:23.375730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate word tokens and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cathedral-class",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:23.492520Z",
     "iopub.status.busy": "2021-06-24T18:39:23.491929Z",
     "iopub.status.idle": "2021-06-24T18:39:23.745886Z",
     "shell.execute_reply": "2021-06-24T18:39:23.745403Z",
     "shell.execute_reply.started": "2021-06-19T13:02:28.324922Z"
    },
    "papermill": {
     "duration": 0.294642,
     "end_time": "2021-06-24T18:39:23.746018",
     "exception": false,
     "start_time": "2021-06-24T18:39:23.451376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acoustic-airline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:23.828405Z",
     "iopub.status.busy": "2021-06-24T18:39:23.826647Z",
     "iopub.status.idle": "2021-06-24T18:39:30.924109Z",
     "shell.execute_reply": "2021-06-24T18:39:30.923272Z",
     "shell.execute_reply.started": "2021-06-19T13:02:28.71349Z"
    },
    "papermill": {
     "duration": 7.140152,
     "end_time": "2021-06-24T18:39:30.924237",
     "exception": false,
     "start_time": "2021-06-24T18:39:23.784085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2834/2834 [00:06<00:00, 405.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (2834, 216) \n",
      "Attention Mask: (2834, 216) \n",
      "Token-type-ids: (2834, 216)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_id, Xtrain_mask, Xtrain_token = sent_encode(train_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtrain_id = Xtrain_id.reshape((Xtrain_id.shape[0], Xtrain_id.shape[2]))\n",
    "Xtrain_mask = Xtrain_mask.reshape((Xtrain_mask.shape[0], Xtrain_mask.shape[2]))\n",
    "Xtrain_token = Xtrain_token.reshape((Xtrain_token.shape[0], Xtrain_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtrain_id.shape} \\nAttention Mask: {Xtrain_mask.shape} \\nToken-type-ids: {Xtrain_token.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lonely-meter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:31.033696Z",
     "iopub.status.busy": "2021-06-24T18:39:31.032949Z",
     "iopub.status.idle": "2021-06-24T18:39:31.052944Z",
     "shell.execute_reply": "2021-06-24T18:39:31.052228Z",
     "shell.execute_reply.started": "2021-06-19T13:02:36.363407Z"
    },
    "papermill": {
     "duration": 0.076854,
     "end_time": "2021-06-24T18:39:31.053087",
     "exception": false,
     "start_time": "2021-06-24T18:39:30.976233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 523.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (7, 216) \n",
      "Attention Mask: (7, 216) \n",
      "Token-type-ids: (7, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xtest_id, Xtest_mask, Xtest_token = sent_encode(test_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtest_id = Xtest_id.reshape((Xtest_id.shape[0], Xtest_id.shape[2]))\n",
    "Xtest_mask = Xtest_mask.reshape((Xtest_mask.shape[0], Xtest_mask.shape[2]))\n",
    "Xtest_token = Xtest_token.reshape((Xtest_token.shape[0], Xtest_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtest_id.shape} \\nAttention Mask: {Xtest_mask.shape} \\nToken-type-ids: {Xtest_token.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-river",
   "metadata": {
    "papermill": {
     "duration": 0.052957,
     "end_time": "2021-06-24T18:39:31.160314",
     "exception": false,
     "start_time": "2021-06-24T18:39:31.107357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initialize the Roberta-Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efficient-floor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:31.268950Z",
     "iopub.status.busy": "2021-06-24T18:39:31.268414Z",
     "iopub.status.idle": "2021-06-24T18:39:43.671506Z",
     "shell.execute_reply": "2021-06-24T18:39:43.670602Z",
     "shell.execute_reply.started": "2021-06-19T13:02:36.39258Z"
    },
    "papermill": {
     "duration": 12.458811,
     "end_time": "2021-06-24T18:39:43.671631",
     "exception": false,
     "start_time": "2021-06-24T18:39:31.212820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/huggingface-roberta-variants/roberta-base/roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../input/huggingface-roberta-variants/roberta-base/roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(ROBERTA_BASE)\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFRobertaModel.from_pretrained(ROBERTA_BASE, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "preceding-arrest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:43.792641Z",
     "iopub.status.busy": "2021-06-24T18:39:43.791993Z",
     "iopub.status.idle": "2021-06-24T18:39:49.908863Z",
     "shell.execute_reply": "2021-06-24T18:39:49.908057Z",
     "shell.execute_reply.started": "2021-06-19T13:02:48.554182Z"
    },
    "papermill": {
     "duration": 6.1824,
     "end_time": "2021-06-24T18:39:49.908989",
     "exception": false,
     "start_time": "2021-06-24T18:39:43.726589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CommonLit_Readability_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "                                                                 token_type_ids[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 216, 768)     1536        tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization (WeightNor (None, 108, 384)     2950273     layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 108, 384)     768         weight_normalization[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 108, 384)     0           layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 108, 384)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_1 (WeightN (None, 54, 192)      737857      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 54, 192)      384         weight_normalization_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 54, 192)      0           layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 54, 192)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10368)        0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 10368)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            10369       dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 128,346,819\n",
      "Trainable params: 126,503,041\n",
      "Non-trainable params: 1,843,778\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commonlit_model(transformer_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-diploma",
   "metadata": {
    "papermill": {
     "duration": 0.053523,
     "end_time": "2021-06-24T18:39:50.017171",
     "exception": false,
     "start_time": "2021-06-24T18:39:49.963648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "romance-detector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:39:50.136987Z",
     "iopub.status.busy": "2021-06-24T18:39:50.136139Z",
     "iopub.status.idle": "2021-06-24T18:41:17.859835Z",
     "shell.execute_reply": "2021-06-24T18:41:17.859358Z",
     "shell.execute_reply.started": "2021-06-19T13:02:55.303531Z"
    },
    "papermill": {
     "duration": 87.788087,
     "end_time": "2021-06-24T18:41:17.859973",
     "exception": false,
     "start_time": "2021-06-24T18:39:50.071886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-83 | Fold-0 | OOF Score: 0.5818927901011692\n",
      "Seed-83 | Fold-1 | OOF Score: 0.3159899519247878\n",
      "Seed-83 | Fold-2 | OOF Score: 0.26385922701852865\n",
      "Seed-83 | Fold-3 | OOF Score: 0.24831539858739213\n",
      "Seed-83 | Fold-4 | OOF Score: 0.21069192041065657\n",
      "\n",
      "Seed: 83 | Aggregate OOF Score: 0.32414985760850684\n",
      "\n",
      "\n",
      "Aggregate OOF Score: 0.32414985760850684\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "seeds = np.random.randint(0, 100, size=NUM_SEED)\n",
    "\n",
    "counter = 0\n",
    "oof_score = 0\n",
    "y_pred_final1 = 0\n",
    "\n",
    "\n",
    "for sidx, seed in enumerate(seeds):\n",
    "    seed_score = 0\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "    for idx, (train, val) in enumerate(kfold.split(Xtrain_id, Ytrain_strat)):\n",
    "        counter += 1\n",
    "\n",
    "        train_x_id, train_x_mask, train_x_token = Xtrain_id[train], Xtrain_mask[train], Xtrain_token[train]\n",
    "        val_x_id, val_x_mask, val_x_token = Xtrain_id[val], Xtrain_mask[val], Xtrain_token[val]\n",
    "        train_y, val_y = Ytrain[train], Ytrain[val]\n",
    "\n",
    "        model = commonlit_model(transformer_model)\n",
    "        \n",
    "        model.load_weights(f'../input/commonlit-roberta-variants-p1/Roberta-Base/CLRP_Roberta_Base_{counter}C.h5')\n",
    "        \n",
    "        y_pred = model.predict([val_x_id, val_x_mask, val_x_token])\n",
    "        y_pred_final1 += model.predict([Xtest_id, Xtest_mask, Xtest_token])\n",
    "        \n",
    "        score = np.sqrt(mean_squared_error(val_y, y_pred))\n",
    "        oof_score += score\n",
    "        seed_score += score\n",
    "        print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n",
    "    \n",
    "    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n",
    "\n",
    "\n",
    "y_pred_final1 = y_pred_final1 / float(counter)\n",
    "oof_score /= float(counter)\n",
    "print(\"Aggregate OOF Score: {}\".format(oof_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-richards",
   "metadata": {
    "papermill": {
     "duration": 0.054975,
     "end_time": "2021-06-24T18:41:17.970734",
     "exception": false,
     "start_time": "2021-06-24T18:41:17.915759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## XLM-Roberta-Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-waste",
   "metadata": {
    "papermill": {
     "duration": 0.054376,
     "end_time": "2021-06-24T18:41:18.079402",
     "exception": false,
     "start_time": "2021-06-24T18:41:18.025026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate word tokens and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decreased-details",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:41:18.193956Z",
     "iopub.status.busy": "2021-06-24T18:41:18.193390Z",
     "iopub.status.idle": "2021-06-24T18:41:18.788644Z",
     "shell.execute_reply": "2021-06-24T18:41:18.788117Z",
     "shell.execute_reply.started": "2021-06-19T13:04:37.167926Z"
    },
    "papermill": {
     "duration": 0.654021,
     "end_time": "2021-06-24T18:41:18.788809",
     "exception": false,
     "start_time": "2021-06-24T18:41:18.134788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained(XLM_ROBERTA_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "saved-correction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:41:18.904410Z",
     "iopub.status.busy": "2021-06-24T18:41:18.903879Z",
     "iopub.status.idle": "2021-06-24T18:41:21.799733Z",
     "shell.execute_reply": "2021-06-24T18:41:21.798557Z",
     "shell.execute_reply.started": "2021-06-19T13:04:37.874223Z"
    },
    "papermill": {
     "duration": 2.955546,
     "end_time": "2021-06-24T18:41:21.799870",
     "exception": false,
     "start_time": "2021-06-24T18:41:18.844324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2834/2834 [00:02<00:00, 1021.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (2834, 216) \n",
      "Attention Mask: (2834, 216) \n",
      "Token-type-ids: (2834, 216)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_id, Xtrain_mask, Xtrain_token = sent_encode(train_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtrain_id = Xtrain_id.reshape((Xtrain_id.shape[0], Xtrain_id.shape[2]))\n",
    "Xtrain_mask = Xtrain_mask.reshape((Xtrain_mask.shape[0], Xtrain_mask.shape[2]))\n",
    "Xtrain_token = Xtrain_token.reshape((Xtrain_token.shape[0], Xtrain_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtrain_id.shape} \\nAttention Mask: {Xtrain_mask.shape} \\nToken-type-ids: {Xtrain_token.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "grateful-advocacy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:41:21.930002Z",
     "iopub.status.busy": "2021-06-24T18:41:21.929162Z",
     "iopub.status.idle": "2021-06-24T18:41:21.944161Z",
     "shell.execute_reply": "2021-06-24T18:41:21.944566Z",
     "shell.execute_reply.started": "2021-06-19T13:04:41.039818Z"
    },
    "papermill": {
     "duration": 0.082926,
     "end_time": "2021-06-24T18:41:21.944720",
     "exception": false,
     "start_time": "2021-06-24T18:41:21.861794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 906.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (7, 216) \n",
      "Attention Mask: (7, 216) \n",
      "Token-type-ids: (7, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xtest_id, Xtest_mask, Xtest_token = sent_encode(test_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtest_id = Xtest_id.reshape((Xtest_id.shape[0], Xtest_id.shape[2]))\n",
    "Xtest_mask = Xtest_mask.reshape((Xtest_mask.shape[0], Xtest_mask.shape[2]))\n",
    "Xtest_token = Xtest_token.reshape((Xtest_token.shape[0], Xtest_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtest_id.shape} \\nAttention Mask: {Xtest_mask.shape} \\nToken-type-ids: {Xtest_token.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-express",
   "metadata": {
    "papermill": {
     "duration": 0.062548,
     "end_time": "2021-06-24T18:41:22.070065",
     "exception": false,
     "start_time": "2021-06-24T18:41:22.007517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initialize the XLMRoberta-Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quiet-berkeley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:41:22.200571Z",
     "iopub.status.busy": "2021-06-24T18:41:22.200060Z",
     "iopub.status.idle": "2021-06-24T18:41:37.333112Z",
     "shell.execute_reply": "2021-06-24T18:41:37.333513Z",
     "shell.execute_reply.started": "2021-06-19T13:04:41.063251Z"
    },
    "papermill": {
     "duration": 15.200518,
     "end_time": "2021-06-24T18:41:37.333658",
     "exception": false,
     "start_time": "2021-06-24T18:41:22.133140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = XLMRobertaConfig.from_pretrained(XLM_ROBERTA_BASE)\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFXLMRobertaModel.from_pretrained(XLM_ROBERTA_BASE, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hairy-penalty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:41:37.470442Z",
     "iopub.status.busy": "2021-06-24T18:41:37.469632Z",
     "iopub.status.idle": "2021-06-24T18:41:39.065293Z",
     "shell.execute_reply": "2021-06-24T18:41:39.064847Z",
     "shell.execute_reply.started": "2021-06-19T13:04:51.779586Z"
    },
    "papermill": {
     "duration": 1.665784,
     "end_time": "2021-06-24T18:41:39.065417",
     "exception": false,
     "start_time": "2021-06-24T18:41:37.399633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CommonLit_Readability_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tfxlm_roberta_model (TFXLMRober TFBaseModelOutputWit 278043648   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "                                                                 token_type_ids[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, 216, 768)     1536        tfxlm_roberta_model[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_12 (Weight (None, 108, 384)     2950273     layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 108, 384)     768         weight_normalization_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 108, 384)     0           layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 108, 384)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_13 (Weight (None, 54, 192)      737857      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, 54, 192)      384         weight_normalization_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 54, 192)      0           layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 54, 192)      0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 10368)        0           spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 10368)        0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            10369       dropout_80[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 281,744,835\n",
      "Trainable params: 279,901,057\n",
      "Non-trainable params: 1,843,778\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commonlit_model(transformer_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-building",
   "metadata": {
    "papermill": {
     "duration": 0.064117,
     "end_time": "2021-06-24T18:41:39.194547",
     "exception": false,
     "start_time": "2021-06-24T18:41:39.130430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "matched-science",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:41:39.332421Z",
     "iopub.status.busy": "2021-06-24T18:41:39.331510Z",
     "iopub.status.idle": "2021-06-24T18:43:46.005011Z",
     "shell.execute_reply": "2021-06-24T18:43:46.004524Z",
     "shell.execute_reply.started": "2021-06-19T13:04:53.560656Z"
    },
    "papermill": {
     "duration": 126.74655,
     "end_time": "2021-06-24T18:43:46.005139",
     "exception": false,
     "start_time": "2021-06-24T18:41:39.258589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-85 | Fold-0 | OOF Score: 0.6724309328381948\n",
      "Seed-85 | Fold-1 | OOF Score: 0.434881209176005\n",
      "Seed-85 | Fold-2 | OOF Score: 0.3692729401043699\n",
      "Seed-85 | Fold-3 | OOF Score: 0.2977010268270374\n",
      "Seed-85 | Fold-4 | OOF Score: 0.3885452823465845\n",
      "\n",
      "Seed: 85 | Aggregate OOF Score: 0.43256627825843835\n",
      "\n",
      "\n",
      "Aggregate OOF Score: 0.43256627825843835\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(29)\n",
    "seeds = np.random.randint(0, 100, size=NUM_SEED)\n",
    "\n",
    "counter = 0\n",
    "oof_score = 0\n",
    "y_pred_final2 = 0\n",
    "\n",
    "\n",
    "for sidx, seed in enumerate(seeds):\n",
    "    seed_score = 0\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "    for idx, (train, val) in enumerate(kfold.split(Xtrain_id, Ytrain_strat)):\n",
    "        counter += 1\n",
    "\n",
    "        train_x_id, train_x_mask, train_x_token = Xtrain_id[train], Xtrain_mask[train], Xtrain_token[train]\n",
    "        val_x_id, val_x_mask, val_x_token = Xtrain_id[val], Xtrain_mask[val], Xtrain_token[val]\n",
    "        train_y, val_y = Ytrain[train], Ytrain[val]\n",
    "\n",
    "        model = commonlit_model(transformer_model)\n",
    "        \n",
    "        model.load_weights(f'../input/commonlit-roberta-variants-p1/XLM-Roberta-Base/CLRP_XLMRoberta_Base_{counter}C.h5')\n",
    "        \n",
    "        y_pred = model.predict([val_x_id, val_x_mask, val_x_token])\n",
    "        y_pred_final2 += model.predict([Xtest_id, Xtest_mask, Xtest_token])\n",
    "        \n",
    "        score = np.sqrt(mean_squared_error(val_y, y_pred))\n",
    "        oof_score += score\n",
    "        seed_score += score\n",
    "        print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n",
    "    \n",
    "    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n",
    "\n",
    "\n",
    "y_pred_final2 = y_pred_final2 / float(counter)\n",
    "oof_score /= float(counter)\n",
    "print(\"Aggregate OOF Score: {}\".format(oof_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-medicaid",
   "metadata": {
    "papermill": {
     "duration": 0.065091,
     "end_time": "2021-06-24T18:43:46.136389",
     "exception": false,
     "start_time": "2021-06-24T18:43:46.071298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DistilRoberta-Base-Uncased Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-grove",
   "metadata": {
    "papermill": {
     "duration": 0.064306,
     "end_time": "2021-06-24T18:43:46.266209",
     "exception": false,
     "start_time": "2021-06-24T18:43:46.201903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate word tokens and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "characteristic-involvement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:43:46.399578Z",
     "iopub.status.busy": "2021-06-24T18:43:46.399071Z",
     "iopub.status.idle": "2021-06-24T18:43:46.544830Z",
     "shell.execute_reply": "2021-06-24T18:43:46.544292Z",
     "shell.execute_reply.started": "2021-06-17T15:22:32.634165Z"
    },
    "papermill": {
     "duration": 0.214064,
     "end_time": "2021-06-24T18:43:46.544952",
     "exception": false,
     "start_time": "2021-06-24T18:43:46.330888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(DISTILROBERTA_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "placed-wireless",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:43:46.684576Z",
     "iopub.status.busy": "2021-06-24T18:43:46.683659Z",
     "iopub.status.idle": "2021-06-24T18:43:51.887963Z",
     "shell.execute_reply": "2021-06-24T18:43:51.888332Z",
     "shell.execute_reply.started": "2021-06-17T15:22:33.083072Z"
    },
    "papermill": {
     "duration": 5.277729,
     "end_time": "2021-06-24T18:43:51.888480",
     "exception": false,
     "start_time": "2021-06-24T18:43:46.610751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2834/2834 [00:05<00:00, 556.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (2834, 216) \n",
      "Attention Mask: (2834, 216) \n",
      "Token-type-ids: (2834, 216)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_id, Xtrain_mask, Xtrain_token = sent_encode(train_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtrain_id = Xtrain_id.reshape((Xtrain_id.shape[0], Xtrain_id.shape[2]))\n",
    "Xtrain_mask = Xtrain_mask.reshape((Xtrain_mask.shape[0], Xtrain_mask.shape[2]))\n",
    "Xtrain_token = Xtrain_token.reshape((Xtrain_token.shape[0], Xtrain_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtrain_id.shape} \\nAttention Mask: {Xtrain_mask.shape} \\nToken-type-ids: {Xtrain_token.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "incorporated-reason",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:43:52.050959Z",
     "iopub.status.busy": "2021-06-24T18:43:52.050171Z",
     "iopub.status.idle": "2021-06-24T18:43:52.068865Z",
     "shell.execute_reply": "2021-06-24T18:43:52.069294Z",
     "shell.execute_reply.started": "2021-06-17T15:22:48.369124Z"
    },
    "papermill": {
     "duration": 0.102221,
     "end_time": "2021-06-24T18:43:52.069417",
     "exception": false,
     "start_time": "2021-06-24T18:43:51.967196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 537.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (7, 216) \n",
      "Attention Mask: (7, 216) \n",
      "Token-type-ids: (7, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xtest_id, Xtest_mask, Xtest_token = sent_encode(test_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtest_id = Xtest_id.reshape((Xtest_id.shape[0], Xtest_id.shape[2]))\n",
    "Xtest_mask = Xtest_mask.reshape((Xtest_mask.shape[0], Xtest_mask.shape[2]))\n",
    "Xtest_token = Xtest_token.reshape((Xtest_token.shape[0], Xtest_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtest_id.shape} \\nAttention Mask: {Xtest_mask.shape} \\nToken-type-ids: {Xtest_token.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-residence",
   "metadata": {
    "papermill": {
     "duration": 0.078763,
     "end_time": "2021-06-24T18:43:52.227705",
     "exception": false,
     "start_time": "2021-06-24T18:43:52.148942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initialize the DistilRoberta-Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "forward-belief",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:43:52.390144Z",
     "iopub.status.busy": "2021-06-24T18:43:52.389578Z",
     "iopub.status.idle": "2021-06-24T18:43:57.026395Z",
     "shell.execute_reply": "2021-06-24T18:43:57.026994Z",
     "shell.execute_reply.started": "2021-06-17T15:22:48.41938Z"
    },
    "papermill": {
     "duration": 4.720096,
     "end_time": "2021-06-24T18:43:57.027155",
     "exception": false,
     "start_time": "2021-06-24T18:43:52.307059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(DISTILROBERTA_BASE)\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFRobertaModel.from_pretrained(DISTILROBERTA_BASE, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "surrounded-machinery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:43:57.204595Z",
     "iopub.status.busy": "2021-06-24T18:43:57.203837Z",
     "iopub.status.idle": "2021-06-24T18:43:58.138369Z",
     "shell.execute_reply": "2021-06-24T18:43:58.137529Z",
     "shell.execute_reply.started": "2021-06-17T15:22:53.48215Z"
    },
    "papermill": {
     "duration": 1.026922,
     "end_time": "2021-06-24T18:43:58.138508",
     "exception": false,
     "start_time": "2021-06-24T18:43:57.111586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CommonLit_Readability_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_36 (LayerNo (None, 216, 768)     1536        tf_roberta_model_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_24 (Weight (None, 108, 384)     2950273     layer_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_37 (LayerNo (None, 108, 384)     768         weight_normalization_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 108, 384)     0           layer_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 108, 384)     0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_25 (Weight (None, 54, 192)      737857      spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_38 (LayerNo (None, 54, 192)      384         weight_normalization_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 54, 192)      0           layer_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 54, 192)      0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 10368)        0           spatial_dropout1d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 10368)        0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            10369       dropout_105[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 85,819,587\n",
      "Trainable params: 83,975,809\n",
      "Non-trainable params: 1,843,778\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commonlit_model(transformer_model, use_tokens_type_ids=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-boulder",
   "metadata": {
    "papermill": {
     "duration": 0.079754,
     "end_time": "2021-06-24T18:43:58.298949",
     "exception": false,
     "start_time": "2021-06-24T18:43:58.219195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dress-label",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:43:58.468817Z",
     "iopub.status.busy": "2021-06-24T18:43:58.467590Z",
     "iopub.status.idle": "2021-06-24T18:44:50.861979Z",
     "shell.execute_reply": "2021-06-24T18:44:50.861509Z",
     "shell.execute_reply.started": "2021-06-17T15:22:59.247967Z"
    },
    "papermill": {
     "duration": 52.483477,
     "end_time": "2021-06-24T18:44:50.862116",
     "exception": false,
     "start_time": "2021-06-24T18:43:58.378639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-82 | Fold-0 | OOF Score: 0.5335939518626852\n",
      "Seed-82 | Fold-1 | OOF Score: 0.3364318069384966\n",
      "Seed-82 | Fold-2 | OOF Score: 0.32787244656054687\n",
      "Seed-82 | Fold-3 | OOF Score: 0.25105166712808297\n",
      "Seed-82 | Fold-4 | OOF Score: 0.23226592424908787\n",
      "\n",
      "Seed: 82 | Aggregate OOF Score: 0.3362431593477799\n",
      "\n",
      "\n",
      "Aggregate OOF Score: 0.3362431593477799\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(31)\n",
    "seeds = np.random.randint(0, 100, size=NUM_SEED)\n",
    "\n",
    "counter = 0\n",
    "oof_score = 0\n",
    "y_pred_final3 = 0\n",
    "\n",
    "\n",
    "for sidx, seed in enumerate(seeds):\n",
    "    seed_score = 0\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "    for idx, (train, val) in enumerate(kfold.split(Xtrain_id, Ytrain_strat)):\n",
    "        counter += 1\n",
    "\n",
    "        train_x_id, train_x_mask, train_x_token = Xtrain_id[train], Xtrain_mask[train], Xtrain_token[train]\n",
    "        val_x_id, val_x_mask, val_x_token = Xtrain_id[val], Xtrain_mask[val], Xtrain_token[val]\n",
    "        train_y, val_y = Ytrain[train], Ytrain[val]\n",
    "\n",
    "        model = commonlit_model(transformer_model, use_tokens_type_ids=False)\n",
    "        \n",
    "        model.load_weights(f'../input/commonlit-roberta-variants-p1/DistilRoberta-Base/CLRP_DistilRoberta_Base_{counter}C.h5')\n",
    "        \n",
    "        y_pred = model.predict([val_x_id, val_x_mask, val_x_token])\n",
    "        y_pred_final3 += model.predict([Xtest_id, Xtest_mask, Xtest_token])\n",
    "        \n",
    "        score = np.sqrt(mean_squared_error(val_y, y_pred))\n",
    "        oof_score += score\n",
    "        seed_score += score\n",
    "        print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n",
    "    \n",
    "    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n",
    "\n",
    "\n",
    "y_pred_final3 = y_pred_final3 / float(counter)\n",
    "oof_score /= float(counter)\n",
    "print(\"Aggregate OOF Score: {}\".format(oof_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-tenant",
   "metadata": {
    "papermill": {
     "duration": 0.080629,
     "end_time": "2021-06-24T18:44:51.024781",
     "exception": false,
     "start_time": "2021-06-24T18:44:50.944152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bert-Base-Uncased Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-store",
   "metadata": {
    "papermill": {
     "duration": 0.080714,
     "end_time": "2021-06-24T18:44:51.186444",
     "exception": false,
     "start_time": "2021-06-24T18:44:51.105730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate word tokens and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mexican-vegetarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:44:51.352068Z",
     "iopub.status.busy": "2021-06-24T18:44:51.351510Z",
     "iopub.status.idle": "2021-06-24T18:44:51.774954Z",
     "shell.execute_reply": "2021-06-24T18:44:51.774428Z",
     "shell.execute_reply.started": "2021-06-19T14:00:41.221915Z"
    },
    "papermill": {
     "duration": 0.50766,
     "end_time": "2021-06-24T18:44:51.775083",
     "exception": false,
     "start_time": "2021-06-24T18:44:51.267423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_BASE_UNCASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "useful-nelson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:44:51.944420Z",
     "iopub.status.busy": "2021-06-24T18:44:51.943602Z",
     "iopub.status.idle": "2021-06-24T18:45:07.263337Z",
     "shell.execute_reply": "2021-06-24T18:45:07.263737Z",
     "shell.execute_reply.started": "2021-06-19T14:00:41.761646Z"
    },
    "papermill": {
     "duration": 15.40703,
     "end_time": "2021-06-24T18:45:07.263905",
     "exception": false,
     "start_time": "2021-06-24T18:44:51.856875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2834/2834 [00:15<00:00, 186.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (2834, 216) \n",
      "Attention Mask: (2834, 216) \n",
      "Token-type-ids: (2834, 216)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_id, Xtrain_mask, Xtrain_token = sent_encode(train_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtrain_id = Xtrain_id.reshape((Xtrain_id.shape[0], Xtrain_id.shape[2]))\n",
    "Xtrain_mask = Xtrain_mask.reshape((Xtrain_mask.shape[0], Xtrain_mask.shape[2]))\n",
    "Xtrain_token = Xtrain_token.reshape((Xtrain_token.shape[0], Xtrain_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtrain_id.shape} \\nAttention Mask: {Xtrain_mask.shape} \\nToken-type-ids: {Xtrain_token.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "thorough-pillow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:45:07.506388Z",
     "iopub.status.busy": "2021-06-24T18:45:07.505858Z",
     "iopub.status.idle": "2021-06-24T18:45:07.549038Z",
     "shell.execute_reply": "2021-06-24T18:45:07.548597Z",
     "shell.execute_reply.started": "2021-06-19T14:00:59.036942Z"
    },
    "papermill": {
     "duration": 0.1661,
     "end_time": "2021-06-24T18:45:07.549153",
     "exception": false,
     "start_time": "2021-06-24T18:45:07.383053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 201.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (7, 216) \n",
      "Attention Mask: (7, 216) \n",
      "Token-type-ids: (7, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xtest_id, Xtest_mask, Xtest_token = sent_encode(test_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtest_id = Xtest_id.reshape((Xtest_id.shape[0], Xtest_id.shape[2]))\n",
    "Xtest_mask = Xtest_mask.reshape((Xtest_mask.shape[0], Xtest_mask.shape[2]))\n",
    "Xtest_token = Xtest_token.reshape((Xtest_token.shape[0], Xtest_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtest_id.shape} \\nAttention Mask: {Xtest_mask.shape} \\nToken-type-ids: {Xtest_token.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-footwear",
   "metadata": {
    "papermill": {
     "duration": 0.118287,
     "end_time": "2021-06-24T18:45:07.785777",
     "exception": false,
     "start_time": "2021-06-24T18:45:07.667490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initialize the Bert-Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nearby-vaccine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:45:08.028757Z",
     "iopub.status.busy": "2021-06-24T18:45:08.028217Z",
     "iopub.status.idle": "2021-06-24T18:45:18.672029Z",
     "shell.execute_reply": "2021-06-24T18:45:18.671581Z",
     "shell.execute_reply.started": "2021-06-19T14:01:02.611922Z"
    },
    "papermill": {
     "duration": 10.768065,
     "end_time": "2021-06-24T18:45:18.672151",
     "exception": false,
     "start_time": "2021-06-24T18:45:07.904086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig()\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFBertModel.from_pretrained(BERT_BASE_UNCASED, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "personal-causing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:45:18.918539Z",
     "iopub.status.busy": "2021-06-24T18:45:18.917746Z",
     "iopub.status.idle": "2021-06-24T18:45:22.147761Z",
     "shell.execute_reply": "2021-06-24T18:45:22.146296Z",
     "shell.execute_reply.started": "2021-06-19T14:01:15.336126Z"
    },
    "papermill": {
     "duration": 3.356688,
     "end_time": "2021-06-24T18:45:22.148069",
     "exception": false,
     "start_time": "2021-06-24T18:45:18.791381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CommonLit_Readability_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "                                                                 token_type_ids[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_54 (LayerNo (None, 216, 768)     1536        tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_36 (Weight (None, 108, 384)     2950273     layer_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_55 (LayerNo (None, 108, 384)     768         weight_normalization_36[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 108, 384)     0           layer_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, 108, 384)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_37 (Weight (None, 54, 192)      737857      spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_56 (LayerNo (None, 54, 192)      384         weight_normalization_37[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 54, 192)      0           layer_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, 54, 192)      0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 10368)        0           spatial_dropout1d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 10368)        0           flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            10369       dropout_148[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 113,183,427\n",
      "Trainable params: 111,339,649\n",
      "Non-trainable params: 1,843,778\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commonlit_model(transformer_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-government",
   "metadata": {
    "papermill": {
     "duration": 0.217163,
     "end_time": "2021-06-24T18:45:22.598446",
     "exception": false,
     "start_time": "2021-06-24T18:45:22.381283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "european-lafayette",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:45:22.865592Z",
     "iopub.status.busy": "2021-06-24T18:45:22.864795Z",
     "iopub.status.idle": "2021-06-24T18:46:33.624824Z",
     "shell.execute_reply": "2021-06-24T18:46:33.624373Z",
     "shell.execute_reply.started": "2021-06-19T14:01:21.689522Z"
    },
    "papermill": {
     "duration": 70.885459,
     "end_time": "2021-06-24T18:46:33.624960",
     "exception": false,
     "start_time": "2021-06-24T18:45:22.739501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-83 | Fold-0 | OOF Score: 0.5780486277112108\n",
      "Seed-83 | Fold-1 | OOF Score: 0.29599539757095084\n",
      "Seed-83 | Fold-2 | OOF Score: 0.34276718634690434\n",
      "Seed-83 | Fold-3 | OOF Score: 0.3492470996393605\n",
      "Seed-83 | Fold-4 | OOF Score: 0.2429676229549472\n",
      "\n",
      "Seed: 83 | Aggregate OOF Score: 0.3618051868446747\n",
      "\n",
      "\n",
      "Aggregate OOF Score: 0.3618051868446747\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "seeds = np.random.randint(0, 100, size=NUM_SEED)\n",
    "\n",
    "counter = 0\n",
    "oof_score = 0\n",
    "y_pred_final4 = 0\n",
    "\n",
    "\n",
    "for sidx, seed in enumerate(seeds):\n",
    "    seed_score = 0\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "    for idx, (train, val) in enumerate(kfold.split(Xtrain_id, Ytrain_strat)):\n",
    "        counter += 1\n",
    "\n",
    "        train_x_id, train_x_mask, train_x_token = Xtrain_id[train], Xtrain_mask[train], Xtrain_token[train]\n",
    "        val_x_id, val_x_mask, val_x_token = Xtrain_id[val], Xtrain_mask[val], Xtrain_token[val]\n",
    "        train_y, val_y = Ytrain[train], Ytrain[val]\n",
    "\n",
    "        model = commonlit_model(transformer_model)\n",
    "        \n",
    "        model.load_weights(f'../input/commonlit-bert-variants-p1/Bert-Base-Uncased/CLRP_Bert_Base_Uncased_{counter}C.h5')\n",
    "        \n",
    "        y_pred = model.predict([val_x_id, val_x_mask, val_x_token])\n",
    "        y_pred_final4 += model.predict([Xtest_id, Xtest_mask, Xtest_token])\n",
    "        \n",
    "        score = np.sqrt(mean_squared_error(val_y, y_pred))\n",
    "        oof_score += score\n",
    "        seed_score += score\n",
    "        print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n",
    "    \n",
    "    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n",
    "\n",
    "\n",
    "y_pred_final4 = y_pred_final4 / float(counter)\n",
    "oof_score /= float(counter)\n",
    "print(\"Aggregate OOF Score: {}\".format(oof_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-asian",
   "metadata": {
    "papermill": {
     "duration": 0.120307,
     "end_time": "2021-06-24T18:46:33.868571",
     "exception": false,
     "start_time": "2021-06-24T18:46:33.748264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DistilBert-Base-Uncased Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-theology",
   "metadata": {
    "papermill": {
     "duration": 0.119838,
     "end_time": "2021-06-24T18:46:34.110374",
     "exception": false,
     "start_time": "2021-06-24T18:46:33.990536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate word tokens and attention masks¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "scientific-collins",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:46:34.355529Z",
     "iopub.status.busy": "2021-06-24T18:46:34.354980Z",
     "iopub.status.idle": "2021-06-24T18:46:34.421457Z",
     "shell.execute_reply": "2021-06-24T18:46:34.421008Z"
    },
    "papermill": {
     "duration": 0.189939,
     "end_time": "2021-06-24T18:46:34.421581",
     "exception": false,
     "start_time": "2021-06-24T18:46:34.231642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(DISTILBERT_BASE_UNCASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "concrete-reputation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:46:34.668537Z",
     "iopub.status.busy": "2021-06-24T18:46:34.667986Z",
     "iopub.status.idle": "2021-06-24T18:46:49.883819Z",
     "shell.execute_reply": "2021-06-24T18:46:49.883383Z"
    },
    "papermill": {
     "duration": 15.342097,
     "end_time": "2021-06-24T18:46:49.883941",
     "exception": false,
     "start_time": "2021-06-24T18:46:34.541844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2834/2834 [00:15<00:00, 187.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (2834, 216) \n",
      "Attention Mask: (2834, 216) \n",
      "Token-type-ids: (2834, 216)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_id, Xtrain_mask, Xtrain_token = sent_encode(train_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtrain_id = Xtrain_id.reshape((Xtrain_id.shape[0], Xtrain_id.shape[2]))\n",
    "Xtrain_mask = Xtrain_mask.reshape((Xtrain_mask.shape[0], Xtrain_mask.shape[2]))\n",
    "Xtrain_token = Xtrain_token.reshape((Xtrain_token.shape[0], Xtrain_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtrain_id.shape} \\nAttention Mask: {Xtrain_mask.shape} \\nToken-type-ids: {Xtrain_token.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fixed-offer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:46:50.283620Z",
     "iopub.status.busy": "2021-06-24T18:46:50.282831Z",
     "iopub.status.idle": "2021-06-24T18:46:50.346151Z",
     "shell.execute_reply": "2021-06-24T18:46:50.347098Z"
    },
    "papermill": {
     "duration": 0.304111,
     "end_time": "2021-06-24T18:46:50.347281",
     "exception": false,
     "start_time": "2021-06-24T18:46:50.043170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 114.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-ids: (7, 216) \n",
      "Attention Mask: (7, 216) \n",
      "Token-type-ids: (7, 216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Xtest_id, Xtest_mask, Xtest_token = sent_encode(test_df['excerpt'].values, tokenizer)\n",
    "\n",
    "Xtest_id = Xtest_id.reshape((Xtest_id.shape[0], Xtest_id.shape[2]))\n",
    "Xtest_mask = Xtest_mask.reshape((Xtest_mask.shape[0], Xtest_mask.shape[2]))\n",
    "Xtest_token = Xtest_token.reshape((Xtest_token.shape[0], Xtest_token.shape[2]))\n",
    "    \n",
    "print(f\"Input-ids: {Xtest_id.shape} \\nAttention Mask: {Xtest_mask.shape} \\nToken-type-ids: {Xtest_token.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-forty",
   "metadata": {
    "papermill": {
     "duration": 0.161959,
     "end_time": "2021-06-24T18:46:50.818541",
     "exception": false,
     "start_time": "2021-06-24T18:46:50.656582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initialize the DistilBert-Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "laden-swaziland",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:46:51.142088Z",
     "iopub.status.busy": "2021-06-24T18:46:51.141470Z",
     "iopub.status.idle": "2021-06-24T18:46:55.352285Z",
     "shell.execute_reply": "2021-06-24T18:46:55.351865Z"
    },
    "papermill": {
     "duration": 4.374528,
     "end_time": "2021-06-24T18:46:55.352407",
     "exception": false,
     "start_time": "2021-06-24T18:46:50.977879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at ../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config = DistilBertConfig()\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFDistilBertModel.from_pretrained(DISTILBERT_BASE_UNCASED, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "documentary-dominant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:46:55.685175Z",
     "iopub.status.busy": "2021-06-24T18:46:55.684332Z",
     "iopub.status.idle": "2021-06-24T18:46:58.000549Z",
     "shell.execute_reply": "2021-06-24T18:46:58.000039Z"
    },
    "papermill": {
     "duration": 2.486753,
     "end_time": "2021-06-24T18:46:58.000689",
     "exception": false,
     "start_time": "2021-06-24T18:46:55.513936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CommonLit_Readability_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_72 (LayerNo (None, 216, 768)     1536        tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_48 (Weight (None, 108, 384)     2950273     layer_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_73 (LayerNo (None, 108, 384)     768         weight_normalization_48[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 108, 384)     0           layer_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, 108, 384)     0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_49 (Weight (None, 54, 192)      737857      spatial_dropout1d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_74 (LayerNo (None, 54, 192)      384         weight_normalization_49[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 54, 192)      0           layer_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_49 (SpatialDr (None, 54, 192)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 10368)        0           spatial_dropout1d_49[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 10368)        0           flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 216)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            10369       dropout_173[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 70,064,067\n",
      "Trainable params: 68,220,289\n",
      "Non-trainable params: 1,843,778\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = commonlit_model(transformer_model, use_tokens_type_ids=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-malta",
   "metadata": {
    "papermill": {
     "duration": 0.162821,
     "end_time": "2021-06-24T18:46:58.325873",
     "exception": false,
     "start_time": "2021-06-24T18:46:58.163052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "governmental-holder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:46:58.667895Z",
     "iopub.status.busy": "2021-06-24T18:46:58.666818Z",
     "iopub.status.idle": "2021-06-24T18:47:40.813994Z",
     "shell.execute_reply": "2021-06-24T18:47:40.813506Z"
    },
    "papermill": {
     "duration": 42.327546,
     "end_time": "2021-06-24T18:47:40.814142",
     "exception": false,
     "start_time": "2021-06-24T18:46:58.486596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-82 | Fold-0 | OOF Score: 0.5728470733668614\n",
      "Seed-82 | Fold-1 | OOF Score: 0.3722774247360091\n",
      "Seed-82 | Fold-2 | OOF Score: 0.19052898729738482\n",
      "Seed-82 | Fold-3 | OOF Score: 0.15866087102496532\n",
      "Seed-82 | Fold-4 | OOF Score: 0.13871715954737712\n",
      "\n",
      "Seed: 82 | Aggregate OOF Score: 0.2866063031945195\n",
      "\n",
      "\n",
      "Aggregate OOF Score: 0.2866063031945195\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(31)\n",
    "seeds = np.random.randint(0, 100, size=NUM_SEED)\n",
    "\n",
    "counter = 0\n",
    "oof_score = 0\n",
    "y_pred_final5 = 0\n",
    "\n",
    "\n",
    "for sidx, seed in enumerate(seeds):\n",
    "    seed_score = 0\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "    for idx, (train, val) in enumerate(kfold.split(Xtrain_id, Ytrain_strat)):\n",
    "        counter += 1\n",
    "\n",
    "        train_x_id, train_x_mask, train_x_token = Xtrain_id[train], Xtrain_mask[train], Xtrain_token[train]\n",
    "        val_x_id, val_x_mask, val_x_token = Xtrain_id[val], Xtrain_mask[val], Xtrain_token[val]\n",
    "        train_y, val_y = Ytrain[train], Ytrain[val]\n",
    "\n",
    "        model = commonlit_model(transformer_model, use_tokens_type_ids=False)\n",
    "        \n",
    "        model.load_weights(f'../input/commonlit-bert-variants-p1/DistilBert-Base-Uncased/CLRP_DistilBert_Base_Uncased_{counter}C.h5')\n",
    "        \n",
    "        y_pred = model.predict([val_x_id, val_x_mask, val_x_token])\n",
    "        y_pred_final5 += model.predict([Xtest_id, Xtest_mask, Xtest_token])\n",
    "        \n",
    "        score = np.sqrt(mean_squared_error(val_y, y_pred))\n",
    "        oof_score += score\n",
    "        seed_score += score\n",
    "        print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n",
    "    \n",
    "    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n",
    "\n",
    "\n",
    "y_pred_final5 = y_pred_final5 / float(counter)\n",
    "oof_score /= float(counter)\n",
    "print(\"Aggregate OOF Score: {}\".format(oof_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-greeting",
   "metadata": {
    "papermill": {
     "duration": 0.16124,
     "end_time": "2021-06-24T18:47:41.137957",
     "exception": false,
     "start_time": "2021-06-24T18:47:40.976717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "collaborative-community",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T18:47:41.468830Z",
     "iopub.status.busy": "2021-06-24T18:47:41.468266Z",
     "iopub.status.idle": "2021-06-24T18:47:41.730712Z",
     "shell.execute_reply": "2021-06-24T18:47:41.731119Z"
    },
    "papermill": {
     "duration": 0.43271,
     "end_time": "2021-06-24T18:47:41.731268",
     "exception": false,
     "start_time": "2021-06-24T18:47:41.298558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.581617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.563686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.259267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.192328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-2.055590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.581617\n",
       "1  f0953f0a5 -0.563686\n",
       "2  0df072751 -0.259267\n",
       "3  04caf4e0c -2.192328\n",
       "4  0e63f8bea -2.055590"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final = (y_pred_final1 * 0.15) + \\\n",
    "               (y_pred_final2 * 0.1) + \\\n",
    "               (y_pred_final3 * 0.15) + \\\n",
    "               (y_pred_final4 * 0.3) + \\\n",
    "               (y_pred_final5 * 0.3)\n",
    "\n",
    "submit_df = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\n",
    "submit_df['target'] = y_pred_final\n",
    "submit_df.to_csv(\"./submission.csv\", index=False)\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-completion",
   "metadata": {
    "papermill": {
     "duration": 0.16201,
     "end_time": "2021-06-24T18:47:42.057419",
     "exception": false,
     "start_time": "2021-06-24T18:47:41.895409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 515.920528,
   "end_time": "2021-06-24T18:47:45.677404",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-24T18:39:09.756876",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
