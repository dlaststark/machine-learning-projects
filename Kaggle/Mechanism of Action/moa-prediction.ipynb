{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:21.931117Z",
     "iopub.status.busy": "2020-10-12T12:51:21.930398Z",
     "iopub.status.idle": "2020-10-12T12:51:21.953758Z",
     "shell.execute_reply": "2020-10-12T12:51:21.954291Z"
    },
    "papermill": {
     "duration": 0.069515,
     "end_time": "2020-10-12T12:51:21.954454",
     "exception": false,
     "start_time": "2020-10-12T12:51:21.884939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/permutation-importance/PermutationImportance.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:22.038032Z",
     "iopub.status.busy": "2020-10-12T12:51:22.037134Z",
     "iopub.status.idle": "2020-10-12T12:51:22.040549Z",
     "shell.execute_reply": "2020-10-12T12:51:22.039996Z"
    },
    "papermill": {
     "duration": 0.046511,
     "end_time": "2020-10-12T12:51:22.040708",
     "exception": false,
     "start_time": "2020-10-12T12:51:21.994197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/kaggle/input/permutation-importance')\n",
    "sys.path.insert(2, '/kaggle/input/iterative-stratification/iterative-stratification-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037688,
     "end_time": "2020-10-12T12:51:22.117314",
     "exception": false,
     "start_time": "2020-10-12T12:51:22.079626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:22.203845Z",
     "iopub.status.busy": "2020-10-12T12:51:22.203070Z",
     "iopub.status.idle": "2020-10-12T12:51:27.974827Z",
     "shell.execute_reply": "2020-10-12T12:51:27.976110Z"
    },
    "papermill": {
     "duration": 5.821165,
     "end_time": "2020-10-12T12:51:27.976309",
     "exception": false,
     "start_time": "2020-10-12T12:51:22.155144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.optimizers import AdamW, Lookahead\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils  import plot_model\n",
    "from PermutationImportance import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055038,
     "end_time": "2020-10-12T12:51:28.086250",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.031212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:28.210397Z",
     "iopub.status.busy": "2020-10-12T12:51:28.207033Z",
     "iopub.status.idle": "2020-10-12T12:51:28.220906Z",
     "shell.execute_reply": "2020-10-12T12:51:28.221441Z"
    },
    "papermill": {
     "duration": 0.079308,
     "end_time": "2020-10-12T12:51:28.221618",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.142310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logloss_metric(df, y_true, y_pred):\n",
    "    \n",
    "    metrics = []\n",
    "    \n",
    "    # Calculate log_loss individually for every field\n",
    "    for _target in df.columns:\n",
    "        metrics.append(log_loss(y_true.loc[:, _target], \n",
    "                                y_pred.loc[:, _target].astype(float), \n",
    "                                labels=[0,1]))\n",
    "    \n",
    "    # Return mean of individual log_loss values\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:28.359032Z",
     "iopub.status.busy": "2020-10-12T12:51:28.358149Z",
     "iopub.status.idle": "2020-10-12T12:51:28.367130Z",
     "shell.execute_reply": "2020-10-12T12:51:28.368172Z"
    },
    "papermill": {
     "duration": 0.073638,
     "end_time": "2020-10-12T12:51:28.368334",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.294696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preprocess(train_df, predict_df):\n",
    "    \n",
    "    # Display individual dataframe shapes\n",
    "    print(\"train_df: {}\".format(train_df.shape))\n",
    "    print(\"predict_df: {}\".format(predict_df.shape))\n",
    "    train_samples = train_df.shape[0]\n",
    "    \n",
    "    # Combined both input dataframes\n",
    "    combined_df = train_df.append(predict_df, sort=False, ignore_index=True)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    combined_df['cp_type_enc'] = combined_df['cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    combined_df['cp_dose_enc'] = combined_df['cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    combined_df['cp_time_days'] = combined_df['cp_time'].apply(lambda x: x//24)\n",
    "    combined_df.drop(['sig_id', 'cp_type', 'cp_dose', 'cp_time'], axis=1, inplace=True)\n",
    "    \n",
    "    # Segregate train and predict datasets\n",
    "    train_x = combined_df[:train_samples].values\n",
    "    predict_x = combined_df[train_samples:].values\n",
    "    print(\"train_x: {}\".format(train_x.shape))\n",
    "    print(\"predict_x: {}\".format(predict_x.shape))\n",
    "    \n",
    "    return train_x, predict_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:28.482707Z",
     "iopub.status.busy": "2020-10-12T12:51:28.481759Z",
     "iopub.status.idle": "2020-10-12T12:51:28.492743Z",
     "shell.execute_reply": "2020-10-12T12:51:28.493845Z"
    },
    "papermill": {
     "duration": 0.075005,
     "end_time": "2020-10-12T12:51:28.494041",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.419036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moa_prediction_model(input_shape, output_shape):\n",
    "    \n",
    "    # Input Layer\n",
    "    x_input = Input(shape=(input_shape, ), name='INPUT')\n",
    "    x = BatchNormalization(name='BN-INPUT')(x_input)\n",
    "    \n",
    "    # Fully-connected Layer 1\n",
    "    x = Dense(units=2048, name='FC-1', activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
    "    x = BatchNormalization(name='BN_FC-1')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-1')(x)\n",
    "    \n",
    "    # Fully-connected Layer 2\n",
    "    x = Dense(units=512, name='FC-2', activation='relu', kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(name='BN_FC-2')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-2')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    x = Dense(units=output_shape, activation='sigmoid', name='OUTPUT')(x)\n",
    "\n",
    "    # Create Keras Model instance\n",
    "    model = Model(inputs=x_input, outputs=x, name='MOA_Prediction_Model')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049745,
     "end_time": "2020-10-12T12:51:28.589546",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.539801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Unscored Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053312,
     "end_time": "2020-10-12T12:51:28.695132",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.641820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:28.827202Z",
     "iopub.status.busy": "2020-10-12T12:51:28.826456Z",
     "iopub.status.idle": "2020-10-12T12:51:28.832947Z",
     "shell.execute_reply": "2020-10-12T12:51:28.833639Z"
    },
    "papermill": {
     "duration": 0.06745,
     "end_time": "2020-10-12T12:51:28.833813",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.766363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set file paths for train and predict datasets\n",
    "train_dataset = \"/kaggle/input/lish-moa/train_features.csv\"\n",
    "train_labels = \"/kaggle/input/lish-moa/train_targets_nonscored.csv\"\n",
    "predict_dataset = \"/kaggle/input/lish-moa/test_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:28.943647Z",
     "iopub.status.busy": "2020-10-12T12:51:28.942697Z",
     "iopub.status.idle": "2020-10-12T12:51:35.446175Z",
     "shell.execute_reply": "2020-10-12T12:51:35.446959Z"
    },
    "papermill": {
     "duration": 6.55309,
     "end_time": "2020-10-12T12:51:35.447205",
     "exception": false,
     "start_time": "2020-10-12T12:51:28.894115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (23814, 876)\n",
      "train_label_df: (23814, 403)\n",
      "predict_df: (3982, 876)\n"
     ]
    }
   ],
   "source": [
    "# Process train and predict features datasets\n",
    "train_df = pd.read_csv(train_dataset)\n",
    "train_label_df = pd.read_csv(train_labels)\n",
    "predict_df = pd.read_csv(predict_dataset)\n",
    "\n",
    "print(\"train_df: {}\".format(train_df.shape))\n",
    "print(\"train_label_df: {}\".format(train_label_df.shape))\n",
    "print(\"predict_df: {}\".format(predict_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:35.600681Z",
     "iopub.status.busy": "2020-10-12T12:51:35.599444Z",
     "iopub.status.idle": "2020-10-12T12:51:35.857300Z",
     "shell.execute_reply": "2020-10-12T12:51:35.856573Z"
    },
    "papermill": {
     "duration": 0.350419,
     "end_time": "2020-10-12T12:51:35.857458",
     "exception": false,
     "start_time": "2020-10-12T12:51:35.507039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label_df: (21948, 403)\n",
      "train_df: (21948, 876)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with cp_type='ctl_vehicle'\n",
    "train_label_df = train_label_df.loc[train_df['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "train_df = train_df.loc[train_df['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "\n",
    "print(\"train_label_df: {}\".format(train_label_df.shape))\n",
    "print(\"train_df: {}\".format(train_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:35.994197Z",
     "iopub.status.busy": "2020-10-12T12:51:35.993090Z",
     "iopub.status.idle": "2020-10-12T12:51:36.009204Z",
     "shell.execute_reply": "2020-10-12T12:51:36.009820Z"
    },
    "papermill": {
     "duration": 0.106569,
     "end_time": "2020-10-12T12:51:36.009968",
     "exception": false,
     "start_time": "2020-10-12T12:51:35.903399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: (21948, 402)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc_transporter_expression_enhancer</th>\n",
       "      <th>abl_inhibitor</th>\n",
       "      <th>ace_inhibitor</th>\n",
       "      <th>acetylcholine_release_enhancer</th>\n",
       "      <th>adenosine_deaminase_inhibitor</th>\n",
       "      <th>adenosine_kinase_inhibitor</th>\n",
       "      <th>adenylyl_cyclase_inhibitor</th>\n",
       "      <th>age_inhibitor</th>\n",
       "      <th>alcohol_dehydrogenase_inhibitor</th>\n",
       "      <th>aldehyde_dehydrogenase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>ve-cadherin_antagonist</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abc_transporter_expression_enhancer  abl_inhibitor  ace_inhibitor  \\\n",
       "0                                    0              0              0   \n",
       "1                                    0              0              0   \n",
       "2                                    0              0              0   \n",
       "3                                    0              0              0   \n",
       "4                                    0              0              0   \n",
       "\n",
       "   acetylcholine_release_enhancer  adenosine_deaminase_inhibitor  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "\n",
       "   adenosine_kinase_inhibitor  adenylyl_cyclase_inhibitor  age_inhibitor  \\\n",
       "0                           0                           0              0   \n",
       "1                           0                           0              0   \n",
       "2                           0                           0              0   \n",
       "3                           0                           0              0   \n",
       "4                           0                           0              0   \n",
       "\n",
       "   alcohol_dehydrogenase_inhibitor  aldehyde_dehydrogenase_activator  ...  \\\n",
       "0                                0                                 0  ...   \n",
       "1                                0                                 0  ...   \n",
       "2                                0                                 0  ...   \n",
       "3                                0                                 0  ...   \n",
       "4                                0                                 0  ...   \n",
       "\n",
       "   ve-cadherin_antagonist  vesicular_monoamine_transporter_inhibitor  \\\n",
       "0                       0                                          0   \n",
       "1                       0                                          0   \n",
       "2                       0                                          0   \n",
       "3                       0                                          0   \n",
       "4                       0                                          0   \n",
       "\n",
       "   vitamin_k_antagonist  voltage-gated_calcium_channel_ligand  \\\n",
       "0                     0                                     0   \n",
       "1                     0                                     0   \n",
       "2                     0                                     0   \n",
       "3                     0                                     0   \n",
       "4                     0                                     0   \n",
       "\n",
       "   voltage-gated_potassium_channel_activator  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                                     0                               0   \n",
       "1                                     0                               0   \n",
       "2                                     0                               0   \n",
       "3                                     0                               0   \n",
       "4                                     0                               0   \n",
       "\n",
       "   wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor  \n",
       "0            0                           0               0  \n",
       "1            0                           0               0  \n",
       "2            0                           0               0  \n",
       "3            0                           0               0  \n",
       "4            0                           0               0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 'sig_id' column\n",
    "train_label_df.drop(['sig_id'], axis=1, inplace=True)\n",
    "train_y = train_label_df.values\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "train_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:36.099211Z",
     "iopub.status.busy": "2020-10-12T12:51:36.098221Z",
     "iopub.status.idle": "2020-10-12T12:51:36.309394Z",
     "shell.execute_reply": "2020-10-12T12:51:36.308847Z"
    },
    "papermill": {
     "duration": 0.257425,
     "end_time": "2020-10-12T12:51:36.309539",
     "exception": false,
     "start_time": "2020-10-12T12:51:36.052114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (21948, 876)\n",
      "predict_df: (3982, 876)\n",
      "train_x: (21948, 875)\n",
      "predict_x: (3982, 875)\n"
     ]
    }
   ],
   "source": [
    "train_x, Xpredict = data_preprocess(train_df, predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041737,
     "end_time": "2020-10-12T12:51:36.392890",
     "exception": false,
     "start_time": "2020-10-12T12:51:36.351153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T12:51:36.497727Z",
     "iopub.status.busy": "2020-10-12T12:51:36.496446Z",
     "iopub.status.idle": "2020-10-12T13:41:07.372366Z",
     "shell.execute_reply": "2020-10-12T13:41:07.372940Z"
    },
    "papermill": {
     "duration": 2970.936063,
     "end_time": "2020-10-12T13:41:07.373102",
     "exception": false,
     "start_time": "2020-10-12T12:51:36.437039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 0 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.3152 - val_loss: 0.0590\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1670 - val_loss: 0.7570\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1389 - val_loss: 0.1500\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.2606 - val_loss: 0.0445\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0361 - val_loss: 0.0145\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1042 - val_loss: 0.0307\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1423 - val_loss: 0.0608\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0312 - val_loss: 0.0312\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0559 - val_loss: 0.0523\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0103\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0142\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0381\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0102\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0207 - val_loss: 0.1018\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0224 - val_loss: 0.0134\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0241\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 18/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0170\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0193\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 25/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 28/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [05:54<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 1 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3094 - val_loss: 0.0436\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.1368 - val_loss: 0.1083\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.2458 - val_loss: 0.4738\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1149 - val_loss: 0.0459\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0795 - val_loss: 0.1184\n",
      "Epoch 6/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.1412\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1488 - val_loss: 0.4722\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.3551 - val_loss: 0.2469\n",
      "Epoch 8/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.1926Restoring model weights from the end of the best epoch.\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.1924 - val_loss: 0.1508\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [05:49<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 2 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3075 - val_loss: 0.1579\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.1465 - val_loss: 0.0386\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0546 - val_loss: 0.0524\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1577 - val_loss: 0.1641\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0652 - val_loss: 0.0225\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0640 - val_loss: 0.0157\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0605 - val_loss: 0.0185\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.1085 - val_loss: 0.2033\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0532 - val_loss: 0.0191\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0124\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0215\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0146\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0560 - val_loss: 0.0135\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0248\n",
      "Epoch 15/85\n",
      "140/147 [===========================>..] - ETA: 0s - loss: 0.0184\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0161\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 25/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0066\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 28/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 38/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [05:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 3 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.2959 - val_loss: 0.0440\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.2756 - val_loss: 0.1759\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 2s 10ms/step - loss: 0.0930 - val_loss: 0.0325\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1136 - val_loss: 0.0152\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0797 - val_loss: 0.2757\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1240 - val_loss: 0.0163\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.0244\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0814 - val_loss: 0.0653\n",
      "Epoch 9/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0279\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.2361\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0672 - val_loss: 0.0327\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 25/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.0068\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 28/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 38/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 2s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [05:46<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 4 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3338 - val_loss: 0.1469\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1290 - val_loss: 0.4124\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1411 - val_loss: 0.0252\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.2596 - val_loss: 0.0526\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0388 - val_loss: 0.0178\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.0216\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0143\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1613 - val_loss: 0.2778\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0692 - val_loss: 0.0193\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0260 - val_loss: 0.0142\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0262\n",
      "Epoch 12/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.0536\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0534 - val_loss: 0.0155\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0116 - val_loss: 0.0093\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 24/85\n",
      "141/147 [===========================>..] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 28/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 38/85\n",
      "142/147 [===========================>..] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [05:49<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 5 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3236 - val_loss: 0.1310\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1451 - val_loss: 0.0537\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1003 - val_loss: 0.0265\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.2731 - val_loss: 0.0800\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1672 - val_loss: 0.1619\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0707 - val_loss: 0.2628\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0698 - val_loss: 0.0691\n",
      "Epoch 8/85\n",
      "143/147 [============================>.] - ETA: 0s - loss: 0.0910\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1035 - val_loss: 0.5145\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.3396 - val_loss: 0.2142\n",
      "Epoch 10/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.1535Restoring model weights from the end of the best epoch.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1528 - val_loss: 0.1100\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [05:47<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 6 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.3178 - val_loss: 0.0541\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.1723 - val_loss: 0.0717\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0679 - val_loss: 0.0516\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.2293 - val_loss: 0.4465\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.1304 - val_loss: 0.0208\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0359 - val_loss: 0.0318\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0256 - val_loss: 0.0167\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1259 - val_loss: 0.0793\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0379 - val_loss: 0.0187\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.0133\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0139\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0273\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0120\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0402 - val_loss: 0.0182\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0130\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0208 - val_loss: 0.0122\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 28/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0036Restoring model weights from the end of the best epoch.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 00075: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [05:58<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare datasets for training\n",
    "Xtrain = train_x.copy()\n",
    "Ytrain = train_y.copy()\n",
    "\n",
    "\n",
    "# Define the model hyperparameters\n",
    "mini_batch_size = 128\n",
    "perm_imp = np.zeros(Xtrain.shape[1])\n",
    "\n",
    "\n",
    "# Define K-fold cross validation test harness\n",
    "kfold = MultilabelStratifiedKFold(n_splits=7, shuffle=True, random_state=50)\n",
    "\n",
    "for idx, (train, val) in enumerate(kfold.split(Xtrain, Ytrain)):\n",
    "    \n",
    "    print(\"\\n---------------- Fold {} ----------------\".format(idx))\n",
    "    \n",
    "    train_x_tmp, val_x_tmp = Xtrain[train], Xtrain[val]\n",
    "    train_y_tmp, val_y_tmp = Ytrain[train], Ytrain[val]\n",
    "    \n",
    "    # Create the model\n",
    "    model = moa_prediction_model(Xtrain.shape[1], Ytrain.shape[1])\n",
    "\n",
    "    # Compile model to configure the learning process\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Lookahead(AdamW(lr=1e-2, \n",
    "                                            weight_decay=1e-5, \n",
    "                                            clipvalue=700), \n",
    "                                      sync_period=10))\n",
    "    \n",
    "    # Early stopping policy\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n",
    "                          restore_best_weights=True, \n",
    "                          patience=7, verbose=1)\n",
    "    \n",
    "    # Reduce LR on plateau policy\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, \n",
    "                                  min_lr=1e-5, patience=5, \n",
    "                                  verbose=1, mode='min')\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(x=train_x_tmp, y=train_y_tmp, \n",
    "                        batch_size=mini_batch_size, epochs=85, verbose=1,\n",
    "                        callbacks=[reduce_lr, early], workers=5,\n",
    "                        validation_data=(val_x_tmp, val_y_tmp))\n",
    "    \n",
    "    fet_imp = PermutationImportance(model, val_x_tmp, val_y_tmp, n_iter=1, random_state=50)\n",
    "    _, local_imp = fet_imp.get_score_importances()\n",
    "    perm_imp += np.mean(local_imp, axis=0)\n",
    "\n",
    "\n",
    "top_feats = np.argwhere(perm_imp < 0).flatten()\n",
    "print(len(top_feats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T13:41:19.451757Z",
     "iopub.status.busy": "2020-10-12T13:41:19.450904Z",
     "iopub.status.idle": "2020-10-12T13:41:19.454952Z",
     "shell.execute_reply": "2020-10-12T13:41:19.455427Z"
    },
    "papermill": {
     "duration": 5.94109,
     "end_time": "2020-10-12T13:41:19.455569",
     "exception": false,
     "start_time": "2020-10-12T13:41:13.514479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,\n",
       "        28,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "        42,  43,  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "        57,  58,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "        71,  72,  73,  75,  76,  77,  78,  79,  80,  81,  82,  84,  85,\n",
       "        87,  88,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 117, 120,\n",
       "       121, 122, 123, 124, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
       "       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149,\n",
       "       150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
       "       164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177,\n",
       "       178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191,\n",
       "       192, 193, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206,\n",
       "       207, 208, 209, 210, 212, 213, 215, 216, 217, 218, 219, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236,\n",
       "       237, 238, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "       252, 253, 254, 256, 257, 258, 260, 261, 262, 263, 264, 265, 268,\n",
       "       269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
       "       283, 284, 285, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 312, 313,\n",
       "       314, 315, 316, 317, 318, 319, 320, 322, 323, 324, 325, 327, 328,\n",
       "       330, 331, 332, 333, 334, 335, 336, 338, 343, 344, 345, 346, 347,\n",
       "       348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
       "       361, 362, 363, 365, 366, 367, 368, 371, 372, 373, 374, 375, 376,\n",
       "       379, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 394,\n",
       "       395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 408,\n",
       "       409, 410, 411, 413, 414, 415, 417, 418, 420, 421, 422, 423, 424,\n",
       "       425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 438, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 481, 482,\n",
       "       483, 484, 485, 487, 488, 492, 493, 494, 495, 496, 497, 498, 499,\n",
       "       500, 501, 502, 504, 505, 506, 508, 510, 511, 513, 515, 516, 517,\n",
       "       518, 520, 522, 524, 526, 528, 530, 531, 533, 534, 537, 538, 539,\n",
       "       540, 542, 543, 545, 547, 548, 551, 552, 553, 555, 556, 558, 559,\n",
       "       560, 561, 563, 564, 565, 566, 567, 568, 570, 571, 572, 576, 577,\n",
       "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 591, 592,\n",
       "       594, 595, 596, 597, 598, 599, 601, 603, 604, 606, 607, 608, 610,\n",
       "       611, 613, 614, 616, 618, 619, 620, 621, 622, 623, 624, 626, 627,\n",
       "       628, 629, 630, 631, 632, 633, 635, 636, 638, 639, 640, 641, 642,\n",
       "       644, 645, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
       "       658, 659, 660, 661, 662, 665, 666, 667, 668, 669, 670, 672, 673,\n",
       "       674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687,\n",
       "       688, 689, 690, 691, 692, 694, 697, 698, 699, 700, 701, 702, 703,\n",
       "       704, 705, 706, 707, 708, 709, 710, 711, 713, 715, 716, 719, 720,\n",
       "       722, 723, 724, 725, 727, 729, 730, 731, 732, 733, 734, 735, 736,\n",
       "       737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749,\n",
       "       750, 751, 753, 754, 755, 756, 757, 759, 760, 763, 766, 768, 769,\n",
       "       770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 781, 782, 783,\n",
       "       784, 785, 786, 787, 788, 789, 792, 793, 794, 795, 798, 799, 801,\n",
       "       802, 804, 805, 806, 807, 808, 809, 810, 811, 813, 814, 815, 816,\n",
       "       817, 818, 820, 821, 822, 823, 824, 826, 830, 831, 832, 833, 834,\n",
       "       835, 836, 837, 838, 839, 840, 842, 843, 844, 845, 847, 848, 849,\n",
       "       850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 862, 863, 864,\n",
       "       865, 866, 867, 869, 870, 871, 873])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T13:41:31.629810Z",
     "iopub.status.busy": "2020-10-12T13:41:31.628838Z",
     "iopub.status.idle": "2020-10-12T13:41:31.636696Z",
     "shell.execute_reply": "2020-10-12T13:41:31.637743Z"
    },
    "papermill": {
     "duration": 6.288758,
     "end_time": "2020-10-12T13:41:31.637934",
     "exception": false,
     "start_time": "2020-10-12T13:41:25.349176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntop_feats = \\n\\nprint(len(top_feats))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "top_feats = \n",
    "\n",
    "print(len(top_feats))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 5.900215,
     "end_time": "2020-10-12T13:41:43.481721",
     "exception": false,
     "start_time": "2020-10-12T13:41:37.581506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split training data into train / test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T13:41:55.315160Z",
     "iopub.status.busy": "2020-10-12T13:41:55.314254Z",
     "iopub.status.idle": "2020-10-12T13:41:58.078690Z",
     "shell.execute_reply": "2020-10-12T13:41:58.079793Z"
    },
    "papermill": {
     "duration": 8.614576,
     "end_time": "2020-10-12T13:41:58.080004",
     "exception": false,
     "start_time": "2020-10-12T13:41:49.465428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.085, random_state=10)\n",
    "for train_index, test_index in sss.split(train_x, train_y):\n",
    "    Xtrain, Xtest = train_x[train_index], train_x[test_index]\n",
    "    Ytrain, Ytest = train_y[train_index], train_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T13:42:09.898385Z",
     "iopub.status.busy": "2020-10-12T13:42:09.896428Z",
     "iopub.status.idle": "2020-10-12T13:42:10.123768Z",
     "shell.execute_reply": "2020-10-12T13:42:10.124308Z"
    },
    "papermill": {
     "duration": 6.286187,
     "end_time": "2020-10-12T13:42:10.124447",
     "exception": false,
     "start_time": "2020-10-12T13:42:03.838260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "Xtrain_full shape: (21948, 722)\n",
      "Xtrain shape: (20082, 722)\n",
      "Ytrain shape: (20082, 402)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "Xtest shape: (1866, 722)\n",
      "Ytest shape: (1866, 402)\n",
      "\n",
      "------------------------- Prediction Dataset -------------------------\n",
      "Xpredict shape: (3982, 722)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_full = train_x[:, top_feats].copy()\n",
    "Xtrain = Xtrain[:, top_feats]\n",
    "Xtest = Xtest[:, top_feats]\n",
    "Xpredict = Xpredict[:, top_feats]\n",
    "\n",
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"Xtrain_full shape: {}\".format(Xtrain_full.shape))\n",
    "print(\"Xtrain shape: {}\".format(Xtrain.shape))\n",
    "print(\"Ytrain shape: {}\".format(Ytrain.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"Xtest shape: {}\".format(Xtest.shape))\n",
    "print(\"Ytest shape: {}\".format(Ytest.shape))\n",
    "\n",
    "print(\"\\n------------------------- Prediction Dataset -------------------------\")\n",
    "print(\"Xpredict shape: {}\".format(Xpredict.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6.100174,
     "end_time": "2020-10-12T13:42:21.946258",
     "exception": false,
     "start_time": "2020-10-12T13:42:15.846084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Build and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T13:42:33.944822Z",
     "iopub.status.busy": "2020-10-12T13:42:33.941286Z",
     "iopub.status.idle": "2020-10-12T13:42:34.097828Z",
     "shell.execute_reply": "2020-10-12T13:42:34.097201Z"
    },
    "papermill": {
     "duration": 6.353337,
     "end_time": "2020-10-12T13:42:34.097948",
     "exception": false,
     "start_time": "2020-10-12T13:42:27.744611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MOA_Prediction_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           [(None, 722)]             0         \n",
      "_________________________________________________________________\n",
      "BN-INPUT (BatchNormalization (None, 722)               2888      \n",
      "_________________________________________________________________\n",
      "FC-1 (Dense)                 (None, 2048)              1480704   \n",
      "_________________________________________________________________\n",
      "BN_FC-1 (BatchNormalization) (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "DROPOUT_FC-1 (Dropout)       (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "FC-2 (Dense)                 (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "BN_FC-2 (BatchNormalization) (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "DROPOUT_FC-2 (Dropout)       (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 402)               206226    \n",
      "=================================================================\n",
      "Total params: 2,749,146\n",
      "Trainable params: 2,742,582\n",
      "Non-trainable params: 6,564\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model hyperparameters\n",
    "mini_batch_size = 128\n",
    "\n",
    "# Prediction Clipping Thresholds\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "# Create the model\n",
    "model = moa_prediction_model(Xtrain.shape[1], Ytrain.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T13:42:45.908903Z",
     "iopub.status.busy": "2020-10-12T13:42:45.907904Z",
     "iopub.status.idle": "2020-10-12T14:35:07.137621Z",
     "shell.execute_reply": "2020-10-12T14:35:07.007487Z"
    },
    "papermill": {
     "duration": 3146.912735,
     "end_time": "2020-10-12T14:35:07.137834",
     "exception": false,
     "start_time": "2020-10-12T13:42:40.225099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Fold 1 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3353 - val_loss: 0.2809\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1503 - val_loss: 0.2034\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1880 - val_loss: 0.0281\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0277 - val_loss: 0.0382\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0137\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0345\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.3422 - val_loss: 0.1503\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0779 - val_loss: 0.0378\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0235 - val_loss: 0.0138\n",
      "Epoch 10/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0177\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0142\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 21/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0069\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "---------------- Fold 2 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.2934 - val_loss: 0.1456\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1331 - val_loss: 0.1846\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2357 - val_loss: 0.2917\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1185 - val_loss: 0.0221\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1700 - val_loss: 0.0204\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0155\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0262 - val_loss: 0.0131\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1419 - val_loss: 0.0706\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0314 - val_loss: 0.0185\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0323 - val_loss: 0.0207\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0172\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0099\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0263\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0110\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 17/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0565\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0093\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 33/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "---------------- Fold 3 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3133 - val_loss: 0.0540\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1175 - val_loss: 0.0306\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2148 - val_loss: 0.1260\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0576 - val_loss: 0.0234\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0188\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0577 - val_loss: 0.0121\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1760 - val_loss: 0.0420\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1656 - val_loss: 0.0574\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0315 - val_loss: 0.0180\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0533 - val_loss: 0.0126\n",
      "Epoch 11/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0135\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 46/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "---------------- Fold 4 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3708 - val_loss: 0.1540\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.1311 - val_loss: 0.1403\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.1731 - val_loss: 0.0817\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0756 - val_loss: 0.0293\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1869 - val_loss: 0.0417\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0306 - val_loss: 0.0137\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0302 - val_loss: 0.0146\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1529 - val_loss: 0.0402\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1644 - val_loss: 0.0387\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0214 - val_loss: 0.0119\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0202\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0682 - val_loss: 0.0611\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0231 - val_loss: 0.0149\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0287\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0107\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0298 - val_loss: 0.0114\n",
      "Epoch 19/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "---------------- Fold 5 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3196 - val_loss: 0.1055\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1091 - val_loss: 0.0410\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1313 - val_loss: 0.0274\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0963 - val_loss: 0.0322\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1074 - val_loss: 0.0981\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.1697\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2467 - val_loss: 0.0400\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0347 - val_loss: 0.0174\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0127\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0167\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0255\n",
      "Epoch 14/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0182\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.0136\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 25/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 6 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3149 - val_loss: 0.1608\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1310 - val_loss: 0.2265\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0888 - val_loss: 0.0147\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1298 - val_loss: 0.0194\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1355 - val_loss: 0.0966\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1288 - val_loss: 0.7305\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2121 - val_loss: 0.0425\n",
      "Epoch 8/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0602\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0597 - val_loss: 0.0462\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0356 - val_loss: 0.0260\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0215 - val_loss: 0.0180\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0139\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 32/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 49/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "---------------- Fold 7 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3218 - val_loss: 0.1121\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1445 - val_loss: 0.3503\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2348 - val_loss: 0.4037\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1142 - val_loss: 0.0369\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1938 - val_loss: 0.0554\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0442 - val_loss: 0.1344\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1299 - val_loss: 0.0237\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0159\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0369 - val_loss: 0.0349\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0420 - val_loss: 0.0778\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1328 - val_loss: 0.0521\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0265 - val_loss: 0.0184\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0171 - val_loss: 0.0122\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 23/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 37/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "---------------- Fold 8 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.2875 - val_loss: 0.1364\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1468 - val_loss: 0.1072\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2159 - val_loss: 0.1376\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1477 - val_loss: 0.1982\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0454 - val_loss: 0.0152\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1216 - val_loss: 0.0288\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1146 - val_loss: 0.0465\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0123\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0180\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0180\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0209\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0312 - val_loss: 0.0117\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0445 - val_loss: 0.0157\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0588 - val_loss: 0.0147\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0256\n",
      "Epoch 17/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0146\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 29/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 9 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3261 - val_loss: 0.2722\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1255 - val_loss: 0.3100\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1483 - val_loss: 0.0209\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1830 - val_loss: 0.0630\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0399 - val_loss: 0.0163\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0870 - val_loss: 0.0148\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0227 - val_loss: 0.0166\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0476 - val_loss: 0.0565\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0430 - val_loss: 0.0262\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0927 - val_loss: 0.0209\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0220 - val_loss: 0.0130\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.0141\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0394\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0120\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0230\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0097\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0153 - val_loss: 0.0188\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0215\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0161 - val_loss: 0.0126\n",
      "Epoch 21/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0297\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0291 - val_loss: 0.0155\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 37/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "---------------- Fold 10 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3324 - val_loss: 0.2358\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1572 - val_loss: 0.1035\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0928 - val_loss: 0.0394\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.2424 - val_loss: 0.1136\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1357 - val_loss: 0.0416\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0221 - val_loss: 0.0156\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0215 - val_loss: 0.0535\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0756 - val_loss: 0.0136\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0381 - val_loss: 0.0294\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0095\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0471 - val_loss: 0.2137\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.1043 - val_loss: 0.0210\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0177 - val_loss: 0.0102\n",
      "Epoch 15/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0152\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "---------------- Fold 11 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3102 - val_loss: 0.2128\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.0206\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1081 - val_loss: 0.3971\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1635 - val_loss: 0.0257\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0849\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0637 - val_loss: 0.1460\n",
      "Epoch 7/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0515\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0510 - val_loss: 0.0308\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0219 - val_loss: 0.0135\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0208\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 23/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "---------------- Fold 12 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3079 - val_loss: 0.0847\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1583 - val_loss: 0.1403\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1906 - val_loss: 0.1026\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0699 - val_loss: 0.0326\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1784 - val_loss: 0.0383\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1253 - val_loss: 0.0603\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0666 - val_loss: 0.0804\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0667 - val_loss: 0.0165\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0360 - val_loss: 0.0177\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0133\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1310 - val_loss: 0.2822\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0722 - val_loss: 0.0217\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0160\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0107 - val_loss: 0.0070\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 39/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0089\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 45/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "---------------- Fold 13 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3069 - val_loss: 0.0953\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1320 - val_loss: 0.0634\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0717 - val_loss: 0.0712\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.3354 - val_loss: 0.0790\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1376 - val_loss: 0.1224\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0716 - val_loss: 0.0443\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0582 - val_loss: 0.0202\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0133\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0183 - val_loss: 0.0113\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0779 - val_loss: 0.0187\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0225 - val_loss: 0.0157\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0090\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0315 - val_loss: 0.0287\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0437 - val_loss: 0.0461\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0195 - val_loss: 0.0134\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 17/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0201\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 14 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3140 - val_loss: 0.0954\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1653 - val_loss: 0.3957\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0960 - val_loss: 0.0395\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0589 - val_loss: 0.0213\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1458 - val_loss: 0.0391\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0811 - val_loss: 0.0211\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0114\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.3174\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0751 - val_loss: 0.0236\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0818 - val_loss: 0.0146\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0491 - val_loss: 0.0257\n",
      "Epoch 12/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0234\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0230 - val_loss: 0.0123\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 25/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0066\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 15 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.2906 - val_loss: 0.0735\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1711 - val_loss: 0.0828\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2352 - val_loss: 0.1475\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1441 - val_loss: 0.0392\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0242 - val_loss: 0.0201\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0579 - val_loss: 0.0518\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0208 - val_loss: 0.0258\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0260 - val_loss: 0.0107\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1094 - val_loss: 0.0280\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0236 - val_loss: 0.0183\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0215\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0094\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0627 - val_loss: 0.0627\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0147\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0142\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0113\n",
      "Epoch 17/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0175\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 16 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3020 - val_loss: 0.1016\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1587 - val_loss: 0.3314\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1208 - val_loss: 0.0482\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.1584 - val_loss: 0.0763\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0912 - val_loss: 0.0161\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0312\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1517 - val_loss: 0.1436\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0771 - val_loss: 0.0351\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.0337\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0113\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0304 - val_loss: 0.0229\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0218 - val_loss: 0.0092\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0253\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 29/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 17 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3062 - val_loss: 0.0422\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1821 - val_loss: 0.1637\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.1454 - val_loss: 0.2256\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0915 - val_loss: 0.0281\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0323 - val_loss: 0.0361\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0145\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1025 - val_loss: 0.4221\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1156 - val_loss: 0.0189\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0819 - val_loss: 0.0197\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0262 - val_loss: 0.0137\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0162\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0131\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0234 - val_loss: 0.0141\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0326 - val_loss: 0.0192\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 19/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0256\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 18 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3308 - val_loss: 0.1486\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1283 - val_loss: 0.0822\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0877 - val_loss: 0.0194\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.2180 - val_loss: 0.1611\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.1187 - val_loss: 0.1101\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0446 - val_loss: 0.0170\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2231 - val_loss: 0.0477\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1928 - val_loss: 0.0818\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0912 - val_loss: 0.0351\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0402 - val_loss: 0.0141\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0150 - val_loss: 0.0223\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.1224 - val_loss: 0.0232\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0135 - val_loss: 0.0159\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0131\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0097\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 33/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 45/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "---------------- Fold 19 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.2975 - val_loss: 0.7691\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1631 - val_loss: 0.0954\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2178 - val_loss: 0.0757\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0511 - val_loss: 0.0237\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0333 - val_loss: 0.0268\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1870 - val_loss: 0.0967\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1149 - val_loss: 0.1506\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0348 - val_loss: 0.0123\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0254 - val_loss: 0.0136\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0565 - val_loss: 0.0114\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0143\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0219 - val_loss: 0.0272\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0237 - val_loss: 0.0144\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 17/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0199\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0098 - val_loss: 0.0072\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 29/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "---------------- Fold 20 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3145 - val_loss: 0.1936\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1364 - val_loss: 0.0819\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0696 - val_loss: 0.0261\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0988 - val_loss: 0.1771\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2035 - val_loss: 0.0595\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0124\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0810 - val_loss: 0.0623\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1094 - val_loss: 0.3813\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1089 - val_loss: 0.0298\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0280\n",
      "Epoch 11/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.1000\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1000 - val_loss: 0.0739\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0668 - val_loss: 0.0494\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0293\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0202\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0146\n",
      "Epoch 16/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0199\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0170\n",
      "Epoch 00016: early stopping\n",
      "---------------- Fold 21 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3136 - val_loss: 0.1372\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1340 - val_loss: 0.0679\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0980 - val_loss: 0.0180\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.3299 - val_loss: 0.2540\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0977 - val_loss: 0.0337\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0551 - val_loss: 0.0300\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.0214 - val_loss: 0.0168\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0241 - val_loss: 0.0113\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0495 - val_loss: 0.0149\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0221 - val_loss: 0.0151\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1016 - val_loss: 0.0386\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0151\n",
      "Epoch 13/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0201\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 22/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 35/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "---------------- Fold 22 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3159 - val_loss: 0.1875\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.2562 - val_loss: 0.3547\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1494 - val_loss: 0.0499\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0964 - val_loss: 0.1183\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0745 - val_loss: 0.0138\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0343 - val_loss: 0.0169\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0135\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0108\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0428 - val_loss: 0.1348\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0450 - val_loss: 0.0298\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0148\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0544 - val_loss: 0.0232\n",
      "Epoch 13/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0180\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0146\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "---------------- Fold 23 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3033 - val_loss: 0.0736\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1280 - val_loss: 0.0389\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1641 - val_loss: 0.0900\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0657 - val_loss: 0.0263\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0237 - val_loss: 0.0192\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1323 - val_loss: 0.4712\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1231 - val_loss: 0.0599\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0485 - val_loss: 0.0888\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0388 - val_loss: 0.0253\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0258 - val_loss: 0.0112\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0295\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0313\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0301 - val_loss: 0.0224\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0118\n",
      "Epoch 15/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0161\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "---------------- Fold 24 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3236 - val_loss: 0.1311\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1162 - val_loss: 0.0551\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.2093 - val_loss: 0.1030\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1237 - val_loss: 0.0658\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.3539 - val_loss: 0.0984\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0508 - val_loss: 0.0290\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0230 - val_loss: 0.0212\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0152\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0218 - val_loss: 0.0176\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0216\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0128\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0818\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0136\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0192 - val_loss: 0.0195\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0124\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0094\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0088\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0130\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0073\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0111 - val_loss: 0.0068\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0122\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0134\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 53/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 61/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "---------------- Fold 25 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3079 - val_loss: 0.0512\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1566 - val_loss: 0.0672\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1381 - val_loss: 0.0401\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0608 - val_loss: 0.0282\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0564 - val_loss: 0.0461\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0448 - val_loss: 0.2671\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.6480 - val_loss: 0.1700\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1208 - val_loss: 0.0632\n",
      "Epoch 9/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0515\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0507 - val_loss: 0.0316\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0290 - val_loss: 0.0275\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0263\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0246 - val_loss: 0.0234\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0223 - val_loss: 0.0213\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0208 - val_loss: 0.0202\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0187 - val_loss: 0.0175\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0161\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0151\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0132\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0085 - val_loss: 0.0136\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0088\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 43/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 56/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "---------------- Fold 26 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3727 - val_loss: 0.1536\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1208 - val_loss: 0.0764\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1205 - val_loss: 0.0212\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1252 - val_loss: 0.1062\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0928 - val_loss: 0.0164\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0448 - val_loss: 0.0497\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0408 - val_loss: 0.3071\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1100 - val_loss: 0.0159\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0605\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0288 - val_loss: 0.0116\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0578\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0597 - val_loss: 0.0119\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0456 - val_loss: 0.0136\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0306 - val_loss: 0.0529\n",
      "Epoch 15/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0216\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0213 - val_loss: 0.0155\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 24/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 40/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "---------------- Fold 27 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3137 - val_loss: 0.0732\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1771 - val_loss: 0.1335\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0843 - val_loss: 0.0590\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2091 - val_loss: 0.0557\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0624\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0222 - val_loss: 0.0158\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1398 - val_loss: 0.0267\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2292 - val_loss: 0.0972\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0633 - val_loss: 0.0236\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0216 - val_loss: 0.0124\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0515 - val_loss: 0.1619\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0368 - val_loss: 0.0123\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0199\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 15/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0508\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0502 - val_loss: 0.0261\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0123\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 31/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 45/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "---------------- Fold 28 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3444 - val_loss: 0.2136\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1248 - val_loss: 0.0789\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0736 - val_loss: 0.0464\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0915 - val_loss: 0.0215\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0958 - val_loss: 0.0423\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1647 - val_loss: 0.0991\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1753 - val_loss: 0.0297\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0474 - val_loss: 0.2583\n",
      "Epoch 9/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.1448\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1426 - val_loss: 0.0239\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0171\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0214 - val_loss: 0.0180\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0132\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 33/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 49/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "---------------- Fold 29 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3343 - val_loss: 0.2379\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1347 - val_loss: 0.0654\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0808 - val_loss: 0.0825\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2430 - val_loss: 0.0570\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0684 - val_loss: 0.0263\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2550 - val_loss: 0.0582\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0390 - val_loss: 0.0201\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0598 - val_loss: 0.0188\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.9192\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1592 - val_loss: 0.0286\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0175\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0304\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0802 - val_loss: 0.0201\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0103\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0162\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0253\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 19/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 27/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "---------------- Fold 30 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3299 - val_loss: 0.1876\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1123 - val_loss: 0.1552\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0730 - val_loss: 0.0226\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.2171 - val_loss: 0.1450\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0401 - val_loss: 0.0328\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0398 - val_loss: 0.0220\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0589 - val_loss: 0.0149\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.2517 - val_loss: 0.0712\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0309 - val_loss: 0.0171\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0414 - val_loss: 0.1516\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0321 - val_loss: 0.0362\n",
      "Epoch 12/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0349\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0348 - val_loss: 0.0299\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0119\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 25/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0034Restoring model weights from the end of the best epoch.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 00083: early stopping\n",
      "---------------- Fold 31 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3107 - val_loss: 0.1262\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1405 - val_loss: 0.2802\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2212 - val_loss: 0.0536\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.1121 - val_loss: 0.2025\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0999 - val_loss: 0.2313\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1375 - val_loss: 0.1199\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0575 - val_loss: 0.0143\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0111\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0255 - val_loss: 0.0342\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0633 - val_loss: 0.0215\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0342 - val_loss: 0.1156\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0221 - val_loss: 0.0102\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0386\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0132\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0097\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0239\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0118\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0130\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 35/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "---------------- Fold 32 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3446 - val_loss: 0.2962\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1426 - val_loss: 0.0400\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1202 - val_loss: 0.0949\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0464 - val_loss: 0.0144\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0836 - val_loss: 0.0349\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0401 - val_loss: 0.0167\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0753 - val_loss: 0.0271\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0616 - val_loss: 0.1624\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0657 - val_loss: 0.0126\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0254 - val_loss: 0.0184\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0140\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0413 - val_loss: 0.0229\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0158\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0153\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "---------------- Fold 33 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.2973 - val_loss: 0.0844\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1065 - val_loss: 0.0629\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.2042 - val_loss: 0.1354\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0607 - val_loss: 0.0191\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.1476 - val_loss: 0.0427\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0347 - val_loss: 0.0132\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0607 - val_loss: 0.0175\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.2060 - val_loss: 0.3141\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.2019 - val_loss: 0.0470\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0303 - val_loss: 0.0164\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0169 - val_loss: 0.0138\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 27/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "---------------- Fold 34 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3174 - val_loss: 0.1572\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1156 - val_loss: 0.0653\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2165 - val_loss: 0.2713\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0700 - val_loss: 0.0167\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1615 - val_loss: 0.0583\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1282 - val_loss: 0.0273\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0738 - val_loss: 0.0158\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0221 - val_loss: 0.0166\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0615 - val_loss: 0.0278\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0109\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 14/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 21/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "---------------- Fold 35 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3371 - val_loss: 0.2076\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1318 - val_loss: 0.0484\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0818 - val_loss: 0.3698\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1688 - val_loss: 0.0599\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1065 - val_loss: 0.0244\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0406 - val_loss: 0.1308\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0752 - val_loss: 0.0224\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0707 - val_loss: 0.0422\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1783 - val_loss: 0.1676\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0503 - val_loss: 0.0186\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0142\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0225 - val_loss: 0.0124\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0229 - val_loss: 0.0224\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0230 - val_loss: 0.0153\n",
      "Epoch 17/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0139\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 31/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 44/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Total #iterations: 35\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = 0\n",
    "y_pred_val = 0\n",
    "y_pred_final = 0\n",
    "idx = 0\n",
    "\n",
    "np.random.seed(1)\n",
    "seeds = np.random.randint(0, 100, size=5)\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    # Define K-fold cross validation test harness\n",
    "    kfold = MultilabelStratifiedKFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for train, val in kfold.split(Xtrain, Ytrain):\n",
    "\n",
    "        idx += 1\n",
    "        print(\"---------------- Fold {} ----------------\".format(idx))\n",
    "\n",
    "        train_x_tmp, val_x_tmp = Xtrain[train], Xtrain[val]\n",
    "        train_y_tmp, val_y_tmp = Ytrain[train], Ytrain[val]\n",
    "\n",
    "        # Create the model\n",
    "        model = moa_prediction_model(Xtrain.shape[1], Ytrain.shape[1])\n",
    "\n",
    "        # Compile model to configure the learning process\n",
    "        model.compile(loss='binary_crossentropy', \n",
    "                      optimizer=Lookahead(AdamW(lr=1e-2, \n",
    "                                                weight_decay=1e-5, \n",
    "                                                clipvalue=700), \n",
    "                                          sync_period=10))\n",
    "\n",
    "        # Early stopping policy\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n",
    "                              restore_best_weights=True, \n",
    "                              patience=10, verbose=1)\n",
    "\n",
    "        # Reduce LR on plateau policy\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, \n",
    "                                      min_lr=1e-5, patience=5, \n",
    "                                      verbose=1, mode='min')\n",
    "\n",
    "        # Fit the model\n",
    "        history = model.fit(x=train_x_tmp, y=train_y_tmp, \n",
    "                            batch_size=mini_batch_size, epochs=85, verbose=1,\n",
    "                            callbacks=[reduce_lr, early], workers=5,\n",
    "                            validation_data=(val_x_tmp, val_y_tmp))\n",
    "\n",
    "        # Make predictions\n",
    "        pred_val = model.predict(Xtest)\n",
    "        y_pred_val += pred_val\n",
    "        \n",
    "        pred_train = model.predict(Xtrain_full)\n",
    "        y_pred_train += pred_train\n",
    "\n",
    "        pred_final = model.predict(Xpredict)\n",
    "        y_pred_final += pred_final\n",
    "\n",
    "\n",
    "print(\"Total #iterations: {}\".format(idx))\n",
    "y_pred_val /= float(idx)\n",
    "y_pred_train /= float(idx)\n",
    "y_pred_final /= float(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:35:57.822383Z",
     "iopub.status.busy": "2020-10-12T14:35:57.821534Z",
     "iopub.status.idle": "2020-10-12T14:35:57.855964Z",
     "shell.execute_reply": "2020-10-12T14:35:57.855371Z"
    },
    "papermill": {
     "duration": 25.476107,
     "end_time": "2020-10-12T14:35:57.856072",
     "exception": false,
     "start_time": "2020-10-12T14:35:32.379965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label smoothing\n",
    "y_pred_val = np.clip(y_pred_val, p_min, p_max)\n",
    "y_pred_train = np.clip(y_pred_train, p_min, p_max)\n",
    "y_pred_final = np.clip(y_pred_final, p_min, p_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:36:49.638202Z",
     "iopub.status.busy": "2020-10-12T14:36:49.637276Z",
     "iopub.status.idle": "2020-10-12T14:36:50.173193Z",
     "shell.execute_reply": "2020-10-12T14:36:50.173687Z"
    },
    "papermill": {
     "duration": 26.700133,
     "end_time": "2020-10-12T14:36:50.173821",
     "exception": false,
     "start_time": "2020-10-12T14:36:23.473688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005194666970553282"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model\n",
    "true_labels = pd.DataFrame(Ytest, columns=train_label_df.columns)\n",
    "pred_labels = pd.DataFrame(y_pred_val, columns=train_label_df.columns)\n",
    "logloss_metric(train_label_df, true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:37:40.980676Z",
     "iopub.status.busy": "2020-10-12T14:37:40.979240Z",
     "iopub.status.idle": "2020-10-12T14:37:40.984260Z",
     "shell.execute_reply": "2020-10-12T14:37:40.984859Z"
    },
    "papermill": {
     "duration": 25.576221,
     "end_time": "2020-10-12T14:37:40.985021",
     "exception": false,
     "start_time": "2020-10-12T14:37:15.408800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc_transporter_expression_enhancer</th>\n",
       "      <th>abl_inhibitor</th>\n",
       "      <th>ace_inhibitor</th>\n",
       "      <th>acetylcholine_release_enhancer</th>\n",
       "      <th>adenosine_deaminase_inhibitor</th>\n",
       "      <th>adenosine_kinase_inhibitor</th>\n",
       "      <th>adenylyl_cyclase_inhibitor</th>\n",
       "      <th>age_inhibitor</th>\n",
       "      <th>alcohol_dehydrogenase_inhibitor</th>\n",
       "      <th>aldehyde_dehydrogenase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "      <th>sig_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_000644bb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_000779bfc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_000a6266a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_0015fd391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008396</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_001626bd3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abc_transporter_expression_enhancer  abl_inhibitor  ace_inhibitor  \\\n",
       "0                                0.001          0.001       0.004444   \n",
       "1                                0.001          0.001       0.005681   \n",
       "2                                0.001          0.001       0.001312   \n",
       "3                                0.001          0.001       0.001014   \n",
       "4                                0.001          0.001       0.008396   \n",
       "\n",
       "   acetylcholine_release_enhancer  adenosine_deaminase_inhibitor  \\\n",
       "0                           0.001                          0.001   \n",
       "1                           0.001                          0.001   \n",
       "2                           0.001                          0.001   \n",
       "3                           0.001                          0.001   \n",
       "4                           0.001                          0.001   \n",
       "\n",
       "   adenosine_kinase_inhibitor  adenylyl_cyclase_inhibitor  age_inhibitor  \\\n",
       "0                       0.001                       0.001       0.001000   \n",
       "1                       0.001                       0.001       0.001000   \n",
       "2                       0.001                       0.001       0.001000   \n",
       "3                       0.001                       0.001       0.001000   \n",
       "4                       0.001                       0.001       0.001738   \n",
       "\n",
       "   alcohol_dehydrogenase_inhibitor  aldehyde_dehydrogenase_activator  ...  \\\n",
       "0                            0.001                             0.001  ...   \n",
       "1                            0.001                             0.001  ...   \n",
       "2                            0.001                             0.001  ...   \n",
       "3                            0.001                             0.001  ...   \n",
       "4                            0.001                             0.001  ...   \n",
       "\n",
       "   vesicular_monoamine_transporter_inhibitor  vitamin_k_antagonist  \\\n",
       "0                                      0.001              0.001000   \n",
       "1                                      0.001              0.001114   \n",
       "2                                      0.001              0.001000   \n",
       "3                                      0.001              0.001000   \n",
       "4                                      0.001              0.001163   \n",
       "\n",
       "   voltage-gated_calcium_channel_ligand  \\\n",
       "0                                 0.001   \n",
       "1                                 0.001   \n",
       "2                                 0.001   \n",
       "3                                 0.001   \n",
       "4                                 0.001   \n",
       "\n",
       "   voltage-gated_potassium_channel_activator  \\\n",
       "0                                    0.00100   \n",
       "1                                    0.00100   \n",
       "2                                    0.00111   \n",
       "3                                    0.00100   \n",
       "4                                    0.00122   \n",
       "\n",
       "   voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                              0.001000                           0.001   \n",
       "1                              0.001000                           0.001   \n",
       "2                              0.001000                           0.001   \n",
       "3                              0.001000                           0.001   \n",
       "4                              0.001002                           0.001   \n",
       "\n",
       "   wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor        sig_id  \n",
       "0        0.001                    0.001000           0.001  id_000644bb2  \n",
       "1        0.001                    0.001231           0.001  id_000779bfc  \n",
       "2        0.001                    0.001000           0.001  id_000a6266a  \n",
       "3        0.001                    0.001000           0.001  id_0015fd391  \n",
       "4        0.001                    0.002459           0.001  id_001626bd3  \n",
       "\n",
       "[5 rows x 403 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create unscored train dataframes for next step\n",
    "train_label_unscored_df = pd.DataFrame(y_pred_train, columns=train_label_df.columns)\n",
    "train_label_unscored_df['sig_id'] = train_df['sig_id']\n",
    "train_label_unscored_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:38:31.361195Z",
     "iopub.status.busy": "2020-10-12T14:38:31.360278Z",
     "iopub.status.idle": "2020-10-12T14:38:31.387477Z",
     "shell.execute_reply": "2020-10-12T14:38:31.388024Z"
    },
    "papermill": {
     "duration": 25.500265,
     "end_time": "2020-10-12T14:38:31.388155",
     "exception": false,
     "start_time": "2020-10-12T14:38:05.887890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc_transporter_expression_enhancer</th>\n",
       "      <th>abl_inhibitor</th>\n",
       "      <th>ace_inhibitor</th>\n",
       "      <th>acetylcholine_release_enhancer</th>\n",
       "      <th>adenosine_deaminase_inhibitor</th>\n",
       "      <th>adenosine_kinase_inhibitor</th>\n",
       "      <th>adenylyl_cyclase_inhibitor</th>\n",
       "      <th>age_inhibitor</th>\n",
       "      <th>alcohol_dehydrogenase_inhibitor</th>\n",
       "      <th>aldehyde_dehydrogenase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "      <th>sig_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_0004d9e33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_001897cda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>id_002429b5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_00276f245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.001</td>\n",
       "      <td>id_0027f1083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abc_transporter_expression_enhancer  abl_inhibitor  ace_inhibitor  \\\n",
       "0                                0.001       0.001000       0.003472   \n",
       "1                                0.001       0.008222       0.001503   \n",
       "2                                0.000       0.000000       0.000000   \n",
       "3                                0.001       0.001000       0.001373   \n",
       "4                                0.001       0.001000       0.007461   \n",
       "\n",
       "   acetylcholine_release_enhancer  adenosine_deaminase_inhibitor  \\\n",
       "0                           0.001                          0.001   \n",
       "1                           0.001                          0.001   \n",
       "2                           0.000                          0.000   \n",
       "3                           0.001                          0.001   \n",
       "4                           0.001                          0.001   \n",
       "\n",
       "   adenosine_kinase_inhibitor  adenylyl_cyclase_inhibitor  age_inhibitor  \\\n",
       "0                       0.001                       0.001       0.001000   \n",
       "1                       0.001                       0.001       0.001000   \n",
       "2                       0.000                       0.000       0.000000   \n",
       "3                       0.001                       0.001       0.001000   \n",
       "4                       0.001                       0.001       0.001024   \n",
       "\n",
       "   alcohol_dehydrogenase_inhibitor  aldehyde_dehydrogenase_activator  ...  \\\n",
       "0                            0.001                             0.001  ...   \n",
       "1                            0.001                             0.001  ...   \n",
       "2                            0.000                             0.000  ...   \n",
       "3                            0.001                             0.001  ...   \n",
       "4                            0.001                             0.001  ...   \n",
       "\n",
       "   vesicular_monoamine_transporter_inhibitor  vitamin_k_antagonist  \\\n",
       "0                                      0.001                 0.001   \n",
       "1                                      0.001                 0.001   \n",
       "2                                      0.000                 0.000   \n",
       "3                                      0.001                 0.001   \n",
       "4                                      0.001                 0.001   \n",
       "\n",
       "   voltage-gated_calcium_channel_ligand  \\\n",
       "0                                 0.001   \n",
       "1                                 0.001   \n",
       "2                                 0.000   \n",
       "3                                 0.001   \n",
       "4                                 0.001   \n",
       "\n",
       "   voltage-gated_potassium_channel_activator  \\\n",
       "0                                   0.001372   \n",
       "1                                   0.001000   \n",
       "2                                   0.000000   \n",
       "3                                   0.001000   \n",
       "4                                   0.001000   \n",
       "\n",
       "   voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                              0.001043                           0.001   \n",
       "1                              0.001000                           0.001   \n",
       "2                              0.000000                           0.000   \n",
       "3                              0.001000                           0.001   \n",
       "4                              0.001000                           0.001   \n",
       "\n",
       "   wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor        sig_id  \n",
       "0        0.001                    0.001058           0.001  id_0004d9e33  \n",
       "1        0.001                    0.001000           0.001  id_001897cda  \n",
       "2        0.000                    0.000000           0.000  id_002429b5b  \n",
       "3        0.001                    0.001000           0.001  id_00276f245  \n",
       "4        0.001                    0.002504           0.001  id_0027f1083  \n",
       "\n",
       "[5 rows x 403 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create unscored predict dataframes for next step\n",
    "pred_labels_unscored_df = pd.DataFrame(y_pred_final, columns=train_label_df.columns)\n",
    "pred_labels_unscored_df.loc[predict_df['cp_type']=='ctl_vehicle', train_label_df.columns] = 0\n",
    "pred_labels_unscored_df['sig_id'] = predict_df['sig_id']\n",
    "pred_labels_unscored_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 24.819331,
     "end_time": "2020-10-12T14:39:22.145606",
     "exception": false,
     "start_time": "2020-10-12T14:38:57.326275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scored Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 25.182843,
     "end_time": "2020-10-12T14:40:12.553226",
     "exception": false,
     "start_time": "2020-10-12T14:39:47.370383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:41:03.228089Z",
     "iopub.status.busy": "2020-10-12T14:41:03.226252Z",
     "iopub.status.idle": "2020-10-12T14:41:03.228953Z",
     "shell.execute_reply": "2020-10-12T14:41:03.229422Z"
    },
    "papermill": {
     "duration": 25.109773,
     "end_time": "2020-10-12T14:41:03.229546",
     "exception": false,
     "start_time": "2020-10-12T14:40:38.119773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set file paths for train and predict datasets\n",
    "train_dataset = \"/kaggle/input/lish-moa/train_features.csv\"\n",
    "train_labels = \"/kaggle/input/lish-moa/train_targets_scored.csv\"\n",
    "predict_dataset = \"/kaggle/input/lish-moa/test_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:41:54.053948Z",
     "iopub.status.busy": "2020-10-12T14:41:54.053075Z",
     "iopub.status.idle": "2020-10-12T14:41:58.112255Z",
     "shell.execute_reply": "2020-10-12T14:41:58.112777Z"
    },
    "papermill": {
     "duration": 29.706386,
     "end_time": "2020-10-12T14:41:58.112925",
     "exception": false,
     "start_time": "2020-10-12T14:41:28.406539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (23814, 876)\n",
      "train_label_df: (23814, 207)\n",
      "predict_df: (3982, 876)\n"
     ]
    }
   ],
   "source": [
    "# Process train and predict features datasets\n",
    "train_df = pd.read_csv(train_dataset)\n",
    "train_label_df = pd.read_csv(train_labels)\n",
    "predict_df = pd.read_csv(predict_dataset)\n",
    "\n",
    "print(\"train_df: {}\".format(train_df.shape))\n",
    "print(\"train_label_df: {}\".format(train_label_df.shape))\n",
    "print(\"predict_df: {}\".format(predict_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:42:49.445722Z",
     "iopub.status.busy": "2020-10-12T14:42:49.444710Z",
     "iopub.status.idle": "2020-10-12T14:42:49.580768Z",
     "shell.execute_reply": "2020-10-12T14:42:49.580204Z"
    },
    "papermill": {
     "duration": 26.562113,
     "end_time": "2020-10-12T14:42:49.580886",
     "exception": false,
     "start_time": "2020-10-12T14:42:23.018773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label_df: (21948, 207)\n",
      "train_df: (21948, 876)\n"
     ]
    }
   ],
   "source": [
    "train_label_df = train_label_df.loc[train_df['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "train_df = train_df.loc[train_df['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "\n",
    "print(\"train_label_df: {}\".format(train_label_df.shape))\n",
    "print(\"train_df: {}\".format(train_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:43:40.038373Z",
     "iopub.status.busy": "2020-10-12T14:43:40.037527Z",
     "iopub.status.idle": "2020-10-12T14:43:40.328874Z",
     "shell.execute_reply": "2020-10-12T14:43:40.330023Z"
    },
    "papermill": {
     "duration": 25.909273,
     "end_time": "2020-10-12T14:43:40.330268",
     "exception": false,
     "start_time": "2020-10-12T14:43:14.420995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (21948, 1278)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>ve-cadherin_antagonist</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...  ve-cadherin_antagonist  \\\n",
       "0 -0.1944 -1.0120  ...                   0.001   \n",
       "1  1.0190  0.5207  ...                   0.001   \n",
       "2 -0.0323  1.2390  ...                   0.001   \n",
       "3  4.0620 -0.8095  ...                   0.001   \n",
       "4  1.4180 -0.8244  ...                   0.001   \n",
       "\n",
       "   vesicular_monoamine_transporter_inhibitor  vitamin_k_antagonist  \\\n",
       "0                                      0.001              0.001000   \n",
       "1                                      0.001              0.001114   \n",
       "2                                      0.001              0.001000   \n",
       "3                                      0.001              0.001000   \n",
       "4                                      0.001              0.001163   \n",
       "\n",
       "   voltage-gated_calcium_channel_ligand  \\\n",
       "0                                 0.001   \n",
       "1                                 0.001   \n",
       "2                                 0.001   \n",
       "3                                 0.001   \n",
       "4                                 0.001   \n",
       "\n",
       "   voltage-gated_potassium_channel_activator  \\\n",
       "0                                    0.00100   \n",
       "1                                    0.00100   \n",
       "2                                    0.00111   \n",
       "3                                    0.00100   \n",
       "4                                    0.00122   \n",
       "\n",
       "   voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                              0.001000                           0.001   \n",
       "1                              0.001000                           0.001   \n",
       "2                              0.001000                           0.001   \n",
       "3                              0.001000                           0.001   \n",
       "4                              0.001002                           0.001   \n",
       "\n",
       "   wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor  \n",
       "0        0.001                    0.001000           0.001  \n",
       "1        0.001                    0.001231           0.001  \n",
       "2        0.001                    0.001000           0.001  \n",
       "3        0.001                    0.001000           0.001  \n",
       "4        0.001                    0.002459           0.001  \n",
       "\n",
       "[5 rows x 1278 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.merge(train_df, train_label_unscored_df, \n",
    "                    how='inner', on='sig_id')\n",
    "print(\"train_df: {}\".format(train_df.shape))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:44:30.043718Z",
     "iopub.status.busy": "2020-10-12T14:44:30.042874Z",
     "iopub.status.idle": "2020-10-12T14:44:30.109685Z",
     "shell.execute_reply": "2020-10-12T14:44:30.110823Z"
    },
    "papermill": {
     "duration": 24.92422,
     "end_time": "2020-10-12T14:44:30.111016",
     "exception": false,
     "start_time": "2020-10-12T14:44:05.186796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_df: (3982, 1278)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>ve-cadherin_antagonist</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1  id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2  id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3  id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825  0.4244   \n",
       "4  id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130  0.2057   \n",
       "\n",
       "      g-4     g-5  ...  ve-cadherin_antagonist  \\\n",
       "0  1.5500 -0.1644  ...                   0.001   \n",
       "1 -0.3652 -0.3319  ...                   0.001   \n",
       "2 -1.4380  0.2455  ...                   0.000   \n",
       "3 -0.5855 -1.2020  ...                   0.001   \n",
       "4 -0.5864 -0.0166  ...                   0.001   \n",
       "\n",
       "   vesicular_monoamine_transporter_inhibitor  vitamin_k_antagonist  \\\n",
       "0                                      0.001                 0.001   \n",
       "1                                      0.001                 0.001   \n",
       "2                                      0.000                 0.000   \n",
       "3                                      0.001                 0.001   \n",
       "4                                      0.001                 0.001   \n",
       "\n",
       "   voltage-gated_calcium_channel_ligand  \\\n",
       "0                                 0.001   \n",
       "1                                 0.001   \n",
       "2                                 0.000   \n",
       "3                                 0.001   \n",
       "4                                 0.001   \n",
       "\n",
       "   voltage-gated_potassium_channel_activator  \\\n",
       "0                                   0.001372   \n",
       "1                                   0.001000   \n",
       "2                                   0.000000   \n",
       "3                                   0.001000   \n",
       "4                                   0.001000   \n",
       "\n",
       "   voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                              0.001043                           0.001   \n",
       "1                              0.001000                           0.001   \n",
       "2                              0.000000                           0.000   \n",
       "3                              0.001000                           0.001   \n",
       "4                              0.001000                           0.001   \n",
       "\n",
       "   wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor  \n",
       "0        0.001                    0.001058           0.001  \n",
       "1        0.001                    0.001000           0.001  \n",
       "2        0.000                    0.000000           0.000  \n",
       "3        0.001                    0.001000           0.001  \n",
       "4        0.001                    0.002504           0.001  \n",
       "\n",
       "[5 rows x 1278 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df = pd.merge(predict_df, pred_labels_unscored_df, \n",
    "                      how='inner', on='sig_id')\n",
    "print(\"predict_df: {}\".format(predict_df.shape))\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:45:20.726981Z",
     "iopub.status.busy": "2020-10-12T14:45:20.709240Z",
     "iopub.status.idle": "2020-10-12T14:45:20.734277Z",
     "shell.execute_reply": "2020-10-12T14:45:20.733704Z"
    },
    "papermill": {
     "duration": 25.267304,
     "end_time": "2020-10-12T14:45:20.734393",
     "exception": false,
     "start_time": "2020-10-12T14:44:55.467089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: (21948, 206)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                            0                       0               0   \n",
       "1                            0                       0               0   \n",
       "2                            0                       0               0   \n",
       "3                            0                       0               0   \n",
       "4                            0                       0               0   \n",
       "\n",
       "   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                               0                                  0   \n",
       "1                               0                                  0   \n",
       "2                               0                                  0   \n",
       "3                               0                                  0   \n",
       "4                               0                                  0   \n",
       "\n",
       "   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "\n",
       "   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                              0                           0   \n",
       "1                              0                           0   \n",
       "2                              0                           0   \n",
       "3                              0                           0   \n",
       "4                              0                           0   \n",
       "\n",
       "   adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                            0  ...                                      0   \n",
       "1                            0  ...                                      0   \n",
       "2                            0  ...                                      0   \n",
       "3                            0  ...                                      0   \n",
       "4                            0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_df.drop(['sig_id'], axis=1, inplace=True)\n",
    "train_y = train_label_df.values\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "train_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:46:10.727835Z",
     "iopub.status.busy": "2020-10-12T14:46:10.726151Z",
     "iopub.status.idle": "2020-10-12T14:46:10.963762Z",
     "shell.execute_reply": "2020-10-12T14:46:10.963227Z"
    },
    "papermill": {
     "duration": 24.93795,
     "end_time": "2020-10-12T14:46:10.963899",
     "exception": false,
     "start_time": "2020-10-12T14:45:46.025949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (21948, 1278)\n",
      "predict_df: (3982, 1278)\n",
      "train_x: (21948, 1277)\n",
      "predict_x: (3982, 1277)\n"
     ]
    }
   ],
   "source": [
    "train_x, Xpredict = data_preprocess(train_df, predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 24.899154,
     "end_time": "2020-10-12T14:47:01.947176",
     "exception": false,
     "start_time": "2020-10-12T14:46:37.048022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:47:52.560462Z",
     "iopub.status.busy": "2020-10-12T14:47:52.559244Z",
     "iopub.status.idle": "2020-10-12T15:58:30.276791Z",
     "shell.execute_reply": "2020-10-12T15:58:30.277934Z"
    },
    "papermill": {
     "duration": 4263.206217,
     "end_time": "2020-10-12T15:58:30.278147",
     "exception": false,
     "start_time": "2020-10-12T14:47:27.071930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 0 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.3418 - val_loss: 0.1317\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1262 - val_loss: 0.0585\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1885 - val_loss: 0.1489\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0630 - val_loss: 0.0544\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0764 - val_loss: 0.0654\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0534 - val_loss: 0.0431\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0663 - val_loss: 0.0704\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0611 - val_loss: 0.0591\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0531 - val_loss: 0.0453\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0523 - val_loss: 0.0377\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0525 - val_loss: 0.0750\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0480 - val_loss: 0.0450\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0476 - val_loss: 0.0374\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0462 - val_loss: 0.0640\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0440 - val_loss: 0.0443\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0433 - val_loss: 0.0356\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0420 - val_loss: 0.0525\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0404 - val_loss: 0.0469\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0398 - val_loss: 0.0361\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0393 - val_loss: 0.0309\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0386 - val_loss: 0.0435\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.0346\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0297\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0364 - val_loss: 0.0387\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0356 - val_loss: 0.0357\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0347 - val_loss: 0.0300\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0338 - val_loss: 0.0404\n",
      "Epoch 28/85\n",
      "139/147 [===========================>..] - ETA: 0s - loss: 0.0343\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0342 - val_loss: 0.0368\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0222 - val_loss: 0.0223\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0207 - val_loss: 0.0204\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0205 - val_loss: 0.0200\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0197\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0200\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0202 - val_loss: 0.0194\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 38/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0201 - val_loss: 0.0199\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0201 - val_loss: 0.0194\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0200 - val_loss: 0.0193\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0191\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0193\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 48/85\n",
      "141/147 [===========================>..] - ETA: 0s - loss: 0.0197\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 68/85\n",
      "141/147 [===========================>..] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0163\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0163\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0163\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0163\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0163\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [08:14<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 1 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3386 - val_loss: 0.1285\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1391 - val_loss: 0.0919\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0951 - val_loss: 0.0530\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0680 - val_loss: 0.1301\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1250 - val_loss: 0.0684\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0996 - val_loss: 0.0502\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0578 - val_loss: 0.0758\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.0531\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0506 - val_loss: 0.0418\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0490 - val_loss: 0.0400\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0466 - val_loss: 0.0629\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0479 - val_loss: 0.0416\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0450 - val_loss: 0.0347\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0428 - val_loss: 0.0528\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0432 - val_loss: 0.0437\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0425 - val_loss: 0.0345\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0404 - val_loss: 0.0511\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0432\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0394 - val_loss: 0.0352\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0386 - val_loss: 0.0290\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0377 - val_loss: 0.0436\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.0386\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0374 - val_loss: 0.0300\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0357 - val_loss: 0.0391\n",
      "Epoch 25/85\n",
      "141/147 [===========================>..] - ETA: 0s - loss: 0.0349\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0348 - val_loss: 0.0366\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0228\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0208 - val_loss: 0.0216\n",
      "Epoch 28/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0211\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0207 - val_loss: 0.0204\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0209\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0199\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0203 - val_loss: 0.0207\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0206\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 37/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0206\n",
      "Epoch 38/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0178\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0174 - val_loss: 0.0177\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0174\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0174\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0171\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0171\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0171\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0171\n",
      "Epoch 57/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0169\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [08:25<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 2 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3402 - val_loss: 0.0969\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1249 - val_loss: 0.0588\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1003 - val_loss: 0.0580\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1401 - val_loss: 0.1089\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0837 - val_loss: 0.1179\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0622 - val_loss: 0.0590\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0686 - val_loss: 0.0786\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0523 - val_loss: 0.0544\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0548 - val_loss: 0.0426\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0511 - val_loss: 0.0422\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0691 - val_loss: 0.0698\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0470 - val_loss: 0.0454\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0459 - val_loss: 0.0379\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0438 - val_loss: 0.0518\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0424 - val_loss: 0.0477\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0413 - val_loss: 0.0337\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0411 - val_loss: 0.0467\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0431\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0396 - val_loss: 0.0332\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0388 - val_loss: 0.0309\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0389 - val_loss: 0.0434\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0376 - val_loss: 0.0363\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0294\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0403\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0351 - val_loss: 0.0365\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0347 - val_loss: 0.0296\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0340 - val_loss: 0.0385\n",
      "Epoch 28/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0340\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0389\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0225 - val_loss: 0.0221\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0199\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0202 - val_loss: 0.0196\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0201\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 38/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0200\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0198\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 57/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.0165\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0171\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0168\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0168\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [08:25<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 3 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.3434 - val_loss: 0.0960\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1305 - val_loss: 0.0917\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1305 - val_loss: 0.0540\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1060 - val_loss: 0.5684\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0787 - val_loss: 0.0495\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0585 - val_loss: 0.0750\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0779 - val_loss: 0.0636\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0527 - val_loss: 0.0624\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0546 - val_loss: 0.0510\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0514 - val_loss: 0.0396\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0481 - val_loss: 0.0634\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0474 - val_loss: 0.0418\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0458 - val_loss: 0.0351\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0446 - val_loss: 0.0580\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0429 - val_loss: 0.0461\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0422 - val_loss: 0.0332\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0413 - val_loss: 0.0492\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0411 - val_loss: 0.0455\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0404 - val_loss: 0.0340\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0297\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0387 - val_loss: 0.0436\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0356\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0372 - val_loss: 0.0285\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0368 - val_loss: 0.0414\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0365 - val_loss: 0.0380\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0356 - val_loss: 0.0309\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0348 - val_loss: 0.0413\n",
      "Epoch 28/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0339\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0339 - val_loss: 0.0380\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0225 - val_loss: 0.0226\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0204\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0204 - val_loss: 0.0199\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0197\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0201 - val_loss: 0.0199\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0198\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 38/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.0199\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0179\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 2s 14ms/step - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 54/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0168\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0161 - val_loss: 0.0167\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0166\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0166\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0165\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0165\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0165\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0165\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [08:35<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 4 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3303 - val_loss: 0.1714\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1566 - val_loss: 0.3261\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0936 - val_loss: 0.0438\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1268 - val_loss: 0.1305\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0835 - val_loss: 1.1079\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1808 - val_loss: 0.0509\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0528 - val_loss: 0.0715\n",
      "Epoch 8/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.0532\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0531 - val_loss: 0.0529\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0311 - val_loss: 0.0289\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0266\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0259 - val_loss: 0.0258\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0259\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0244\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0254\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0247 - val_loss: 0.0243\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0249 - val_loss: 0.0264\n",
      "Epoch 18/85\n",
      "141/147 [===========================>..] - ETA: 0s - loss: 0.0255\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0255 - val_loss: 0.0249\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0228 - val_loss: 0.0221\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0197\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0196\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0193\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0190\n",
      "Epoch 28/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0191\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0189\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0187\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0188\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0187\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0186\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0188\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0186\n",
      "Epoch 38/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0184\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0187\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0185\n",
      "Epoch 43/85\n",
      "145/147 [============================>.] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0184\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0182\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0181\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0148 - val_loss: 0.0181\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0181\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0180\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0180\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0180\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0180\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0179\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0179\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0179\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0179\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0179\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0178\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0179\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0178\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0178\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0178\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0177\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0133 - val_loss: 0.0178\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0178\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0177\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0177\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0177\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0177\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0177\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0177\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0176\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0177\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0176\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0176\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0176\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0176\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [08:37<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 5 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3391 - val_loss: 0.1470\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1217 - val_loss: 0.0716\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0968 - val_loss: 0.0480\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0770 - val_loss: 0.0974\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1215 - val_loss: 0.0496\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0864 - val_loss: 0.0905\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0905 - val_loss: 0.0653\n",
      "Epoch 8/85\n",
      "141/147 [===========================>..] - ETA: 0s - loss: 0.0528\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0525 - val_loss: 0.0520\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0298 - val_loss: 0.0280\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0258 - val_loss: 0.0254\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0252 - val_loss: 0.0271\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0251\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0247\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0250\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0249 - val_loss: 0.0249\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0248\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0259\n",
      "Epoch 18/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0248\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 2s 10ms/step - loss: 0.0248 - val_loss: 0.0255\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0228 - val_loss: 0.0222\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0197\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0196\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0192\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 28/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0190\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0188\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0187\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0187\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0185\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0186\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0168 - val_loss: 0.0184\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 38/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0185\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0188\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0184\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0184\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0184\n",
      "Epoch 45/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0184\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0182\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0181\n",
      "Epoch 48/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0181\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0181\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0180\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0180\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0180\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0180\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0180\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0180\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0179\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0179\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0179\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0179\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0178\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0178\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0178\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0178\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0178\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0177\n",
      "Epoch 69/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0132 - val_loss: 0.0177\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0132 - val_loss: 0.0177\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0131 - val_loss: 0.0177\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0131 - val_loss: 0.0177\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0129 - val_loss: 0.0177\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0128 - val_loss: 0.0177\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0177\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0128 - val_loss: 0.0177\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0176\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0127 - val_loss: 0.0176\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0126 - val_loss: 0.0176\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0125 - val_loss: 0.0176\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0176\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0125 - val_loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [08:31<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 6 ----------------\n",
      "Epoch 1/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.3318 - val_loss: 0.0856\n",
      "Epoch 2/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1496 - val_loss: 0.1385\n",
      "Epoch 3/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1124 - val_loss: 0.2262\n",
      "Epoch 4/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0870 - val_loss: 0.0665\n",
      "Epoch 5/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0570 - val_loss: 0.0600\n",
      "Epoch 6/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0711 - val_loss: 0.1292\n",
      "Epoch 7/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0666 - val_loss: 0.0787\n",
      "Epoch 8/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0560 - val_loss: 0.0587\n",
      "Epoch 9/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0522 - val_loss: 0.0406\n",
      "Epoch 10/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0613 - val_loss: 0.0371\n",
      "Epoch 11/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0555 - val_loss: 0.0485\n",
      "Epoch 12/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0465 - val_loss: 0.0437\n",
      "Epoch 13/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0449 - val_loss: 0.0358\n",
      "Epoch 14/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0431 - val_loss: 0.0601\n",
      "Epoch 15/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0423 - val_loss: 0.0427\n",
      "Epoch 16/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0413 - val_loss: 0.0323\n",
      "Epoch 17/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0406 - val_loss: 0.0600\n",
      "Epoch 18/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0400 - val_loss: 0.0488\n",
      "Epoch 19/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0392 - val_loss: 0.0347\n",
      "Epoch 20/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0381 - val_loss: 0.0308\n",
      "Epoch 21/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0387 - val_loss: 0.0446\n",
      "Epoch 22/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0376 - val_loss: 0.0365\n",
      "Epoch 23/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0372 - val_loss: 0.0302\n",
      "Epoch 24/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0363 - val_loss: 0.0440\n",
      "Epoch 25/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0351 - val_loss: 0.0363\n",
      "Epoch 26/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0302\n",
      "Epoch 27/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0408\n",
      "Epoch 28/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0336\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0336 - val_loss: 0.0373\n",
      "Epoch 29/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0224 - val_loss: 0.0222\n",
      "Epoch 30/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 31/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 32/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 33/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 34/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 35/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 36/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 37/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0203\n",
      "Epoch 38/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 39/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 40/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 41/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 42/85\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 43/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 44/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 45/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 46/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 47/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0197 - val_loss: 0.0198\n",
      "Epoch 48/85\n",
      "144/147 [============================>.] - ETA: 0s - loss: 0.0196\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 49/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0183\n",
      "Epoch 50/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 51/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 52/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 53/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 54/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 55/85\n",
      "147/147 [==============================] - 2s 13ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 56/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 57/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 58/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 59/85\n",
      "147/147 [==============================] - 2s 10ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 60/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 61/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 62/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0164 - val_loss: 0.0168\n",
      "Epoch 63/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0168\n",
      "Epoch 64/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0168\n",
      "Epoch 65/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 66/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 67/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 68/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 69/85\n",
      "146/147 [============================>.] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 70/85\n",
      "147/147 [==============================] - 2s 10ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 71/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 72/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 73/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 74/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 75/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 76/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 77/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 78/85\n",
      "147/147 [==============================] - 2s 11ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 79/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 80/85\n",
      "147/147 [==============================] - 2s 12ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 81/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 82/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 83/85\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 84/85\n",
      "147/147 [==============================] - 1s 10ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 85/85\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [08:16<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare datasets for training\n",
    "Xtrain = train_x.copy()\n",
    "Ytrain = train_y.copy()\n",
    "\n",
    "\n",
    "# Define the model hyperparameters\n",
    "mini_batch_size = 128\n",
    "perm_imp = np.zeros(Xtrain.shape[1])\n",
    "\n",
    "\n",
    "# Define K-fold cross validation test harness\n",
    "kfold = MultilabelStratifiedKFold(n_splits=7, shuffle=True, random_state=50)\n",
    "\n",
    "for idx, (train, val) in enumerate(kfold.split(Xtrain, Ytrain)):\n",
    "    \n",
    "    print(\"\\n---------------- Fold {} ----------------\".format(idx))\n",
    "    \n",
    "    train_x_tmp, val_x_tmp = Xtrain[train], Xtrain[val]\n",
    "    train_y_tmp, val_y_tmp = Ytrain[train], Ytrain[val]\n",
    "    \n",
    "    # Create the model\n",
    "    model = moa_prediction_model(Xtrain.shape[1], Ytrain.shape[1])\n",
    "\n",
    "    # Compile model to configure the learning process\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Lookahead(AdamW(lr=1e-2, \n",
    "                                            weight_decay=1e-5, \n",
    "                                            clipvalue=700), \n",
    "                                      sync_period=10))\n",
    "    \n",
    "    # Early stopping policy\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n",
    "                          restore_best_weights=True, \n",
    "                          patience=7, verbose=1)\n",
    "    \n",
    "    # Reduce LR on plateau policy\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, \n",
    "                                  min_lr=1e-5, patience=5, \n",
    "                                  verbose=1, mode='min')\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(x=train_x_tmp, y=train_y_tmp, \n",
    "                        batch_size=mini_batch_size, epochs=85, verbose=1,\n",
    "                        callbacks=[reduce_lr, early], workers=5,\n",
    "                        validation_data=(val_x_tmp, val_y_tmp))\n",
    "    \n",
    "    fet_imp = PermutationImportance(model, val_x_tmp, val_y_tmp, n_iter=1, random_state=50)\n",
    "    _, local_imp = fet_imp.get_score_importances()\n",
    "    perm_imp += np.mean(local_imp, axis=0)\n",
    "\n",
    "\n",
    "top_feats = np.argwhere(perm_imp < 0).flatten()\n",
    "print(len(top_feats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T15:59:37.417841Z",
     "iopub.status.busy": "2020-10-12T15:59:37.415989Z",
     "iopub.status.idle": "2020-10-12T15:59:37.420313Z",
     "shell.execute_reply": "2020-10-12T15:59:37.419809Z"
    },
    "papermill": {
     "duration": 33.356577,
     "end_time": "2020-10-12T15:59:37.420414",
     "exception": false,
     "start_time": "2020-10-12T15:59:04.063837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1273, 1275, 1276])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T16:00:44.296629Z",
     "iopub.status.busy": "2020-10-12T16:00:44.295715Z",
     "iopub.status.idle": "2020-10-12T16:00:44.298677Z",
     "shell.execute_reply": "2020-10-12T16:00:44.299154Z"
    },
    "papermill": {
     "duration": 33.712089,
     "end_time": "2020-10-12T16:00:44.299281",
     "exception": false,
     "start_time": "2020-10-12T16:00:10.587192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntop_feats = \\n\\nprint(len(top_feats))\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "top_feats = \n",
    "\n",
    "print(len(top_feats))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 33.988916,
     "end_time": "2020-10-12T16:01:50.909727",
     "exception": false,
     "start_time": "2020-10-12T16:01:16.920811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split training data into train / test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T16:02:57.099054Z",
     "iopub.status.busy": "2020-10-12T16:02:57.098140Z",
     "iopub.status.idle": "2020-10-12T16:02:58.812943Z",
     "shell.execute_reply": "2020-10-12T16:02:58.811991Z"
    },
    "papermill": {
     "duration": 35.291978,
     "end_time": "2020-10-12T16:02:58.813070",
     "exception": false,
     "start_time": "2020-10-12T16:02:23.521092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.085, random_state=10)\n",
    "for train_index, test_index in sss.split(train_x, train_y):\n",
    "    Xtrain, Xtest = train_x[train_index], train_x[test_index]\n",
    "    Ytrain, Ytest = train_y[train_index], train_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T16:04:05.854378Z",
     "iopub.status.busy": "2020-10-12T16:04:05.853277Z",
     "iopub.status.idle": "2020-10-12T16:04:05.999838Z",
     "shell.execute_reply": "2020-10-12T16:04:05.999262Z"
    },
    "papermill": {
     "duration": 33.474814,
     "end_time": "2020-10-12T16:04:05.999946",
     "exception": false,
     "start_time": "2020-10-12T16:03:32.525132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training Dataset -------------------------\n",
      "Xtrain_full shape: (21948, 722)\n",
      "Xtrain shape: (20082, 1071)\n",
      "Ytrain shape: (20082, 206)\n",
      "\n",
      "------------------------- Test Dataset -------------------------\n",
      "Xtest shape: (1866, 1071)\n",
      "Ytest shape: (1866, 206)\n",
      "\n",
      "------------------------- Prediction Dataset -------------------------\n",
      "Xpredict shape: (3982, 1071)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = Xtrain[:, top_feats]\n",
    "Xtest = Xtest[:, top_feats]\n",
    "Xpredict = Xpredict[:, top_feats]\n",
    "\n",
    "print(\"------------------------- Training Dataset -------------------------\")\n",
    "print(\"Xtrain_full shape: {}\".format(Xtrain_full.shape))\n",
    "print(\"Xtrain shape: {}\".format(Xtrain.shape))\n",
    "print(\"Ytrain shape: {}\".format(Ytrain.shape))\n",
    "\n",
    "print(\"\\n------------------------- Test Dataset -------------------------\")\n",
    "print(\"Xtest shape: {}\".format(Xtest.shape))\n",
    "print(\"Ytest shape: {}\".format(Ytest.shape))\n",
    "\n",
    "print(\"\\n------------------------- Prediction Dataset -------------------------\")\n",
    "print(\"Xpredict shape: {}\".format(Xpredict.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 32.586251,
     "end_time": "2020-10-12T16:05:12.045846",
     "exception": false,
     "start_time": "2020-10-12T16:04:39.459595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Build and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T16:06:18.512600Z",
     "iopub.status.busy": "2020-10-12T16:06:18.511659Z",
     "iopub.status.idle": "2020-10-12T16:06:18.646811Z",
     "shell.execute_reply": "2020-10-12T16:06:18.648007Z"
    },
    "papermill": {
     "duration": 33.106708,
     "end_time": "2020-10-12T16:06:18.648212",
     "exception": false,
     "start_time": "2020-10-12T16:05:45.541504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MOA_Prediction_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           [(None, 1071)]            0         \n",
      "_________________________________________________________________\n",
      "BN-INPUT (BatchNormalization (None, 1071)              4284      \n",
      "_________________________________________________________________\n",
      "FC-1 (Dense)                 (None, 2048)              2195456   \n",
      "_________________________________________________________________\n",
      "BN_FC-1 (BatchNormalization) (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "DROPOUT_FC-1 (Dropout)       (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "FC-2 (Dense)                 (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "BN_FC-2 (BatchNormalization) (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "DROPOUT_FC-2 (Dropout)       (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 206)               105678    \n",
      "=================================================================\n",
      "Total params: 3,364,746\n",
      "Trainable params: 3,357,484\n",
      "Non-trainable params: 7,262\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model hyperparameters\n",
    "mini_batch_size = 128\n",
    "\n",
    "# Prediction Clipping Thresholds\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "# Create the model\n",
    "model = moa_prediction_model(Xtrain.shape[1], Ytrain.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T16:07:25.370483Z",
     "iopub.status.busy": "2020-10-12T16:07:25.369664Z",
     "iopub.status.idle": "2020-10-12T16:07:26.005069Z",
     "shell.execute_reply": "2020-10-12T16:07:26.004530Z"
    },
    "papermill": {
     "duration": 33.617346,
     "end_time": "2020-10-12T16:07:26.005190",
     "exception": false,
     "start_time": "2020-10-12T16:06:52.387844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='/kaggle/working/moa_prediction_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T16:08:33.199911Z",
     "iopub.status.busy": "2020-10-12T16:08:33.194511Z",
     "iopub.status.idle": "2020-10-12T17:01:52.547568Z",
     "shell.execute_reply": "2020-10-12T17:01:52.543720Z"
    },
    "papermill": {
     "duration": 3233.018548,
     "end_time": "2020-10-12T17:01:52.547785",
     "exception": false,
     "start_time": "2020-10-12T16:07:59.529237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Fold 1 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3461 - val_loss: 0.1747\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1335 - val_loss: 0.1123\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1178 - val_loss: 0.3865\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1365 - val_loss: 0.0645\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0582 - val_loss: 0.0490\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0752 - val_loss: 0.0504\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0551 - val_loss: 0.0571\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1390 - val_loss: 0.0721\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0709 - val_loss: 0.0517\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0496 - val_loss: 0.0411\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0484 - val_loss: 0.0515\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0469 - val_loss: 0.0363\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0454 - val_loss: 0.0447\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0434 - val_loss: 0.0346\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0421 - val_loss: 0.0408\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0418 - val_loss: 0.0323\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0397 - val_loss: 0.0419\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0398 - val_loss: 0.0305\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0383 - val_loss: 0.0434\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0315\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0376 - val_loss: 0.0431\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0372 - val_loss: 0.0294\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0375 - val_loss: 0.0379\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0365 - val_loss: 0.0295\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0400\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0357 - val_loss: 0.0281\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0346 - val_loss: 0.0399\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0347 - val_loss: 0.0288\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0348 - val_loss: 0.0377\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0334 - val_loss: 0.0278\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0330 - val_loss: 0.0346\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0332 - val_loss: 0.0282\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0319 - val_loss: 0.0343\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0313 - val_loss: 0.0262\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0311 - val_loss: 0.0319\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0306 - val_loss: 0.0254\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0298 - val_loss: 0.0307\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0297 - val_loss: 0.0250\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0289 - val_loss: 0.0314\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0282 - val_loss: 0.0248\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0277\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0248\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0274\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0239\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0270 - val_loss: 0.0277\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0263 - val_loss: 0.0245\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0272\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0259 - val_loss: 0.0229\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0258 - val_loss: 0.0273\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0256 - val_loss: 0.0233\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0252 - val_loss: 0.0259\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0251 - val_loss: 0.0230\n",
      "Epoch 53/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0251\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0258\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0184\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "---------------- Fold 2 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3621 - val_loss: 0.1767\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1042 - val_loss: 0.0744\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1405 - val_loss: 0.0686\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0962 - val_loss: 0.0704\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0673 - val_loss: 0.0645\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0759 - val_loss: 0.0912\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0674 - val_loss: 0.0566\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1100 - val_loss: 0.0459\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0525 - val_loss: 0.0499\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0541 - val_loss: 0.0394\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0484 - val_loss: 0.0576\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0491 - val_loss: 0.0376\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0453 - val_loss: 0.0580\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0469 - val_loss: 0.0365\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0429 - val_loss: 0.0468\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0432 - val_loss: 0.0330\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0421 - val_loss: 0.0419\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0413 - val_loss: 0.0310\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0401 - val_loss: 0.0429\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0313\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0385 - val_loss: 0.0376\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0386 - val_loss: 0.0296\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0367 - val_loss: 0.0396\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0371 - val_loss: 0.0295\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0365 - val_loss: 0.0433\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0377 - val_loss: 0.0284\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0347 - val_loss: 0.0380\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0350 - val_loss: 0.0292\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0335 - val_loss: 0.0358\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0334 - val_loss: 0.0264\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0330 - val_loss: 0.0361\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0327 - val_loss: 0.0267\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0317 - val_loss: 0.0328\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0316 - val_loss: 0.0259\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0311 - val_loss: 0.0328\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0306 - val_loss: 0.0256\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0301 - val_loss: 0.0313\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0296 - val_loss: 0.0260\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0287 - val_loss: 0.0310\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0243\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0294\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0277 - val_loss: 0.0241\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0284\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0239\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0272\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0239\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0260 - val_loss: 0.0274\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0233\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0261 - val_loss: 0.0271\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0261 - val_loss: 0.0229\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0253 - val_loss: 0.0264\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0224\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0245\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0226\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0256\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0246 - val_loss: 0.0221\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0241 - val_loss: 0.0263\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0245 - val_loss: 0.0225\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0242 - val_loss: 0.0246\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0243 - val_loss: 0.0219\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0251\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0242 - val_loss: 0.0218\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0243 - val_loss: 0.0245\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0242 - val_loss: 0.0222\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0240 - val_loss: 0.0243\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0216\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0253\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0215\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0236 - val_loss: 0.0237\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0219\n",
      "Epoch 71/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0240\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0241\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0187\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0181\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0176\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 83/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0179\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "---------------- Fold 3 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3616 - val_loss: 0.1469\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0876 - val_loss: 0.1556\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1266 - val_loss: 0.5834\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1122 - val_loss: 0.0800\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1049 - val_loss: 0.0507\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0771 - val_loss: 0.0465\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0603 - val_loss: 0.0493\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0515 - val_loss: 0.0391\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0521 - val_loss: 0.0569\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0489 - val_loss: 0.0405\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0489 - val_loss: 0.0458\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0465 - val_loss: 0.0363\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0461 - val_loss: 0.0463\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0455 - val_loss: 0.0331\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0434 - val_loss: 0.0451\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0422 - val_loss: 0.0314\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0412 - val_loss: 0.0423\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0415 - val_loss: 0.0323\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0404 - val_loss: 0.0491\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0314\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0377 - val_loss: 0.0415\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0246 - val_loss: 0.0239\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0220 - val_loss: 0.0225\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0218 - val_loss: 0.0212\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0216 - val_loss: 0.0213\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0214 - val_loss: 0.0207\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0214 - val_loss: 0.0206\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0215 - val_loss: 0.0208\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0207\n",
      "Epoch 33/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0214\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0193\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0182\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0178\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0176\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0174\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0174\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 51/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0172\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0147 - val_loss: 0.0167\n",
      "---------------- Fold 4 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3443 - val_loss: 0.0830\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1067 - val_loss: 0.0433\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1070 - val_loss: 0.0468\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0990 - val_loss: 0.0409\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0945 - val_loss: 0.0849\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0674 - val_loss: 0.0467\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0597 - val_loss: 0.0503\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0587 - val_loss: 0.0647\n",
      "Epoch 9/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0536\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0535 - val_loss: 0.0521\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0329 - val_loss: 0.0294\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0268 - val_loss: 0.0272\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0258 - val_loss: 0.0247\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0247 - val_loss: 0.0254\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0252 - val_loss: 0.0253\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0278\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0252 - val_loss: 0.0244\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0248 - val_loss: 0.0239\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0236\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0245 - val_loss: 0.0241\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0244 - val_loss: 0.0236\n",
      "Epoch 23/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0243\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0251\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0221\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0203\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0200\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0196\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0195\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0192\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0189\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0191\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0188\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0187\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0186\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0186\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0185\n",
      "Epoch 41/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0186\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0182\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0182\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0181\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.0181\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0181\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0181\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0180\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0180\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0180\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0179\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0179\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0179\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0178\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0178\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0178\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0178\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0178\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0178\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0178\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0177\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0177\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0177\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0177\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0177\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0177\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0177\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0177\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0176\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0176\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0177\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0176\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0133 - val_loss: 0.0176\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0176\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0176\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0176\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0176\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0176\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0176\n",
      "---------------- Fold 5 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3425 - val_loss: 0.1974\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1562 - val_loss: 0.1654\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0830 - val_loss: 0.0493\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1522 - val_loss: 0.0530\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0895 - val_loss: 0.0523\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0645 - val_loss: 0.0429\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0767 - val_loss: 0.0517\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0627 - val_loss: 0.0577\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0528 - val_loss: 0.0550\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0528 - val_loss: 0.0385\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0490 - val_loss: 0.0497\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0512 - val_loss: 0.0377\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0474 - val_loss: 0.0448\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0455 - val_loss: 0.0358\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0429 - val_loss: 0.0462\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0437 - val_loss: 0.0334\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0411 - val_loss: 0.0438\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0410 - val_loss: 0.0325\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0403 - val_loss: 0.0419\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0305\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0388 - val_loss: 0.0410\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0385 - val_loss: 0.0302\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0390\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0370 - val_loss: 0.0309\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0367 - val_loss: 0.0410\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0358 - val_loss: 0.0364\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0346 - val_loss: 0.0274\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0347 - val_loss: 0.0416\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0345 - val_loss: 0.0272\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0339 - val_loss: 0.0403\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0339 - val_loss: 0.0261\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0322 - val_loss: 0.0335\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0327 - val_loss: 0.0277\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0323 - val_loss: 0.0336\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0314 - val_loss: 0.0258\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0303 - val_loss: 0.0340\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0302 - val_loss: 0.0254\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0299 - val_loss: 0.0358\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0296 - val_loss: 0.0250\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0291 - val_loss: 0.0289\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0253\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0296\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0243\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0275 - val_loss: 0.0286\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0274 - val_loss: 0.0234\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0275\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0231\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0266 - val_loss: 0.0289\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0262 - val_loss: 0.0231\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0257 - val_loss: 0.0262\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0255 - val_loss: 0.0236\n",
      "Epoch 53/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0254\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0254 - val_loss: 0.0277\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0199\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0183\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0182\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0182 - val_loss: 0.0179\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0166\n",
      "---------------- Fold 6 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3380 - val_loss: 0.1055\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1669 - val_loss: 0.0885\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0946 - val_loss: 0.0603\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0908 - val_loss: 0.0605\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1154 - val_loss: 0.0770\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0784 - val_loss: 0.0517\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0782 - val_loss: 0.0677\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0570 - val_loss: 0.0449\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0533 - val_loss: 0.0594\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0530 - val_loss: 0.0404\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0544 - val_loss: 0.0487\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0492 - val_loss: 0.0381\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0458 - val_loss: 0.0470\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0455 - val_loss: 0.0354\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0454 - val_loss: 0.0444\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0442 - val_loss: 0.0319\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0432 - val_loss: 0.0431\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0418 - val_loss: 0.0323\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0402 - val_loss: 0.0388\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0403 - val_loss: 0.0299\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0388 - val_loss: 0.0385\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0384 - val_loss: 0.0304\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0376 - val_loss: 0.0392\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.0296\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0361 - val_loss: 0.0376\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0362 - val_loss: 0.0286\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0357 - val_loss: 0.0361\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0271\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0344 - val_loss: 0.0387\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0345 - val_loss: 0.0277\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0336 - val_loss: 0.0339\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0338 - val_loss: 0.0282\n",
      "Epoch 33/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0323\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0323 - val_loss: 0.0342\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0222 - val_loss: 0.0216\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0197\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0192\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0193\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0193\n",
      "Epoch 43/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0197\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0175 - val_loss: 0.0174\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0168\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 68/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0166\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "---------------- Fold 7 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3577 - val_loss: 0.2107\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1028 - val_loss: 0.0869\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1496 - val_loss: 0.0526\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0778 - val_loss: 0.0971\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1316 - val_loss: 0.1137\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0743 - val_loss: 0.1074\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0589 - val_loss: 0.0479\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0608 - val_loss: 0.0477\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0531 - val_loss: 0.0526\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0508 - val_loss: 0.0389\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0495 - val_loss: 0.0470\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0486 - val_loss: 0.0394\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0468 - val_loss: 0.0461\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0462 - val_loss: 0.0341\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0440 - val_loss: 0.0434\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0432 - val_loss: 0.0326\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0418 - val_loss: 0.0464\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0418 - val_loss: 0.0316\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0416\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0389 - val_loss: 0.0308\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0382 - val_loss: 0.0410\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0382 - val_loss: 0.0298\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0369 - val_loss: 0.0301\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0366 - val_loss: 0.0388\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0360 - val_loss: 0.0284\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0355 - val_loss: 0.0420\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0351 - val_loss: 0.0281\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0338 - val_loss: 0.0337\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0335 - val_loss: 0.0272\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0332 - val_loss: 0.0326\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0327 - val_loss: 0.0268\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0315 - val_loss: 0.0356\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0317 - val_loss: 0.0265\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0312 - val_loss: 0.0319\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0306 - val_loss: 0.0254\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0302 - val_loss: 0.0318\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0300 - val_loss: 0.0258\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0297 - val_loss: 0.0300\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0248\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0304\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0248\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0319\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0240\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0284\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0245\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0283\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0235\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0288\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0261 - val_loss: 0.0233\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0255 - val_loss: 0.0264\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0253 - val_loss: 0.0221\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0248 - val_loss: 0.0265\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0249 - val_loss: 0.0226\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0266\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0246 - val_loss: 0.0223\n",
      "Epoch 57/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0245\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0252\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0201 - val_loss: 0.0198\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0189\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0182\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0181\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 67/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0173\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 85/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0167\n",
      "---------------- Fold 8 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3332 - val_loss: 0.0756\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1703 - val_loss: 0.0666\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2144 - val_loss: 0.2869\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0877 - val_loss: 0.0484\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.0659\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0845 - val_loss: 0.0531\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0614 - val_loss: 0.0528\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0516 - val_loss: 0.0419\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0532 - val_loss: 0.0482\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0495 - val_loss: 0.0408\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0475 - val_loss: 0.0434\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0466 - val_loss: 0.0385\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0453 - val_loss: 0.0467\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0447 - val_loss: 0.0349\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0451 - val_loss: 0.0458\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0428 - val_loss: 0.0338\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0409 - val_loss: 0.0431\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0409 - val_loss: 0.0307\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0397 - val_loss: 0.0438\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0396 - val_loss: 0.0316\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0385 - val_loss: 0.0397\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0385 - val_loss: 0.0298\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0383 - val_loss: 0.0419\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0385 - val_loss: 0.0289\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0364 - val_loss: 0.0419\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0374 - val_loss: 0.0298\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0360 - val_loss: 0.0384\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0362 - val_loss: 0.0281\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0361 - val_loss: 0.0353\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0348 - val_loss: 0.0282\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0344 - val_loss: 0.0394\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0348 - val_loss: 0.0271\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0345 - val_loss: 0.0381\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0336 - val_loss: 0.0263\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0328 - val_loss: 0.0355\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0323 - val_loss: 0.0265\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0381\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0317 - val_loss: 0.0259\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0309 - val_loss: 0.0318\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0304 - val_loss: 0.0254\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0296 - val_loss: 0.0245\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0309\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0286 - val_loss: 0.0245\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0289\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0240\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0288\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0236\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0293\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0235\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0263 - val_loss: 0.0274\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0259 - val_loss: 0.0231\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0256 - val_loss: 0.0267\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0255 - val_loss: 0.0236\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0253 - val_loss: 0.0259\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0222\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0249 - val_loss: 0.0227\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0249 - val_loss: 0.0258\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0249 - val_loss: 0.0224\n",
      "Epoch 61/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0247\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0247 - val_loss: 0.0257\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0196\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0182\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0176\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0176\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 77/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0173\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0171\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "---------------- Fold 9 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3322 - val_loss: 0.1881\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1861 - val_loss: 0.0971\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0743 - val_loss: 0.0612\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0953 - val_loss: 0.0439\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1010 - val_loss: 0.0813\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0683 - val_loss: 0.0585\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0538 - val_loss: 0.0460\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0572 - val_loss: 0.0433\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0991 - val_loss: 0.0508\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0510 - val_loss: 0.0425\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0470 - val_loss: 0.0517\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0459 - val_loss: 0.0353\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0466 - val_loss: 0.0429\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0464 - val_loss: 0.0339\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0427 - val_loss: 0.0439\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0422 - val_loss: 0.0367\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0420 - val_loss: 0.0402\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0396 - val_loss: 0.0322\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0385 - val_loss: 0.0436\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0383 - val_loss: 0.0314\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.0401\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0290\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0368 - val_loss: 0.0389\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0362 - val_loss: 0.0289\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0358 - val_loss: 0.0276\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0344 - val_loss: 0.0383\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0352 - val_loss: 0.0275\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0332 - val_loss: 0.0368\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0337 - val_loss: 0.0269\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0329 - val_loss: 0.0352\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0324 - val_loss: 0.0264\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0342\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0262\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0308 - val_loss: 0.0317\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0304 - val_loss: 0.0252\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0294 - val_loss: 0.0305\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0291 - val_loss: 0.0249\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0288 - val_loss: 0.0295\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0248\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0300\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0251\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0271\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0271 - val_loss: 0.0284\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0197\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0192 - val_loss: 0.0189\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0189\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0189\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0185\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0188 - val_loss: 0.0185\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0188\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0184\n",
      "Epoch 57/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0187\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0185\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 77/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "---------------- Fold 10 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3423 - val_loss: 0.0937\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1026 - val_loss: 0.0520\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0807 - val_loss: 0.0579\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1399 - val_loss: 0.0815\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0822 - val_loss: 0.0565\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0654 - val_loss: 0.0447\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0567 - val_loss: 0.0572\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0855 - val_loss: 0.0526\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0520 - val_loss: 0.0502\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0530 - val_loss: 0.0540\n",
      "Epoch 11/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0537\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0533 - val_loss: 0.0474\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0304 - val_loss: 0.0281\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0253 - val_loss: 0.0261\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0247 - val_loss: 0.0241\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0244 - val_loss: 0.0248\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0248 - val_loss: 0.0239\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0254\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0233\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0241 - val_loss: 0.0236\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0241 - val_loss: 0.0227\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0238 - val_loss: 0.0239\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.0241 - val_loss: 0.0228\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 25/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0239\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0239 - val_loss: 0.0234\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0219 - val_loss: 0.0212\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0204 - val_loss: 0.0202\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0197 - val_loss: 0.0195\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0192\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0188 - val_loss: 0.0189\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0187\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0185\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0183\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0183\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0174 - val_loss: 0.0180\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0180\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0178\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0177\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0177\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0176\n",
      "Epoch 47/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0160 - val_loss: 0.0177\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0175\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0175\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0174\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0174\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0174\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0174\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0173\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0173\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0173\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0173\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0173\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0173\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0172\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0172\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0172\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0171\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0171\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0171\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0171\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0170\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0170\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0170\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0170\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0170\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0170\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0170\n",
      "---------------- Fold 11 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3379 - val_loss: 0.2366\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1154 - val_loss: 0.0522\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0995 - val_loss: 0.1841\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0966 - val_loss: 0.0648\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0717 - val_loss: 0.0939\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1311 - val_loss: 0.0520\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0599 - val_loss: 0.0543\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0540 - val_loss: 0.0414\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0534 - val_loss: 0.0626\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0770 - val_loss: 0.0639\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0526 - val_loss: 0.0534\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0496 - val_loss: 0.0359\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0469 - val_loss: 0.0493\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0452 - val_loss: 0.0344\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0435 - val_loss: 0.0431\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0434 - val_loss: 0.0342\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0425 - val_loss: 0.0436\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0413 - val_loss: 0.0338\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0401 - val_loss: 0.0418\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0399 - val_loss: 0.0298\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0386 - val_loss: 0.0411\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0308\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0419\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0372 - val_loss: 0.0300\n",
      "Epoch 25/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0365\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0363 - val_loss: 0.0384\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0233 - val_loss: 0.0231\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0211 - val_loss: 0.0218\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0205\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0200\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0204\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0207 - val_loss: 0.0200\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0207 - val_loss: 0.0201\n",
      "Epoch 35/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0189\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0180\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0178\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0170\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0163 - val_loss: 0.0170\n",
      "Epoch 56/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0166\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0166\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0166\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0166\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0166\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0165\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0165\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0165\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0165\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0165\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0165\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0165\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0165\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "---------------- Fold 12 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3463 - val_loss: 0.1964\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1355 - val_loss: 0.1180\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1607 - val_loss: 0.0624\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0711 - val_loss: 0.0563\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0728 - val_loss: 0.0654\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0652 - val_loss: 0.0543\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0594 - val_loss: 0.0761\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0564 - val_loss: 0.0441\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0547 - val_loss: 0.0466\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0598 - val_loss: 0.0415\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0511 - val_loss: 0.0472\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0504 - val_loss: 0.0367\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0472 - val_loss: 0.0479\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0450 - val_loss: 0.0372\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0433 - val_loss: 0.0486\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0444 - val_loss: 0.0346\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0420 - val_loss: 0.0428\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0407 - val_loss: 0.0313\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0403 - val_loss: 0.0433\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0421 - val_loss: 0.0318\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0435\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0396 - val_loss: 0.0316\n",
      "Epoch 23/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0381\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0396\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0240 - val_loss: 0.0239\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0215 - val_loss: 0.0224\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0215 - val_loss: 0.0211\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0213 - val_loss: 0.0209\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0212 - val_loss: 0.0217\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0214\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0188\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0183\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0176 - val_loss: 0.0181\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0179\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0179\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0178\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0177\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0176\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0176\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 53/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0174\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0173\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0173\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0173\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0171\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.0171\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0171\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0171\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0171\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0171\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0171\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0170\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0171\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0170\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0170\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0170\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0170\n",
      "---------------- Fold 13 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.3493 - val_loss: 0.1400\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1330 - val_loss: 0.2585\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1521 - val_loss: 0.1628\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1017 - val_loss: 0.0672\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0617 - val_loss: 0.0546\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0640 - val_loss: 0.0572\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1444 - val_loss: 0.0536\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0514 - val_loss: 0.0408\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0495 - val_loss: 0.0485\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0503 - val_loss: 0.0373\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0469 - val_loss: 0.0501\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0460 - val_loss: 0.0415\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0454 - val_loss: 0.0459\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0455 - val_loss: 0.0359\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0431 - val_loss: 0.0435\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0419 - val_loss: 0.0334\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0426 - val_loss: 0.0446\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0409 - val_loss: 0.0324\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0403 - val_loss: 0.0412\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0397 - val_loss: 0.0308\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0387 - val_loss: 0.0482\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0381 - val_loss: 0.0302\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0374 - val_loss: 0.0417\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0371 - val_loss: 0.0304\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0373\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0360 - val_loss: 0.0282\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0355 - val_loss: 0.0399\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0354 - val_loss: 0.0279\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0344 - val_loss: 0.0377\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0281\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0337 - val_loss: 0.0351\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0327 - val_loss: 0.0271\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0321 - val_loss: 0.0348\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0322 - val_loss: 0.0260\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0311 - val_loss: 0.0334\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0312 - val_loss: 0.0261\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0300 - val_loss: 0.0318\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0299 - val_loss: 0.0254\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0292 - val_loss: 0.0316\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0292 - val_loss: 0.0257\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0291\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0288 - val_loss: 0.0244\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0290\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0241\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0273 - val_loss: 0.0287\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0272 - val_loss: 0.0237\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0286\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0262 - val_loss: 0.0230\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0262 - val_loss: 0.0285\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0255 - val_loss: 0.0227\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0255 - val_loss: 0.0270\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0256 - val_loss: 0.0227\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0268\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0253 - val_loss: 0.0228\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0263\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0204 - val_loss: 0.0200\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0192\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0185\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0181\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 67/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 85/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "---------------- Fold 14 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3436 - val_loss: 0.0896\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1100 - val_loss: 0.0578\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1569 - val_loss: 0.0931\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1066 - val_loss: 0.0582\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0893 - val_loss: 0.0464\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0900 - val_loss: 0.0499\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0627 - val_loss: 0.0476\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0539 - val_loss: 0.0461\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0636 - val_loss: 0.0483\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0485 - val_loss: 0.0377\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0490 - val_loss: 0.0542\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0507 - val_loss: 0.0387\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0450 - val_loss: 0.0434\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0459 - val_loss: 0.0379\n",
      "Epoch 15/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0420\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0420 - val_loss: 0.0441\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0261\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0235 - val_loss: 0.0241\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0230 - val_loss: 0.0222\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0227 - val_loss: 0.0228\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0229 - val_loss: 0.0221\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0223\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0221\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0223 - val_loss: 0.0217\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0223 - val_loss: 0.0216\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0222 - val_loss: 0.0225\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0222 - val_loss: 0.0215\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0223 - val_loss: 0.0225\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0223 - val_loss: 0.0216\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0221 - val_loss: 0.0213\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0222 - val_loss: 0.0213\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0217 - val_loss: 0.0211\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0216 - val_loss: 0.0211\n",
      "Epoch 41/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0217\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0197\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0185\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0183\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0174 - val_loss: 0.0181\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0180\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0178\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0177\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0175\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0174\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0174\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0175\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0175\n",
      "Epoch 59/85\n",
      "127/135 [===========================>..] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0174\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0173\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0173\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0173\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0173\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0172\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0172\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0172\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.0172\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0172\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0172\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0171\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0171\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0171\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0171\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0171\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0171\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0171\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "---------------- Fold 15 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3192 - val_loss: 0.0737\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1354 - val_loss: 0.0522\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1711 - val_loss: 0.0757\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1165 - val_loss: 0.1163\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1094 - val_loss: 0.0604\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0583 - val_loss: 0.0493\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0557 - val_loss: 0.1051\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0771 - val_loss: 0.0407\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0512 - val_loss: 0.0507\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0513 - val_loss: 0.0376\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0501 - val_loss: 0.0578\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0474 - val_loss: 0.0381\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0478 - val_loss: 0.0502\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0468 - val_loss: 0.0360\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0451 - val_loss: 0.0454\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.0370\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0426 - val_loss: 0.0435\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0420 - val_loss: 0.0321\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0409 - val_loss: 0.0427\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0407 - val_loss: 0.0304\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0396 - val_loss: 0.0470\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0388 - val_loss: 0.0304\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0417\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0386 - val_loss: 0.0295\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0404\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0368 - val_loss: 0.0286\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0371\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0358 - val_loss: 0.0283\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0350 - val_loss: 0.0377\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0344 - val_loss: 0.0279\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0335 - val_loss: 0.0361\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0335 - val_loss: 0.0262\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0326 - val_loss: 0.0351\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0320 - val_loss: 0.0266\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0315 - val_loss: 0.0345\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0307 - val_loss: 0.0261\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0334\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0302 - val_loss: 0.0256\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0298 - val_loss: 0.0292\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.0248\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0290 - val_loss: 0.0313\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0295 - val_loss: 0.0250\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0286\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0252\n",
      "Epoch 45/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0278\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0277\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0189\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0185\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0184\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0185\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0185\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0182\n",
      "Epoch 59/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0185\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0186\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0174\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 79/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "---------------- Fold 16 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3509 - val_loss: 0.1669\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1115 - val_loss: 0.0727\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1157 - val_loss: 0.0946\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0797 - val_loss: 0.1010\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0605 - val_loss: 0.0468\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0635 - val_loss: 0.0445\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0540 - val_loss: 0.0540\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0643 - val_loss: 0.0425\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0544 - val_loss: 0.0515\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0529 - val_loss: 0.0414\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0501 - val_loss: 0.0484\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0483 - val_loss: 0.0375\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0469 - val_loss: 0.0494\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0376\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0453 - val_loss: 0.0448\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0431 - val_loss: 0.0341\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0415 - val_loss: 0.0439\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0415 - val_loss: 0.0314\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0403 - val_loss: 0.0418\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0394 - val_loss: 0.0308\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0384 - val_loss: 0.0404\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0378 - val_loss: 0.0307\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0372 - val_loss: 0.0384\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0362 - val_loss: 0.0289\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0360 - val_loss: 0.0378\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0356 - val_loss: 0.0275\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0344 - val_loss: 0.0374\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0349 - val_loss: 0.0274\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0336 - val_loss: 0.0379\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0335 - val_loss: 0.0275\n",
      "Epoch 31/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0326\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0325 - val_loss: 0.0356\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0223 - val_loss: 0.0223\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0203 - val_loss: 0.0212\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 41/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0199\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0170\n",
      "Epoch 62/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0167\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "---------------- Fold 17 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3484 - val_loss: 0.2054\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1222 - val_loss: 0.1439\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1457 - val_loss: 0.1220\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0672 - val_loss: 0.0439\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0567 - val_loss: 0.0685\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0583 - val_loss: 0.0434\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0663 - val_loss: 0.0637\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0679 - val_loss: 0.0501\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0546 - val_loss: 0.0577\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0604 - val_loss: 0.0823\n",
      "Epoch 11/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0859\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0845 - val_loss: 0.0499\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0317 - val_loss: 0.0297\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0264\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0252 - val_loss: 0.0247\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0243\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0245 - val_loss: 0.0237\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0245 - val_loss: 0.0240\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0237\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0243 - val_loss: 0.0246\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0243 - val_loss: 0.0234\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0242 - val_loss: 0.0246\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0245 - val_loss: 0.0236\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0242 - val_loss: 0.0236\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0238 - val_loss: 0.0234\n",
      "Epoch 25/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0237\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0237 - val_loss: 0.0237\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0218 - val_loss: 0.0211\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0202\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0192\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0187\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0185\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0182\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0181\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0180\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0181\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0178\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0177\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0178\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0176\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0177\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0176\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0179\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0175\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0175\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0174\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0174\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0174\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0144 - val_loss: 0.0173\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0173\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0143 - val_loss: 0.0173\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0173\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0173\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0173\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0172\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0172\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0172\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0172\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0138 - val_loss: 0.0172\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0172\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0172\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0171\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0171\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0171\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0171\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0171\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0133 - val_loss: 0.0171\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0171\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0171\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0171\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0171\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0170\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0170\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0170\n",
      "---------------- Fold 18 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3246 - val_loss: 0.0549\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1560 - val_loss: 0.0548\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0833 - val_loss: 0.1676\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0790 - val_loss: 0.0702\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1318 - val_loss: 0.1501\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0742 - val_loss: 0.0427\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0554 - val_loss: 0.0514\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0736 - val_loss: 0.0914\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0543 - val_loss: 0.0505\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0521 - val_loss: 0.0374\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0560 - val_loss: 0.0445\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0482 - val_loss: 0.0409\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0466 - val_loss: 0.0549\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0474 - val_loss: 0.0450\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0459\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0459 - val_loss: 0.0492\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0256\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0233 - val_loss: 0.0229\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0230 - val_loss: 0.0229\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0230 - val_loss: 0.0222\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0229 - val_loss: 0.0232\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0231 - val_loss: 0.0224\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0229 - val_loss: 0.0225\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0227 - val_loss: 0.0223\n",
      "Epoch 25/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0226\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0192\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0190\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0183\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0185\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.0174 - val_loss: 0.0181\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0181\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0181\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0178\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0177\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0179\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0176\n",
      "Epoch 45/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0178\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0175\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0175\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0174\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0174\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0174\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0174\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0173\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0173\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0150 - val_loss: 0.0173\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0173\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0173\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0173\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0173\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0172\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0172\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0172\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0172\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0172\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0172\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0172\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0144 - val_loss: 0.0171\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0171\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0171\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0171\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0143 - val_loss: 0.0171\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0171\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0171\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0170\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0170\n",
      "---------------- Fold 19 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3497 - val_loss: 0.1694\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1453 - val_loss: 0.1033\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1152 - val_loss: 0.0728\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0956 - val_loss: 0.0491\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1019 - val_loss: 0.0592\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0794 - val_loss: 0.0424\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0596 - val_loss: 0.0493\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0551 - val_loss: 0.0508\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0745 - val_loss: 0.0474\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0479 - val_loss: 0.0406\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0548 - val_loss: 0.0541\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0465 - val_loss: 0.0385\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.0429\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0431 - val_loss: 0.0339\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0424 - val_loss: 0.0453\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0408 - val_loss: 0.0336\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0405 - val_loss: 0.0394\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0398 - val_loss: 0.0324\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0397 - val_loss: 0.0419\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0392 - val_loss: 0.0316\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0386 - val_loss: 0.0405\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0387 - val_loss: 0.0307\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.0421\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0374 - val_loss: 0.0299\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0368 - val_loss: 0.0383\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0366 - val_loss: 0.0297\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0355 - val_loss: 0.0378\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0358 - val_loss: 0.0276\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0422\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0272\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0342 - val_loss: 0.0350\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0338 - val_loss: 0.0267\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0346\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0330 - val_loss: 0.0258\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0318 - val_loss: 0.0333\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0315 - val_loss: 0.0258\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0308 - val_loss: 0.0326\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0303 - val_loss: 0.0257\n",
      "Epoch 39/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0295\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0294 - val_loss: 0.0307\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0214 - val_loss: 0.0216\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0203\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0197\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0195 - val_loss: 0.0192\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0194 - val_loss: 0.0190\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0192\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0194\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0190\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0192\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0189\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0190\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 55/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0190\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0179\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0177\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 79/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "---------------- Fold 20 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3409 - val_loss: 0.1351\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1374 - val_loss: 0.0587\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1488 - val_loss: 0.1274\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2680 - val_loss: 0.3358\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1033 - val_loss: 0.0777\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0539 - val_loss: 0.0485\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0615 - val_loss: 0.0475\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0509 - val_loss: 0.0414\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0493 - val_loss: 0.0483\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0515 - val_loss: 0.0503\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0459 - val_loss: 0.0468\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0472 - val_loss: 0.0354\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0445 - val_loss: 0.0456\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0436 - val_loss: 0.0367\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0419 - val_loss: 0.0454\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0415 - val_loss: 0.0332\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0406 - val_loss: 0.0418\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0395 - val_loss: 0.0327\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0397 - val_loss: 0.0441\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0390 - val_loss: 0.0304\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0382 - val_loss: 0.0388\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0383 - val_loss: 0.0320\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0382 - val_loss: 0.0396\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0374 - val_loss: 0.0292\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0435\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0382 - val_loss: 0.0297\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0361 - val_loss: 0.0417\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0363 - val_loss: 0.0288\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0353 - val_loss: 0.0384\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0353 - val_loss: 0.0286\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0343 - val_loss: 0.0360\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0347 - val_loss: 0.0275\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0332 - val_loss: 0.0367\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0335 - val_loss: 0.0282\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0326 - val_loss: 0.0335\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0319 - val_loss: 0.0282\n",
      "Epoch 37/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0313\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0313 - val_loss: 0.0316\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0217 - val_loss: 0.0220\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0190\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0191\n",
      "Epoch 49/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0194\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0168\n",
      "Epoch 71/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0168\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0168\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0158 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "---------------- Fold 21 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3425 - val_loss: 0.1197\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1606 - val_loss: 0.0630\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0848 - val_loss: 0.2015\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1445 - val_loss: 0.0537\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1159 - val_loss: 0.0674\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0538 - val_loss: 0.0459\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0586 - val_loss: 0.0617\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0675 - val_loss: 0.0480\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0511 - val_loss: 0.0547\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0501 - val_loss: 0.0390\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0494 - val_loss: 0.0482\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0481 - val_loss: 0.0349\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0459 - val_loss: 0.0454\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0449 - val_loss: 0.0335\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0434 - val_loss: 0.0473\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0417 - val_loss: 0.0336\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0412 - val_loss: 0.0454\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0401 - val_loss: 0.0331\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0395 - val_loss: 0.0424\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0304\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0387 - val_loss: 0.0405\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0382 - val_loss: 0.0325\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0376 - val_loss: 0.0466\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0379 - val_loss: 0.0296\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0366 - val_loss: 0.0379\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0360 - val_loss: 0.0288\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0352 - val_loss: 0.0360\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0284\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0340 - val_loss: 0.0352\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0274\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0334 - val_loss: 0.0333\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0333 - val_loss: 0.0265\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0323 - val_loss: 0.0343\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0322 - val_loss: 0.0258\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0313 - val_loss: 0.0323\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0313 - val_loss: 0.0256\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0305 - val_loss: 0.0346\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0303 - val_loss: 0.0256\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0291 - val_loss: 0.0329\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0298 - val_loss: 0.0256\n",
      "Epoch 41/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0284\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0304\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0200\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0194 - val_loss: 0.0189\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0187\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0189\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0185\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0185\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0185\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0191\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0186 - val_loss: 0.0183\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 81/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0165\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0165\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "---------------- Fold 22 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3276 - val_loss: 0.1278\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1837 - val_loss: 0.2402\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1044 - val_loss: 0.0638\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0759 - val_loss: 0.0651\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1534 - val_loss: 0.0606\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0537 - val_loss: 0.0492\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0537 - val_loss: 0.0514\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0517 - val_loss: 0.0633\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0551 - val_loss: 0.0518\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0523 - val_loss: 0.0379\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0501 - val_loss: 0.0472\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0495 - val_loss: 0.0360\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0451 - val_loss: 0.0552\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0456 - val_loss: 0.0355\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0427 - val_loss: 0.0462\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0442 - val_loss: 0.0333\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0417 - val_loss: 0.0422\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0398 - val_loss: 0.0336\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0396 - val_loss: 0.0401\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0389 - val_loss: 0.0312\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0378 - val_loss: 0.0406\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0385 - val_loss: 0.0293\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0366 - val_loss: 0.0396\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0370 - val_loss: 0.0291\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0362 - val_loss: 0.0389\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 2s 16ms/step - loss: 0.0363 - val_loss: 0.0285\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0342 - val_loss: 0.0354\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0348 - val_loss: 0.0289\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0341 - val_loss: 0.0366\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0341 - val_loss: 0.0274\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0332 - val_loss: 0.0352\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0335 - val_loss: 0.0267\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0327 - val_loss: 0.0370\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0324 - val_loss: 0.0265\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0314 - val_loss: 0.0323\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0308 - val_loss: 0.0253\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0300 - val_loss: 0.0320\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0297 - val_loss: 0.0253\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0297 - val_loss: 0.0310\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0294 - val_loss: 0.0246\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0291 - val_loss: 0.0285\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0284 - val_loss: 0.0240\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0280 - val_loss: 0.0305\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0277 - val_loss: 0.0242\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0270 - val_loss: 0.0273\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0269 - val_loss: 0.0235\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0267 - val_loss: 0.0271\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0262 - val_loss: 0.0230\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0261 - val_loss: 0.0280\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0259 - val_loss: 0.0232\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0252 - val_loss: 0.0259\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0254 - val_loss: 0.0230\n",
      "Epoch 53/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0254\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0254 - val_loss: 0.0250\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.0193\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 69/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0176\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0173\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0170\n",
      "---------------- Fold 23 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3360 - val_loss: 0.0914\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1275 - val_loss: 0.0454\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1389 - val_loss: 0.0914\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1053 - val_loss: 0.2398\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0900 - val_loss: 0.1616\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0735 - val_loss: 0.0471\n",
      "Epoch 7/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0575\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0572 - val_loss: 0.0524\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0330 - val_loss: 0.0306\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0269\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0259 - val_loss: 0.0252\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0259 - val_loss: 0.0255\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0327\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0260\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0258 - val_loss: 0.0253\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0258\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0235 - val_loss: 0.0228\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0194 - val_loss: 0.0198\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0197\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0193\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0190\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0189\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0189\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0194\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0188\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0173 - val_loss: 0.0187\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0189\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0186\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0185\n",
      "Epoch 39/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0186\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0184\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0183\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0183\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0149 - val_loss: 0.0182\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0182\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0148 - val_loss: 0.0182\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.0182\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.0181\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0145 - val_loss: 0.0181\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0144 - val_loss: 0.0181\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0181\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0180\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.0180\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0141 - val_loss: 0.0180\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0180\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0180\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0180\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0180\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0179\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0179\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0137 - val_loss: 0.0179\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0179\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0179\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0134 - val_loss: 0.0179\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0178\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0178\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0178\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0178\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0178\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0178\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0178\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0178\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0178\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0128 - val_loss: 0.0178\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0177\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0178\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0177\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0177\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0177\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0177\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0177\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0177\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0124 - val_loss: 0.0177\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0177\n",
      "---------------- Fold 24 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3542 - val_loss: 0.1707\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1417 - val_loss: 0.1918\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1032 - val_loss: 0.0829\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0618 - val_loss: 0.0506\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0872 - val_loss: 0.0621\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1161 - val_loss: 0.0476\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0925 - val_loss: 0.0492\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0501 - val_loss: 0.0415\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0571 - val_loss: 0.0557\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0491 - val_loss: 0.0395\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0469 - val_loss: 0.0468\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0470 - val_loss: 0.0384\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0452 - val_loss: 0.0450\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0443 - val_loss: 0.0335\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0422 - val_loss: 0.0442\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0414 - val_loss: 0.0333\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0403 - val_loss: 0.0415\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0402 - val_loss: 0.0307\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0384 - val_loss: 0.0409\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0391 - val_loss: 0.0308\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0379 - val_loss: 0.0411\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0287\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0377 - val_loss: 0.0374\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0364 - val_loss: 0.0295\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0354 - val_loss: 0.0357\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0361 - val_loss: 0.0278\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0353 - val_loss: 0.0370\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0346 - val_loss: 0.0268\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0349\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0273\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0327 - val_loss: 0.0345\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0327 - val_loss: 0.0270\n",
      "Epoch 33/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0318\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0318 - val_loss: 0.0334\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0192\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0201\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0191\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0190\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0192\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0189\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0190\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0192 - val_loss: 0.0187\n",
      "Epoch 53/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0189\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0165\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 81/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0164\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0164\n",
      "---------------- Fold 25 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3532 - val_loss: 0.1683\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1331 - val_loss: 0.0859\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0811 - val_loss: 0.0582\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1024 - val_loss: 0.1186\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1686 - val_loss: 0.0995\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0622 - val_loss: 0.0489\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0564 - val_loss: 0.0678\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0544 - val_loss: 0.0477\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0662 - val_loss: 0.0548\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0503 - val_loss: 0.0385\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0555 - val_loss: 0.0468\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0483 - val_loss: 0.0380\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0468 - val_loss: 0.0601\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0457 - val_loss: 0.0366\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0456 - val_loss: 0.0480\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0432 - val_loss: 0.0344\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0418 - val_loss: 0.0431\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0418 - val_loss: 0.0320\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0404 - val_loss: 0.0414\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0402 - val_loss: 0.0305\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0389 - val_loss: 0.0396\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0384 - val_loss: 0.0296\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0377 - val_loss: 0.0403\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0290\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0364 - val_loss: 0.0394\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0372 - val_loss: 0.0296\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0360 - val_loss: 0.0378\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0355 - val_loss: 0.0285\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0350 - val_loss: 0.0406\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0352 - val_loss: 0.0271\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0342 - val_loss: 0.0365\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0349 - val_loss: 0.0269\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0361\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0328 - val_loss: 0.0267\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0317 - val_loss: 0.0334\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0261\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0303 - val_loss: 0.0310\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0304 - val_loss: 0.0257\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0297 - val_loss: 0.0315\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0292 - val_loss: 0.0249\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0307\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0248\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0286\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0238\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0278 - val_loss: 0.0292\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0271 - val_loss: 0.0242\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0285\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0270 - val_loss: 0.0237\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0266\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0264 - val_loss: 0.0237\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0257 - val_loss: 0.0257\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0259 - val_loss: 0.0229\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0252 - val_loss: 0.0262\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0252 - val_loss: 0.0228\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0258\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0223\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0258\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0220\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0253\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0224\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0249 - val_loss: 0.0262\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0247 - val_loss: 0.0220\n",
      "Epoch 63/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0250\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0248\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0202 - val_loss: 0.0198\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0188 - val_loss: 0.0191\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 77/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "---------------- Fold 26 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3460 - val_loss: 0.1031\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.2192 - val_loss: 0.1673\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1182 - val_loss: 0.0615\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.0453\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0988 - val_loss: 0.0653\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0656 - val_loss: 0.1216\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0708 - val_loss: 0.0552\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0548 - val_loss: 0.0444\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0780 - val_loss: 0.0675\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0502 - val_loss: 0.0388\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0488 - val_loss: 0.0468\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0492 - val_loss: 0.0411\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0469 - val_loss: 0.0489\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0443 - val_loss: 0.0344\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0425 - val_loss: 0.0425\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0422 - val_loss: 0.0323\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0402 - val_loss: 0.0422\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0412 - val_loss: 0.0321\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0394 - val_loss: 0.0429\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0403 - val_loss: 0.0318\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0387 - val_loss: 0.0417\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0391 - val_loss: 0.0308\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0380 - val_loss: 0.0383\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0387 - val_loss: 0.0311\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0379 - val_loss: 0.0391\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0373 - val_loss: 0.0287\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0396\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0361 - val_loss: 0.0271\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0351 - val_loss: 0.0400\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0272\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0345 - val_loss: 0.0367\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0337 - val_loss: 0.0270\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0326 - val_loss: 0.0382\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0331 - val_loss: 0.0256\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0316 - val_loss: 0.0316\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0312 - val_loss: 0.0257\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0308 - val_loss: 0.0330\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0299 - val_loss: 0.0258\n",
      "Epoch 39/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0295\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0295 - val_loss: 0.0326\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0217 - val_loss: 0.0214\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0191\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0189\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0187\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0188\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0194\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.0188\n",
      "Epoch 51/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0191\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0189\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0168\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "---------------- Fold 27 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3233 - val_loss: 0.0888\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1362 - val_loss: 0.1013\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1742 - val_loss: 0.1168\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0723 - val_loss: 0.0440\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0623 - val_loss: 0.0560\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1006 - val_loss: 0.0991\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1082 - val_loss: 0.0733\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0539 - val_loss: 0.0414\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0503 - val_loss: 0.0567\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.0398\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0483 - val_loss: 0.0459\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0492 - val_loss: 0.0404\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0470 - val_loss: 0.0685\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0468 - val_loss: 0.0336\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0434 - val_loss: 0.0480\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0435 - val_loss: 0.0350\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0417 - val_loss: 0.0424\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0411 - val_loss: 0.0324\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0399 - val_loss: 0.0438\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0393 - val_loss: 0.0318\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0384 - val_loss: 0.0406\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0377 - val_loss: 0.0298\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0365 - val_loss: 0.0283\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0364 - val_loss: 0.0381\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0276\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0343 - val_loss: 0.0358\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0279\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0337 - val_loss: 0.0346\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0333 - val_loss: 0.0269\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0331 - val_loss: 0.0332\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0322 - val_loss: 0.0258\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0316 - val_loss: 0.0344\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0251\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0311 - val_loss: 0.0336\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0303 - val_loss: 0.0257\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0300 - val_loss: 0.0319\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0299 - val_loss: 0.0258\n",
      "Epoch 39/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0296\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0295 - val_loss: 0.0294\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0192\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0187\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0193 - val_loss: 0.0187\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 49/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0178\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0167\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0160 - val_loss: 0.0166\n",
      "---------------- Fold 28 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3401 - val_loss: 0.0946\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1636 - val_loss: 0.0929\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1411 - val_loss: 0.0731\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0955 - val_loss: 0.0492\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0647 - val_loss: 0.0525\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0595 - val_loss: 0.0565\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1513 - val_loss: 0.0547\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0509 - val_loss: 0.0398\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0546 - val_loss: 0.0518\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0504 - val_loss: 0.0410\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0492 - val_loss: 0.0491\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0469 - val_loss: 0.0391\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0460 - val_loss: 0.0484\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0445 - val_loss: 0.0331\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0421 - val_loss: 0.0429\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0413 - val_loss: 0.0352\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0397 - val_loss: 0.0406\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0401 - val_loss: 0.0316\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0392 - val_loss: 0.0397\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0385 - val_loss: 0.0305\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0389 - val_loss: 0.0405\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0384 - val_loss: 0.0301\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0375 - val_loss: 0.0388\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0381 - val_loss: 0.0288\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0364 - val_loss: 0.0374\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0359 - val_loss: 0.0291\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0354 - val_loss: 0.0391\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0353 - val_loss: 0.0278\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0347 - val_loss: 0.0357\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0346 - val_loss: 0.0278\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0340 - val_loss: 0.0349\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0336 - val_loss: 0.0264\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0330 - val_loss: 0.0348\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0324 - val_loss: 0.0262\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0317 - val_loss: 0.0337\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0310 - val_loss: 0.0249\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0303 - val_loss: 0.0310\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0299 - val_loss: 0.0254\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0295 - val_loss: 0.0310\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0295 - val_loss: 0.0255\n",
      "Epoch 41/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0295\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0294 - val_loss: 0.0308\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0196 - val_loss: 0.0201\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0189\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 53/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0189\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0189 - val_loss: 0.0187\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0182 - val_loss: 0.0180\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0178 - val_loss: 0.0177\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0167 - val_loss: 0.0169\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "---------------- Fold 29 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3365 - val_loss: 0.1308\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1833 - val_loss: 0.1596\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0997 - val_loss: 0.0514\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1777 - val_loss: 0.0624\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0588 - val_loss: 0.0656\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0549 - val_loss: 0.0401\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0530 - val_loss: 0.0479\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0812 - val_loss: 0.0517\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0529 - val_loss: 0.0689\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0559 - val_loss: 0.0389\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0499 - val_loss: 0.0482\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0476 - val_loss: 0.0406\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0451 - val_loss: 0.0434\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0453 - val_loss: 0.0348\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0440 - val_loss: 0.0443\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0429 - val_loss: 0.0322\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0414 - val_loss: 0.0410\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0404 - val_loss: 0.0318\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0404\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0400 - val_loss: 0.0301\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0379 - val_loss: 0.0403\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0382 - val_loss: 0.0295\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0374 - val_loss: 0.0380\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0367 - val_loss: 0.0286\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0363 - val_loss: 0.0400\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0365 - val_loss: 0.0284\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0356 - val_loss: 0.0381\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0345 - val_loss: 0.0289\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0347 - val_loss: 0.0353\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0345 - val_loss: 0.0274\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0329 - val_loss: 0.0358\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0332 - val_loss: 0.0272\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0325 - val_loss: 0.0331\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0317 - val_loss: 0.0259\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0308 - val_loss: 0.0324\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0308 - val_loss: 0.0252\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0297 - val_loss: 0.0250\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0290 - val_loss: 0.0304\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0289 - val_loss: 0.0245\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0307\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0249\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0275 - val_loss: 0.0296\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0239\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0275\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0236\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0261 - val_loss: 0.0269\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0262 - val_loss: 0.0231\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0259 - val_loss: 0.0260\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0254 - val_loss: 0.0229\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0253 - val_loss: 0.0259\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0230\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0248\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0250 - val_loss: 0.0224\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0250\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0222\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0250\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0242 - val_loss: 0.0223\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0249\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0219\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0241 - val_loss: 0.0251\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0225\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0241 - val_loss: 0.0245\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0250\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0241 - val_loss: 0.0221\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0238 - val_loss: 0.0239\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0240 - val_loss: 0.0220\n",
      "Epoch 69/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0238\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0238 - val_loss: 0.0250\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0187 - val_loss: 0.0188\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0180\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0180\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 79/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0180\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "---------------- Fold 30 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3454 - val_loss: 0.2733\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1556 - val_loss: 0.0487\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1031 - val_loss: 0.0572\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0692 - val_loss: 0.0722\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0851 - val_loss: 0.0531\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0598 - val_loss: 0.0433\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0754 - val_loss: 0.0739\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0604 - val_loss: 0.0434\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0588 - val_loss: 0.0788\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0783 - val_loss: 0.0499\n",
      "Epoch 11/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0541\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0538 - val_loss: 0.0490\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0296 - val_loss: 0.0279\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0261\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0249 - val_loss: 0.0242\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0244 - val_loss: 0.0257\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0245 - val_loss: 0.0236\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0246 - val_loss: 0.0243\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0247 - val_loss: 0.0236\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0240 - val_loss: 0.0240\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0240 - val_loss: 0.0230\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0241 - val_loss: 0.0248\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0243 - val_loss: 0.0239\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0241 - val_loss: 0.0249\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 25/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0241\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0222 - val_loss: 0.0217\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0191 - val_loss: 0.0195\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0193\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0188\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0191\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0187\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0187\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0184\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0184\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0169 - val_loss: 0.0183\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0183\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0163 - val_loss: 0.0181\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0161 - val_loss: 0.0184\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0182\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0183\n",
      "Epoch 47/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0182\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0180\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0180\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0144 - val_loss: 0.0179\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0179\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0141 - val_loss: 0.0178\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0178\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0140 - val_loss: 0.0178\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0178\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0177\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0177\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0137 - val_loss: 0.0177\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0177\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0135 - val_loss: 0.0177\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0177\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0176\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0177\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0176\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0131 - val_loss: 0.0176\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0176\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0176\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0176\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0176\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0176\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0176\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0176\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0176\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0176\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0175\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0175\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0176\n",
      "---------------- Fold 31 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.3456 - val_loss: 0.1606\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1567 - val_loss: 0.1726\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1498 - val_loss: 0.0462\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1091 - val_loss: 0.0564\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1442 - val_loss: 0.0733\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0586 - val_loss: 0.0476\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0817 - val_loss: 0.1809\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0727 - val_loss: 0.0402\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0477 - val_loss: 0.0496\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0527 - val_loss: 0.0378\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0472 - val_loss: 0.0467\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0477 - val_loss: 0.0376\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0450 - val_loss: 0.0420\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0441 - val_loss: 0.0346\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0430 - val_loss: 0.0440\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0423 - val_loss: 0.0337\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0412 - val_loss: 0.0448\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0407 - val_loss: 0.0317\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.0407\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0384 - val_loss: 0.0301\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.0411\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0383 - val_loss: 0.0291\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0371 - val_loss: 0.0384\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0364 - val_loss: 0.0294\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0359 - val_loss: 0.0374\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0357 - val_loss: 0.0291\n",
      "Epoch 27/85\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.0350\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0350 - val_loss: 0.0365\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0232 - val_loss: 0.0230\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0207\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0205 - val_loss: 0.0200\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 37/85\n",
      "128/135 [===========================>..] - ETA: 0s - loss: 0.0204\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0191 - val_loss: 0.0190\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0180\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0177\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0176\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0175\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0175\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0167 - val_loss: 0.0174\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.0174\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0173\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0173\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0173\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0172\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 58/85\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0171\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0156 - val_loss: 0.0171\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0170\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0170\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0170\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0170\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0169\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0150 - val_loss: 0.0169\n",
      "---------------- Fold 32 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3460 - val_loss: 0.1189\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1122 - val_loss: 0.0677\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1380 - val_loss: 0.0891\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1037 - val_loss: 0.0572\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0837 - val_loss: 0.0705\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0637 - val_loss: 0.0458\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0543 - val_loss: 0.0529\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1472 - val_loss: 0.0792\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0552 - val_loss: 0.0517\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0482 - val_loss: 0.0421\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0470 - val_loss: 0.0530\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0465 - val_loss: 0.0382\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.0433\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0438 - val_loss: 0.0353\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0422 - val_loss: 0.0446\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0432 - val_loss: 0.0321\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0415 - val_loss: 0.0441\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0402 - val_loss: 0.0314\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0389 - val_loss: 0.0425\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0390 - val_loss: 0.0316\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0382 - val_loss: 0.0413\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0380 - val_loss: 0.0323\n",
      "Epoch 23/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0377\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.0375\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0214 - val_loss: 0.0228\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0211 - val_loss: 0.0206\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0204\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0205\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0209 - val_loss: 0.0203\n",
      "Epoch 33/85\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.0207\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0207 - val_loss: 0.0211\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0178\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0171\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0171\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0164 - val_loss: 0.0171\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0171\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0153 - val_loss: 0.0168\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0166\n",
      "---------------- Fold 33 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3310 - val_loss: 0.0547\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1453 - val_loss: 0.1306\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1080 - val_loss: 0.1097\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1079 - val_loss: 0.0463\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1250 - val_loss: 0.0533\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0646 - val_loss: 0.0433\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0819 - val_loss: 0.0917\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0645 - val_loss: 0.1102\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0560 - val_loss: 0.0473\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0668 - val_loss: 0.0402\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0476 - val_loss: 0.0504\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0484 - val_loss: 0.0376\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0465 - val_loss: 0.0452\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0455 - val_loss: 0.0361\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0437 - val_loss: 0.0473\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0426 - val_loss: 0.0319\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0408 - val_loss: 0.0450\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0406 - val_loss: 0.0316\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0406 - val_loss: 0.0400\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0392 - val_loss: 0.0297\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0386 - val_loss: 0.0410\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0297\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0371 - val_loss: 0.0380\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0365 - val_loss: 0.0291\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0364 - val_loss: 0.0360\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0358 - val_loss: 0.0295\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0354 - val_loss: 0.0370\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0350 - val_loss: 0.0281\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0345 - val_loss: 0.0357\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0340 - val_loss: 0.0272\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0329 - val_loss: 0.0357\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0331 - val_loss: 0.0270\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0321 - val_loss: 0.0332\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0317 - val_loss: 0.0262\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0311 - val_loss: 0.0349\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0310 - val_loss: 0.0256\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0296 - val_loss: 0.0311\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0295 - val_loss: 0.0254\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0295 - val_loss: 0.0243\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0299\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0243\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0278\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0235\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0269 - val_loss: 0.0232\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0277\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.0236\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0260 - val_loss: 0.0267\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0257 - val_loss: 0.0229\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0253 - val_loss: 0.0281\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0258 - val_loss: 0.0230\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0252\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0250 - val_loss: 0.0221\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0247 - val_loss: 0.0256\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0225\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0244 - val_loss: 0.0250\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0248 - val_loss: 0.0227\n",
      "Epoch 59/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0243\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0242 - val_loss: 0.0245\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0182\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0185 - val_loss: 0.0182\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0177\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0179\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 71/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0170\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0167\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "---------------- Fold 34 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.3350 - val_loss: 0.3844\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1257 - val_loss: 0.0553\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1288 - val_loss: 0.0632\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.1113 - val_loss: 0.0481\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0515 - val_loss: 0.0574\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.1357 - val_loss: 0.1019\n",
      "Epoch 7/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0593 - val_loss: 0.0479\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0593 - val_loss: 0.0962\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0538 - val_loss: 0.0529\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0530 - val_loss: 0.0393\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0484 - val_loss: 0.0461\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0456 - val_loss: 0.0384\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0457 - val_loss: 0.0444\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0440 - val_loss: 0.0341\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0424 - val_loss: 0.0436\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0421 - val_loss: 0.0314\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0405 - val_loss: 0.0434\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0411 - val_loss: 0.0306\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0394 - val_loss: 0.0440\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0394 - val_loss: 0.0300\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0378 - val_loss: 0.0436\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0385 - val_loss: 0.0294\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0376 - val_loss: 0.0381\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0376 - val_loss: 0.0305\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0367 - val_loss: 0.0389\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0365 - val_loss: 0.0298\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0352\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0352 - val_loss: 0.0369\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0209 - val_loss: 0.0214\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0206 - val_loss: 0.0200\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0206 - val_loss: 0.0200\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0203 - val_loss: 0.0196\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 45/85\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.0201\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 47/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0175 - val_loss: 0.0177\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0173\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0166 - val_loss: 0.0171\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0165 - val_loss: 0.0171\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0170\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0163 - val_loss: 0.0170\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0170\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0161 - val_loss: 0.0169\n",
      "Epoch 65/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0160 - val_loss: 0.0169\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0157 - val_loss: 0.0168\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0168\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0156 - val_loss: 0.0168\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0156 - val_loss: 0.0168\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0153 - val_loss: 0.0167\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0154 - val_loss: 0.0167\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0167\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0153 - val_loss: 0.0166\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0153 - val_loss: 0.0166\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0152 - val_loss: 0.0166\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "---------------- Fold 35 ----------------\n",
      "Epoch 1/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.3420 - val_loss: 0.1981\n",
      "Epoch 2/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.1512 - val_loss: 0.0498\n",
      "Epoch 3/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.1368 - val_loss: 0.1628\n",
      "Epoch 4/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0909 - val_loss: 0.1666\n",
      "Epoch 5/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0871 - val_loss: 0.0499\n",
      "Epoch 6/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0591 - val_loss: 0.1102\n",
      "Epoch 7/85\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0933\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0933 - val_loss: 0.0982\n",
      "Epoch 8/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0496 - val_loss: 0.0369\n",
      "Epoch 9/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0319 - val_loss: 0.0324\n",
      "Epoch 10/85\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.0284 - val_loss: 0.0263\n",
      "Epoch 11/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0265 - val_loss: 0.0256\n",
      "Epoch 12/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0260 - val_loss: 0.0253\n",
      "Epoch 13/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0260 - val_loss: 0.0251\n",
      "Epoch 14/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0253 - val_loss: 0.0244\n",
      "Epoch 15/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0254\n",
      "Epoch 16/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0255 - val_loss: 0.0245\n",
      "Epoch 17/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0260 - val_loss: 0.0255\n",
      "Epoch 18/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0256 - val_loss: 0.0242\n",
      "Epoch 19/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0242\n",
      "Epoch 20/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0256 - val_loss: 0.0248\n",
      "Epoch 21/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0261 - val_loss: 0.0250\n",
      "Epoch 22/85\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 0.0265 - val_loss: 0.0252\n",
      "Epoch 23/85\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0253\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0253 - val_loss: 0.0243\n",
      "Epoch 24/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0226 - val_loss: 0.0218\n",
      "Epoch 25/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0211 - val_loss: 0.0207\n",
      "Epoch 26/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 27/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0197 - val_loss: 0.0197\n",
      "Epoch 28/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 29/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0192\n",
      "Epoch 30/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 31/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 32/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 33/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0181 - val_loss: 0.0185\n",
      "Epoch 34/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0177 - val_loss: 0.0183\n",
      "Epoch 35/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0177 - val_loss: 0.0184\n",
      "Epoch 36/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0176 - val_loss: 0.0183\n",
      "Epoch 37/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0175 - val_loss: 0.0182\n",
      "Epoch 38/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0172 - val_loss: 0.0182\n",
      "Epoch 39/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0181\n",
      "Epoch 40/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 41/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0181\n",
      "Epoch 42/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0166 - val_loss: 0.0179\n",
      "Epoch 43/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 44/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0163 - val_loss: 0.0179\n",
      "Epoch 45/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0162 - val_loss: 0.0180\n",
      "Epoch 46/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0179\n",
      "Epoch 47/85\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0184\n",
      "Epoch 48/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0177\n",
      "Epoch 49/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0150 - val_loss: 0.0177\n",
      "Epoch 50/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0148 - val_loss: 0.0177\n",
      "Epoch 51/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0147 - val_loss: 0.0176\n",
      "Epoch 52/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0146 - val_loss: 0.0176\n",
      "Epoch 53/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0176\n",
      "Epoch 54/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0144 - val_loss: 0.0176\n",
      "Epoch 55/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0175\n",
      "Epoch 56/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0143 - val_loss: 0.0175\n",
      "Epoch 57/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0175\n",
      "Epoch 58/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0142 - val_loss: 0.0175\n",
      "Epoch 59/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0141 - val_loss: 0.0175\n",
      "Epoch 60/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0140 - val_loss: 0.0174\n",
      "Epoch 61/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0139 - val_loss: 0.0174\n",
      "Epoch 62/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0174\n",
      "Epoch 63/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0138 - val_loss: 0.0174\n",
      "Epoch 64/85\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.0138 - val_loss: 0.0174\n",
      "Epoch 65/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0137 - val_loss: 0.0174\n",
      "Epoch 66/85\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.0136 - val_loss: 0.0174\n",
      "Epoch 67/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0136 - val_loss: 0.0174\n",
      "Epoch 68/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.0173\n",
      "Epoch 69/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0135 - val_loss: 0.0173\n",
      "Epoch 70/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0173\n",
      "Epoch 71/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0134 - val_loss: 0.0173\n",
      "Epoch 72/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0173\n",
      "Epoch 73/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0173\n",
      "Epoch 74/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 75/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 76/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0131 - val_loss: 0.0173\n",
      "Epoch 77/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0172\n",
      "Epoch 78/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0172\n",
      "Epoch 79/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0172\n",
      "Epoch 80/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0172\n",
      "Epoch 81/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0172\n",
      "Epoch 82/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0172\n",
      "Epoch 83/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0128 - val_loss: 0.0172\n",
      "Epoch 84/85\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.0127 - val_loss: 0.0172\n",
      "Epoch 85/85\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0172\n",
      "Total #iterations: 35\n"
     ]
    }
   ],
   "source": [
    "y_pred = 0\n",
    "y_pred_final = 0\n",
    "idx = 0\n",
    "\n",
    "np.random.seed(1)\n",
    "seeds = np.random.randint(0, 100, size=5)\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    # Define K-fold cross validation test harness\n",
    "    kfold = MultilabelStratifiedKFold(n_splits=7, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for train, val in kfold.split(Xtrain, Ytrain):\n",
    "\n",
    "        idx += 1\n",
    "        print(\"---------------- Fold {} ----------------\".format(idx))\n",
    "\n",
    "        train_x_tmp, val_x_tmp = Xtrain[train], Xtrain[val]\n",
    "        train_y_tmp, val_y_tmp = Ytrain[train], Ytrain[val]\n",
    "\n",
    "        # Create the model\n",
    "        model = moa_prediction_model(Xtrain.shape[1], Ytrain.shape[1])\n",
    "\n",
    "        # Compile model to configure the learning process\n",
    "        model.compile(loss='binary_crossentropy', \n",
    "                      optimizer=Lookahead(AdamW(lr=1e-2, \n",
    "                                                weight_decay=1e-5, \n",
    "                                                clipvalue=700), \n",
    "                                          sync_period=10))\n",
    "\n",
    "        # Early stopping policy\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n",
    "                              restore_best_weights=True, \n",
    "                              patience=10, verbose=1)\n",
    "\n",
    "        # Reduce LR on plateau policy\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, \n",
    "                                      min_lr=1e-5, patience=5, \n",
    "                                      verbose=1, mode='min')\n",
    "\n",
    "        # Fit the model\n",
    "        history = model.fit(x=train_x_tmp, y=train_y_tmp, \n",
    "                            batch_size=mini_batch_size, epochs=85, verbose=1,\n",
    "                            callbacks=[reduce_lr, early], workers=5,\n",
    "                            validation_data=(val_x_tmp, val_y_tmp))\n",
    "\n",
    "        # Make predictions\n",
    "        pred = model.predict(Xtest)\n",
    "        y_pred += pred\n",
    "\n",
    "        pred_final = model.predict(Xpredict)\n",
    "        y_pred_final += pred_final\n",
    "\n",
    "\n",
    "print(\"Total #iterations: {}\".format(idx))\n",
    "y_pred /= float(idx)\n",
    "y_pred_final /= float(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T17:03:44.906368Z",
     "iopub.status.busy": "2020-10-12T17:03:44.905480Z",
     "iopub.status.idle": "2020-10-12T17:03:44.914953Z",
     "shell.execute_reply": "2020-10-12T17:03:44.914384Z"
    },
    "papermill": {
     "duration": 56.911849,
     "end_time": "2020-10-12T17:03:44.915068",
     "exception": false,
     "start_time": "2020-10-12T17:02:48.003219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label smoothing\n",
    "y_pred = np.clip(y_pred, p_min, p_max)\n",
    "y_pred_final = np.clip(y_pred_final, p_min, p_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T17:05:35.295996Z",
     "iopub.status.busy": "2020-10-12T17:05:35.295035Z",
     "iopub.status.idle": "2020-10-12T17:05:35.624816Z",
     "shell.execute_reply": "2020-10-12T17:05:35.623848Z"
    },
    "papermill": {
     "duration": 55.429816,
     "end_time": "2020-10-12T17:05:35.624942",
     "exception": false,
     "start_time": "2020-10-12T17:04:40.195126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016492138941003275"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels = pd.DataFrame(Ytest, columns=train_label_df.columns)\n",
    "pred_labels = pd.DataFrame(y_pred, columns=train_label_df.columns)\n",
    "logloss_metric(train_label_df, true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 55.302211,
     "end_time": "2020-10-12T17:07:26.481533",
     "exception": false,
     "start_time": "2020-10-12T17:06:31.179322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T17:09:16.538548Z",
     "iopub.status.busy": "2020-10-12T17:09:16.537714Z",
     "iopub.status.idle": "2020-10-12T17:09:16.566478Z",
     "shell.execute_reply": "2020-10-12T17:09:16.566967Z"
    },
    "papermill": {
     "duration": 54.510445,
     "end_time": "2020-10-12T17:09:16.567097",
     "exception": false,
     "start_time": "2020-10-12T17:08:22.056652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3982, 206)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.015508</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.017099</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                     0.001000                   0.001        0.001915   \n",
       "1                     0.001000                   0.001        0.001211   \n",
       "2                     0.000000                   0.000        0.000000   \n",
       "3                     0.001000                   0.001        0.001863   \n",
       "4                     0.001885                   0.001        0.001827   \n",
       "\n",
       "   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                        0.015508                           0.021545   \n",
       "1                        0.002659                           0.002152   \n",
       "2                        0.000000                           0.000000   \n",
       "3                        0.013270                           0.018007   \n",
       "4                        0.013483                           0.018651   \n",
       "\n",
       "   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                        0.004934                    0.002623   \n",
       "1                        0.001588                    0.001084   \n",
       "2                        0.000000                    0.000000   \n",
       "3                        0.003876                    0.003456   \n",
       "4                        0.004574                    0.006088   \n",
       "\n",
       "   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                       0.005574                    0.001000   \n",
       "1                       0.008005                    0.004749   \n",
       "2                       0.000000                    0.000000   \n",
       "3                       0.008697                    0.001000   \n",
       "4                       0.002676                    0.001000   \n",
       "\n",
       "   adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                     0.016699  ...                                  0.001   \n",
       "1                     0.010807  ...                                  0.001   \n",
       "2                     0.000000  ...                                  0.000   \n",
       "3                     0.014241  ...                                  0.001   \n",
       "4                     0.016012  ...                                  0.001   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.002258         0.003698           0.002693   \n",
       "1      0.002122         0.001942           0.001000   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.001170         0.002725           0.004337   \n",
       "4      0.001000         0.003533           0.001000   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.001162                                  0.001   \n",
       "1                   0.017099                                  0.001   \n",
       "2                   0.000000                                  0.000   \n",
       "3                   0.004501                                  0.001   \n",
       "4                   0.001000                                  0.001   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.001169   0.002293                    0.003018       0.001571  \n",
       "1         0.016166   0.001000                    0.001431       0.001736  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.001580   0.002247                    0.002083       0.002286  \n",
       "4         0.001000   0.001522                    0.001058       0.002028  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = pd.DataFrame(y_pred_final, columns=train_label_df.columns)\n",
    "pred_labels.loc[predict_df['cp_type']=='ctl_vehicle', train_label_df.columns] = 0\n",
    "print(pred_labels.shape)\n",
    "pred_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T17:11:06.289531Z",
     "iopub.status.busy": "2020-10-12T17:11:06.286849Z",
     "iopub.status.idle": "2020-10-12T17:11:06.558763Z",
     "shell.execute_reply": "2020-10-12T17:11:06.559374Z"
    },
    "papermill": {
     "duration": 54.918408,
     "end_time": "2020-10-12T17:11:06.559532",
     "exception": false,
     "start_time": "2020-10-12T17:10:11.641124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.015508</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.017099</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.001000                   0.001   \n",
       "1  id_001897cda                     0.001000                   0.001   \n",
       "2  id_002429b5b                     0.000000                   0.000   \n",
       "3  id_00276f245                     0.001000                   0.001   \n",
       "4  id_0027f1083                     0.001885                   0.001   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.001915                        0.015508   \n",
       "1        0.001211                        0.002659   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.001863                        0.013270   \n",
       "4        0.001827                        0.013483   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.021545                        0.004934   \n",
       "1                           0.002152                        0.001588   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.018007                        0.003876   \n",
       "4                           0.018651                        0.004574   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.002623                       0.005574   \n",
       "1                    0.001084                       0.008005   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.003456                       0.008697   \n",
       "4                    0.006088                       0.002676   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.001000  ...                                  0.001   \n",
       "1                    0.004749  ...                                  0.001   \n",
       "2                    0.000000  ...                                  0.000   \n",
       "3                    0.001000  ...                                  0.001   \n",
       "4                    0.001000  ...                                  0.001   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.002258         0.003698           0.002693   \n",
       "1      0.002122         0.001942           0.001000   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.001170         0.002725           0.004337   \n",
       "4      0.001000         0.003533           0.001000   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.001162                                  0.001   \n",
       "1                   0.017099                                  0.001   \n",
       "2                   0.000000                                  0.000   \n",
       "3                   0.004501                                  0.001   \n",
       "4                   0.001000                                  0.001   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.001169   0.002293                    0.003018       0.001571  \n",
       "1         0.016166   0.001000                    0.001431       0.001736  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.001580   0.002247                    0.002083       0.002286  \n",
       "4         0.001000   0.001522                    0.001058       0.002028  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df = pd.read_csv(\"/kaggle/input/lish-moa/sample_submission.csv\")\n",
    "submit_df.loc[:, submit_df.columns != 'sig_id'] = pred_labels\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T17:12:56.290609Z",
     "iopub.status.busy": "2020-10-12T17:12:56.289705Z",
     "iopub.status.idle": "2020-10-12T17:12:57.778015Z",
     "shell.execute_reply": "2020-10-12T17:12:57.776975Z"
    },
    "papermill": {
     "duration": 56.128485,
     "end_time": "2020-10-12T17:12:57.778138",
     "exception": false,
     "start_time": "2020-10-12T17:12:01.649653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 54.515002,
     "end_time": "2020-10-12T17:14:47.030609",
     "exception": false,
     "start_time": "2020-10-12T17:13:52.515607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 15864.729087,
   "end_time": "2020-10-12T17:15:42.182789",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-12T12:51:17.453702",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
