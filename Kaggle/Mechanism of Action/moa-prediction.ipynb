{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:34.338864Z",
     "iopub.status.busy": "2020-10-20T15:11:34.337987Z",
     "iopub.status.idle": "2020-10-20T15:11:34.362356Z",
     "shell.execute_reply": "2020-10-20T15:11:34.363288Z"
    },
    "papermill": {
     "duration": 0.057337,
     "end_time": "2020-10-20T15:11:34.363545",
     "exception": false,
     "start_time": "2020-10-20T15:11:34.306208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/permutation-importance/PermutationImportance.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:34.418344Z",
     "iopub.status.busy": "2020-10-20T15:11:34.417355Z",
     "iopub.status.idle": "2020-10-20T15:11:34.420686Z",
     "shell.execute_reply": "2020-10-20T15:11:34.420107Z"
    },
    "papermill": {
     "duration": 0.032219,
     "end_time": "2020-10-20T15:11:34.420803",
     "exception": false,
     "start_time": "2020-10-20T15:11:34.388584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/kaggle/input/permutation-importance')\n",
    "sys.path.insert(2, '/kaggle/input/iterative-stratification/iterative-stratification-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023256,
     "end_time": "2020-10-20T15:11:34.467887",
     "exception": false,
     "start_time": "2020-10-20T15:11:34.444631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:34.525650Z",
     "iopub.status.busy": "2020-10-20T15:11:34.524752Z",
     "iopub.status.idle": "2020-10-20T15:11:42.142829Z",
     "shell.execute_reply": "2020-10-20T15:11:42.143436Z"
    },
    "papermill": {
     "duration": 7.652645,
     "end_time": "2020-10-20T15:11:42.143601",
     "exception": false,
     "start_time": "2020-10-20T15:11:34.490956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.optimizers import AdamW, Lookahead\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from PermutationImportance import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023973,
     "end_time": "2020-10-20T15:11:42.190860",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.166887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.249830Z",
     "iopub.status.busy": "2020-10-20T15:11:42.247613Z",
     "iopub.status.idle": "2020-10-20T15:11:42.250821Z",
     "shell.execute_reply": "2020-10-20T15:11:42.251405Z"
    },
    "papermill": {
     "duration": 0.037297,
     "end_time": "2020-10-20T15:11:42.251574",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.214277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logloss_metric(df, y_true, y_pred):\n",
    "    \n",
    "    metrics = []\n",
    "    \n",
    "    # Calculate log_loss individually for every field\n",
    "    for _target in df.columns:\n",
    "        metrics.append(log_loss(y_true.loc[:, _target], \n",
    "                                y_pred.loc[:, _target].astype(float), \n",
    "                                labels=[0,1]))\n",
    "    \n",
    "    # Return mean of individual log_loss values\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.312513Z",
     "iopub.status.busy": "2020-10-20T15:11:42.311653Z",
     "iopub.status.idle": "2020-10-20T15:11:42.314971Z",
     "shell.execute_reply": "2020-10-20T15:11:42.315502Z"
    },
    "papermill": {
     "duration": 0.039093,
     "end_time": "2020-10-20T15:11:42.315659",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.276566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca_fet(train, test, features, kind, n_components, SEED=10):\n",
    "    \n",
    "    # Combine train and test datasets\n",
    "    train_ = train[features].copy()\n",
    "    test_ = test[features].copy()\n",
    "    data = pd.concat([train_, test_], axis=0)\n",
    "    \n",
    "    # Perform PCA to create new features\n",
    "    pca = PCA(n_components=n_components, random_state=SEED)\n",
    "    data = pca.fit_transform(data)\n",
    "    columns = [f'pca_{kind}{i + 1}' for i in range(n_components)]\n",
    "    data = pd.DataFrame(data, columns = columns)\n",
    "    \n",
    "    # Append new features to train and test datasets\n",
    "    train_ = data.iloc[:train.shape[0]]\n",
    "    test_ = data.iloc[train.shape[0]:].reset_index(drop=True)\n",
    "    train = pd.concat([train, train_], axis=1)\n",
    "    test = pd.concat([test, test_], axis=1)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.374419Z",
     "iopub.status.busy": "2020-10-20T15:11:42.373383Z",
     "iopub.status.idle": "2020-10-20T15:11:42.376965Z",
     "shell.execute_reply": "2020-10-20T15:11:42.376289Z"
    },
    "papermill": {
     "duration": 0.037865,
     "end_time": "2020-10-20T15:11:42.377081",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.339216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_fet(train, test, features, kind, n_clusters, SEED=10):\n",
    "    \n",
    "    # Combine train and test datasets\n",
    "    train_ = train[features].copy()\n",
    "    test_ = test[features].copy()\n",
    "    data = pd.concat([train_, test_], axis=0)\n",
    "    \n",
    "    # Perform KMeans to create new features\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED).fit(data)\n",
    "    \n",
    "    # Append new features to train and test datasets\n",
    "    train[f'clusters_{kind}'] = kmeans.labels_[:train.shape[0]]\n",
    "    test[f'clusters_{kind}'] = kmeans.labels_[train.shape[0]:]\n",
    "    train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "    test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.453030Z",
     "iopub.status.busy": "2020-10-20T15:11:42.442317Z",
     "iopub.status.idle": "2020-10-20T15:11:42.460663Z",
     "shell.execute_reply": "2020-10-20T15:11:42.461204Z"
    },
    "papermill": {
     "duration": 0.061492,
     "end_time": "2020-10-20T15:11:42.461354",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.399862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preprocess(dataset_dict, SEED=10):\n",
    "    \n",
    "    # Extract datasets path from input dict\n",
    "    train_ds = dataset_dict['train_dataset']\n",
    "    train_labels_ds = dataset_dict['train_labels_scored']\n",
    "    predict_ds = dataset_dict['predict_dataset']\n",
    "    \n",
    "    # Read and display individual dataframe shapes\n",
    "    train_df = pd.read_csv(train_ds)\n",
    "    train_label_df = pd.read_csv(train_labels_ds)\n",
    "    predict_df = pd.read_csv(predict_ds)\n",
    "    print(\"\\n------------- Input Dataset Shapes -------------\")\n",
    "    print(\"train_df: {}\".format(train_df.shape))\n",
    "    print(\"train_label_df: {}\".format(train_label_df.shape))\n",
    "    print(\"predict_df: {}\".format(predict_df.shape))\n",
    "    \n",
    "    # Drop training rows with cp_type = ctl_vehicle\n",
    "    train_label_df = train_label_df.loc[train_df['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "    train_df = train_df.loc[train_df['cp_type']=='trt_cp'].reset_index(drop=True)\n",
    "    train_samples = train_df.shape[0]\n",
    "    print(\"\\n------------- Dataset Shapes after removing ctl_vehicle rows -------------\")\n",
    "    print(\"train_df: {}\".format(train_df.shape))\n",
    "    print(\"train_label_df: {}\".format(train_label_df.shape))\n",
    "    \n",
    "    # Separate the columns for gene expression and cell viability\n",
    "    features_g = list(train_df.columns[4:776])\n",
    "    features_c = list(train_df.columns[776:876])\n",
    "    \n",
    "    # Generate PCA features\n",
    "    print(\"\\n------------- Performing PCA -------------\")\n",
    "    train, test = pca_fet(train_df, predict_df, features_g, kind='g', n_components=80, SEED=SEED)\n",
    "    train, test = pca_fet(train, test, features_c, kind='c', n_components=80, SEED=SEED)\n",
    "    print(\"Dataset size after PCA: \\ntrain: {} \\npredict: {}\".format(train.shape, test.shape))\n",
    "    \n",
    "    '''\n",
    "    # Generate KMeans features\n",
    "    print(\"\\n------------- Performing KMeans -------------\")\n",
    "    train, test = kmeans_fet(train, test, features_g, kind='g', n_clusters=50, SEED=SEED)\n",
    "    train, test = kmeans_fet(train, test, features_c, kind='c', n_clusters=50, SEED=SEED)\n",
    "    print(\"Dataset size after KMeans: \\ntrain: {} \\npredict: {}\".format(train.shape, test.shape))\n",
    "    '''\n",
    "    \n",
    "    # Combined both input dataframes\n",
    "    combined_df = train.append(test, sort=False, ignore_index=True)\n",
    "    \n",
    "    # Additional Feature Engineering\n",
    "    combined_df['cp_type_enc'] = combined_df['cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    combined_df['cp_dose_enc'] = combined_df['cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    combined_df['cp_time_days'] = combined_df['cp_time'].apply(lambda x: x//24)\n",
    "    combined_df.drop(['sig_id', 'cp_type', 'cp_dose', 'cp_time'], axis=1, inplace=True)\n",
    "    \n",
    "    combined_df['g_sum'] = combined_df[features_g].sum(axis=1)\n",
    "    combined_df['g_mean'] = combined_df[features_g].mean(axis=1)\n",
    "    combined_df['g_std'] = combined_df[features_g].std(axis=1)\n",
    "    combined_df['g_kurt'] = combined_df[features_g].kurtosis(axis=1)\n",
    "    combined_df['g_skew'] = combined_df[features_g].skew(axis=1)\n",
    "    combined_df['c_sum'] = combined_df[features_c].sum(axis=1)\n",
    "    combined_df['c_mean'] = combined_df[features_c].mean(axis=1)\n",
    "    combined_df['c_std'] = combined_df[features_c].std(axis=1)\n",
    "    combined_df['c_kurt'] = combined_df[features_c].kurtosis(axis=1)\n",
    "    combined_df['c_skew'] = combined_df[features_c].skew(axis=1)\n",
    "    combined_df['gc_sum'] = combined_df[features_g + features_c].sum(axis=1)\n",
    "    combined_df['gc_mean'] = combined_df[features_g + features_c].mean(axis=1)\n",
    "    combined_df['gc_std'] = combined_df[features_g + features_c].std(axis=1)\n",
    "    combined_df['gc_kurt'] = combined_df[features_g + features_c].kurtosis(axis=1)\n",
    "    combined_df['gc_skew'] = combined_df[features_g + features_c].skew(axis=1)\n",
    "    \n",
    "    # Segregate train and predict datasets\n",
    "    train_label_df.drop(['sig_id'], axis=1, inplace=True)\n",
    "    train_y = train_label_df.values\n",
    "    train_x = combined_df[:train_samples].values\n",
    "    predict_x = combined_df[train_samples:].values\n",
    "    \n",
    "    print(\"\\n------------- Final Dataset Shapes -------------\")\n",
    "    print(\"\\ntrain_x: {}\".format(train_x.shape))\n",
    "    print(\"train_y: {}\".format(train_y.shape))\n",
    "    print(\"predict_x: {}\".format(predict_x.shape))\n",
    "    \n",
    "    return train_x, train_y, predict_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.520921Z",
     "iopub.status.busy": "2020-10-20T15:11:42.520033Z",
     "iopub.status.idle": "2020-10-20T15:11:42.523622Z",
     "shell.execute_reply": "2020-10-20T15:11:42.523098Z"
    },
    "papermill": {
     "duration": 0.038718,
     "end_time": "2020-10-20T15:11:42.523730",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.485012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moa_prediction_model_2L(input_shape, output_shape):\n",
    "    \n",
    "    # Input Layer\n",
    "    x_input = Input(shape=(input_shape, ), name='INPUT')\n",
    "    x = BatchNormalization(name='BN-INPUT')(x_input)\n",
    "    \n",
    "    # Fully-connected Layer 1\n",
    "    x = Dense(units=1024, name='FC-1', activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
    "    x = BatchNormalization(name='BN_FC-1')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-1')(x)\n",
    "    \n",
    "    # Fully-connected Layer 2\n",
    "    x = Dense(units=256, name='FC-2', activation='relu', kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(name='BN_FC-2')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-2')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    x = Dense(units=output_shape, activation='sigmoid', name='OUTPUT')(x)\n",
    "\n",
    "    # Create Keras Model instance\n",
    "    model = Model(inputs=x_input, outputs=x, name='MOA_Prediction_Model_2L')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.588514Z",
     "iopub.status.busy": "2020-10-20T15:11:42.587463Z",
     "iopub.status.idle": "2020-10-20T15:11:42.590734Z",
     "shell.execute_reply": "2020-10-20T15:11:42.590169Z"
    },
    "papermill": {
     "duration": 0.043162,
     "end_time": "2020-10-20T15:11:42.590865",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.547703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moa_prediction_model_3L(input_shape, output_shape):\n",
    "    \n",
    "    # Input Layer\n",
    "    x_input = Input(shape=(input_shape, ), name='INPUT')\n",
    "    x = BatchNormalization(name='BN-INPUT')(x_input)\n",
    "    \n",
    "    # Fully-connected Layer 1\n",
    "    x = Dense(units=1024, name='FC-1', activation='selu', kernel_regularizer=l2(0.0005))(x)\n",
    "    x = BatchNormalization(name='BN_FC-1')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-1')(x)\n",
    "    \n",
    "    # Fully-connected Layer 2\n",
    "    x = Dense(units=512, name='FC-2', activation='selu', kernel_regularizer=l2(0.0003))(x)\n",
    "    x = BatchNormalization(name='BN_FC-2')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-2')(x)\n",
    "    \n",
    "    # Fully-connected Layer 3\n",
    "    x = Dense(units=256, name='FC-3', activation='selu', kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(name='BN_FC-3')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-3')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    x = Dense(units=output_shape, activation='sigmoid', name='OUTPUT')(x)\n",
    "\n",
    "    # Create Keras Model instance\n",
    "    model = Model(inputs=x_input, outputs=x, name='MOA_Prediction_Model_3L')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.655214Z",
     "iopub.status.busy": "2020-10-20T15:11:42.654184Z",
     "iopub.status.idle": "2020-10-20T15:11:42.657212Z",
     "shell.execute_reply": "2020-10-20T15:11:42.656656Z"
    },
    "papermill": {
     "duration": 0.0426,
     "end_time": "2020-10-20T15:11:42.657324",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.614724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moa_prediction_model_4L(input_shape, output_shape):\n",
    "    \n",
    "    # Input Layer\n",
    "    x_input = Input(shape=(input_shape, ), name='INPUT')\n",
    "    x = BatchNormalization(name='BN-INPUT')(x_input)\n",
    "    \n",
    "    # Fully-connected Layer 1\n",
    "    x = Dense(units=1024, name='FC-1', kernel_regularizer=l2(0.0005))(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(name='BN_FC-1')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-1')(x)\n",
    "    \n",
    "    # Fully-connected Layer 2\n",
    "    x = Dense(units=512, name='FC-2', kernel_regularizer=l2(0.0003))(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(name='BN_FC-2')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-2')(x)\n",
    "    \n",
    "    # Fully-connected Layer 3\n",
    "    x = Dense(units=512, name='FC-3', kernel_regularizer=l2(0.0003))(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(name='BN_FC-3')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-3')(x)\n",
    "    \n",
    "    # Fully-connected Layer 4\n",
    "    x = Dense(units=256, name='FC-4', kernel_regularizer=l2(0.0001))(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(name='BN_FC-4')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-4')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    x = Dense(units=output_shape, activation='sigmoid', name='OUTPUT')(x)\n",
    "\n",
    "    # Create Keras Model instance\n",
    "    model = Model(inputs=x_input, outputs=x, name='MOA_Prediction_Model_4L')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.722996Z",
     "iopub.status.busy": "2020-10-20T15:11:42.721938Z",
     "iopub.status.idle": "2020-10-20T15:11:42.724981Z",
     "shell.execute_reply": "2020-10-20T15:11:42.724351Z"
    },
    "papermill": {
     "duration": 0.043721,
     "end_time": "2020-10-20T15:11:42.725101",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.681380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moa_prediction_model_5L(input_shape, output_shape):\n",
    "    \n",
    "    # Input Layer\n",
    "    x_input = Input(shape=(input_shape, ), name='INPUT')\n",
    "    x = BatchNormalization(name='BN-INPUT')(x_input)\n",
    "    \n",
    "    # Fully-connected Layer 1\n",
    "    x = Dense(units=1024, name='FC-1', activation='swish', kernel_regularizer=l2(0.0005))(x)\n",
    "    x = BatchNormalization(name='BN_FC-1')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-1')(x)\n",
    "    \n",
    "    # Fully-connected Layer 2\n",
    "    x = Dense(units=512, name='FC-2', activation='swish', kernel_regularizer=l2(0.0003))(x)\n",
    "    x = BatchNormalization(name='BN_FC-2')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-2')(x)\n",
    "    \n",
    "    # Fully-connected Layer 3\n",
    "    x = Dense(units=512, name='FC-3', activation='swish', kernel_regularizer=l2(0.0003))(x)\n",
    "    x = BatchNormalization(name='BN_FC-3')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-3')(x)\n",
    "    \n",
    "    # Fully-connected Layer 4\n",
    "    x = Dense(units=256, name='FC-4', activation='swish', kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(name='BN_FC-4')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-4')(x)\n",
    "    \n",
    "    # Fully-connected Layer 5\n",
    "    x = Dense(units=256, name='FC-5', activation='swish', kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(name='BN_FC-5')(x)\n",
    "    x = Dropout(rate=0.5, name='DROPOUT_FC-5')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    x = Dense(units=output_shape, activation='sigmoid', name='OUTPUT')(x)\n",
    "\n",
    "    # Create Keras Model instance\n",
    "    model = Model(inputs=x_input, outputs=x, name='MOA_Prediction_Model_5L')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024105,
     "end_time": "2020-10-20T15:11:42.776433",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.752328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024482,
     "end_time": "2020-10-20T15:11:42.825414",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.800932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set file paths for train and predict datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.882341Z",
     "iopub.status.busy": "2020-10-20T15:11:42.881296Z",
     "iopub.status.idle": "2020-10-20T15:11:42.884537Z",
     "shell.execute_reply": "2020-10-20T15:11:42.883893Z"
    },
    "papermill": {
     "duration": 0.033078,
     "end_time": "2020-10-20T15:11:42.884644",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.851566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = \"/kaggle/input/lish-moa/train_features.csv\"\n",
    "train_labels_scored = \"/kaggle/input/lish-moa/train_targets_scored.csv\"\n",
    "predict_dataset = \"/kaggle/input/lish-moa/test_features.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023945,
     "end_time": "2020-10-20T15:11:42.933345",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.909400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Process train and predict features datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:42.990933Z",
     "iopub.status.busy": "2020-10-20T15:11:42.989566Z",
     "iopub.status.idle": "2020-10-20T15:11:49.139887Z",
     "shell.execute_reply": "2020-10-20T15:11:49.139006Z"
    },
    "papermill": {
     "duration": 6.182485,
     "end_time": "2020-10-20T15:11:49.140051",
     "exception": false,
     "start_time": "2020-10-20T15:11:42.957566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (23814, 876)\n",
      "train_label_df: (23814, 206)\n",
      "predict_df: (3982, 876)\n"
     ]
    }
   ],
   "source": [
    "# Read and display individual dataframe shapes\n",
    "train_df = pd.read_csv(train_dataset)\n",
    "train_label_df = pd.read_csv(train_labels_scored)\n",
    "train_label_df.drop(['sig_id'], axis=1, inplace=True)\n",
    "predict_df = pd.read_csv(predict_dataset)\n",
    "\n",
    "print(\"train_df: {}\".format(train_df.shape))\n",
    "print(\"train_label_df: {}\".format(train_label_df.shape))\n",
    "print(\"predict_df: {}\".format(predict_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:49.218654Z",
     "iopub.status.busy": "2020-10-20T15:11:49.217725Z",
     "iopub.status.idle": "2020-10-20T15:11:49.224143Z",
     "shell.execute_reply": "2020-10-20T15:11:49.223162Z"
    },
    "papermill": {
     "duration": 0.047754,
     "end_time": "2020-10-20T15:11:49.224287",
     "exception": false,
     "start_time": "2020-10-20T15:11:49.176533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "datasets['train_dataset'] = train_dataset\n",
    "datasets['train_labels_scored'] = train_labels_scored\n",
    "datasets['predict_dataset'] = predict_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:11:49.310976Z",
     "iopub.status.busy": "2020-10-20T15:11:49.307880Z",
     "iopub.status.idle": "2020-10-20T15:12:04.195898Z",
     "shell.execute_reply": "2020-10-20T15:12:04.195320Z"
    },
    "papermill": {
     "duration": 14.934082,
     "end_time": "2020-10-20T15:12:04.196028",
     "exception": false,
     "start_time": "2020-10-20T15:11:49.261946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Input Dataset Shapes -------------\n",
      "train_df: (23814, 876)\n",
      "train_label_df: (23814, 207)\n",
      "predict_df: (3982, 876)\n",
      "\n",
      "------------- Dataset Shapes after removing ctl_vehicle rows -------------\n",
      "train_df: (21948, 876)\n",
      "train_label_df: (21948, 207)\n",
      "\n",
      "------------- Performing PCA -------------\n",
      "Dataset size after PCA: \n",
      "train: (21948, 1036) \n",
      "predict: (3982, 1036)\n",
      "\n",
      "------------- Final Dataset Shapes -------------\n",
      "\n",
      "train_x: (21948, 1050)\n",
      "train_y: (21948, 206)\n",
      "predict_x: (3982, 1050)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain, Xpredict = data_preprocess(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026728,
     "end_time": "2020-10-20T15:12:04.248831",
     "exception": false,
     "start_time": "2020-10-20T15:12:04.222103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:12:04.311289Z",
     "iopub.status.busy": "2020-10-20T15:12:04.310484Z",
     "iopub.status.idle": "2020-10-20T15:12:04.314606Z",
     "shell.execute_reply": "2020-10-20T15:12:04.313968Z"
    },
    "papermill": {
     "duration": 0.038826,
     "end_time": "2020-10-20T15:12:04.314766",
     "exception": false,
     "start_time": "2020-10-20T15:12:04.275940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model hyperparameters\n",
    "mini_batch_size = 128\n",
    "\n",
    "# Prediction Clipping Thresholds\n",
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "# Set number of K-Folds\n",
    "FOLD = 7\n",
    "\n",
    "# Set seeds for training different models\n",
    "np.random.seed(1)\n",
    "seed_2L = np.random.randint(  0,  50, size=3)      # relu\n",
    "seed_3L = np.random.randint( 51, 100, size=3)      # selu\n",
    "seed_4L = np.random.randint(101, 150, size=2)      # leaky-relu\n",
    "seed_5L = np.random.randint(151, 200, size=3)      # swish\n",
    "seed_mstr = [seed_2L, seed_3L, seed_4L, seed_5L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T15:12:04.392374Z",
     "iopub.status.busy": "2020-10-20T15:12:04.381879Z",
     "iopub.status.idle": "2020-10-20T17:40:04.079160Z",
     "shell.execute_reply": "2020-10-20T17:40:04.080055Z"
    },
    "papermill": {
     "duration": 8879.739602,
     "end_time": "2020-10-20T17:40:04.080318",
     "exception": false,
     "start_time": "2020-10-20T15:12:04.340716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Layer Model | Seed: 37 | Fold: 1 | Log Loss: 0.01628473008242043\n",
      "2-Layer Model | Seed: 37 | Fold: 2 | Log Loss: 0.016675568282555793\n",
      "2-Layer Model | Seed: 37 | Fold: 3 | Log Loss: 0.016449822286556236\n",
      "2-Layer Model | Seed: 37 | Fold: 4 | Log Loss: 0.016618990101947423\n",
      "2-Layer Model | Seed: 37 | Fold: 5 | Log Loss: 0.016336608981526286\n",
      "2-Layer Model | Seed: 37 | Fold: 6 | Log Loss: 0.016604642013457335\n",
      "2-Layer Model | Seed: 37 | Fold: 7 | Log Loss: 0.016507218687340872\n",
      "\n",
      "2-Layer Model | Seed: 37 | Aggregate Log Loss: 0.01649679720511491\n",
      "--------------------------------------------------------------------\n",
      "2-Layer Model | Seed: 43 | Fold: 1 | Log Loss: 0.016509745287787165\n",
      "2-Layer Model | Seed: 43 | Fold: 2 | Log Loss: 0.016677909837265654\n",
      "2-Layer Model | Seed: 43 | Fold: 3 | Log Loss: 0.016234026289052725\n",
      "2-Layer Model | Seed: 43 | Fold: 4 | Log Loss: 0.016435054032969593\n",
      "2-Layer Model | Seed: 43 | Fold: 5 | Log Loss: 0.016373127844958663\n",
      "2-Layer Model | Seed: 43 | Fold: 6 | Log Loss: 0.01659468360282493\n",
      "2-Layer Model | Seed: 43 | Fold: 7 | Log Loss: 0.016323050206112463\n",
      "\n",
      "2-Layer Model | Seed: 43 | Aggregate Log Loss: 0.016449656728710172\n",
      "--------------------------------------------------------------------\n",
      "2-Layer Model | Seed: 12 | Fold: 1 | Log Loss: 0.016556412760209936\n",
      "2-Layer Model | Seed: 12 | Fold: 2 | Log Loss: 0.016348803059243598\n",
      "2-Layer Model | Seed: 12 | Fold: 3 | Log Loss: 0.016569777480067792\n",
      "2-Layer Model | Seed: 12 | Fold: 4 | Log Loss: 0.016417322963458807\n",
      "2-Layer Model | Seed: 12 | Fold: 5 | Log Loss: 0.01650355117230956\n",
      "2-Layer Model | Seed: 12 | Fold: 6 | Log Loss: 0.016556384951645665\n",
      "2-Layer Model | Seed: 12 | Fold: 7 | Log Loss: 0.016326468813530587\n",
      "\n",
      "2-Layer Model | Seed: 12 | Aggregate Log Loss: 0.016468388742923706\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "2-Layer Model | Aggregate Log Loss: 0.016471614225582933\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "3-Layer Model | Seed: 59 | Fold: 1 | Log Loss: 0.01688047504070849\n",
      "3-Layer Model | Seed: 59 | Fold: 2 | Log Loss: 0.01706570657148686\n",
      "3-Layer Model | Seed: 59 | Fold: 3 | Log Loss: 0.01706575065802883\n",
      "3-Layer Model | Seed: 59 | Fold: 4 | Log Loss: 0.01708206391524439\n",
      "3-Layer Model | Seed: 59 | Fold: 5 | Log Loss: 0.017034310292253912\n",
      "3-Layer Model | Seed: 59 | Fold: 6 | Log Loss: 0.016972823557794288\n",
      "3-Layer Model | Seed: 59 | Fold: 7 | Log Loss: 0.017120902462748906\n",
      "\n",
      "3-Layer Model | Seed: 59 | Aggregate Log Loss: 0.017031718928323666\n",
      "--------------------------------------------------------------------\n",
      "3-Layer Model | Seed: 60 | Fold: 1 | Log Loss: 0.017172801760325228\n",
      "3-Layer Model | Seed: 60 | Fold: 2 | Log Loss: 0.01722509419244545\n",
      "3-Layer Model | Seed: 60 | Fold: 3 | Log Loss: 0.016990638632975306\n",
      "3-Layer Model | Seed: 60 | Fold: 4 | Log Loss: 0.01698740290553911\n",
      "3-Layer Model | Seed: 60 | Fold: 5 | Log Loss: 0.01729828554186574\n",
      "3-Layer Model | Seed: 60 | Fold: 6 | Log Loss: 0.01696321215033595\n",
      "3-Layer Model | Seed: 60 | Fold: 7 | Log Loss: 0.017261258436989606\n",
      "\n",
      "3-Layer Model | Seed: 60 | Aggregate Log Loss: 0.0171283848029252\n",
      "--------------------------------------------------------------------\n",
      "3-Layer Model | Seed: 62 | Fold: 1 | Log Loss: 0.016918486869666023\n",
      "3-Layer Model | Seed: 62 | Fold: 2 | Log Loss: 0.017134773737377335\n",
      "3-Layer Model | Seed: 62 | Fold: 3 | Log Loss: 0.016956463732401082\n",
      "3-Layer Model | Seed: 62 | Fold: 4 | Log Loss: 0.017150312655481358\n",
      "3-Layer Model | Seed: 62 | Fold: 5 | Log Loss: 0.017114224316502946\n",
      "3-Layer Model | Seed: 62 | Fold: 6 | Log Loss: 0.01689407041372494\n",
      "3-Layer Model | Seed: 62 | Fold: 7 | Log Loss: 0.017118133858450773\n",
      "\n",
      "3-Layer Model | Seed: 62 | Aggregate Log Loss: 0.017040923654800637\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "3-Layer Model | Aggregate Log Loss: 0.017067009128683166\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "4-Layer Model | Seed: 106 | Fold: 1 | Log Loss: 0.017010845360103197\n",
      "4-Layer Model | Seed: 106 | Fold: 2 | Log Loss: 0.01676039583955784\n",
      "4-Layer Model | Seed: 106 | Fold: 3 | Log Loss: 0.016849082694725268\n",
      "4-Layer Model | Seed: 106 | Fold: 4 | Log Loss: 0.016894747123596992\n",
      "4-Layer Model | Seed: 106 | Fold: 5 | Log Loss: 0.016884675102531065\n",
      "4-Layer Model | Seed: 106 | Fold: 6 | Log Loss: 0.017201373038138165\n",
      "4-Layer Model | Seed: 106 | Fold: 7 | Log Loss: 0.016933584963927707\n",
      "\n",
      "4-Layer Model | Seed: 106 | Aggregate Log Loss: 0.016933529160368607\n",
      "--------------------------------------------------------------------\n",
      "4-Layer Model | Seed: 116 | Fold: 1 | Log Loss: 0.016804624004346593\n",
      "4-Layer Model | Seed: 116 | Fold: 2 | Log Loss: 0.017135187926103117\n",
      "4-Layer Model | Seed: 116 | Fold: 3 | Log Loss: 0.017123245573456788\n",
      "4-Layer Model | Seed: 116 | Fold: 4 | Log Loss: 0.017002015629646223\n",
      "4-Layer Model | Seed: 116 | Fold: 5 | Log Loss: 0.016752535306797788\n",
      "4-Layer Model | Seed: 116 | Fold: 6 | Log Loss: 0.01688073566787562\n",
      "4-Layer Model | Seed: 116 | Fold: 7 | Log Loss: 0.016917269432129706\n",
      "\n",
      "4-Layer Model | Seed: 116 | Aggregate Log Loss: 0.01694508764862226\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "4-Layer Model | Aggregate Log Loss: 0.016939308404495434\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "5-Layer Model | Seed: 151 | Fold: 1 | Log Loss: 0.01756034616651121\n",
      "5-Layer Model | Seed: 151 | Fold: 2 | Log Loss: 0.0172992800340005\n",
      "5-Layer Model | Seed: 151 | Fold: 3 | Log Loss: 0.017180685202723808\n",
      "5-Layer Model | Seed: 151 | Fold: 4 | Log Loss: 0.017373451074674418\n",
      "5-Layer Model | Seed: 151 | Fold: 5 | Log Loss: 0.017443288953195288\n",
      "5-Layer Model | Seed: 151 | Fold: 6 | Log Loss: 0.01764689515538922\n",
      "5-Layer Model | Seed: 151 | Fold: 7 | Log Loss: 0.017422243277518158\n",
      "\n",
      "5-Layer Model | Seed: 151 | Aggregate Log Loss: 0.017418027123430373\n",
      "--------------------------------------------------------------------\n",
      "5-Layer Model | Seed: 167 | Fold: 1 | Log Loss: 0.017088549924658195\n",
      "5-Layer Model | Seed: 167 | Fold: 2 | Log Loss: 0.017340120963223123\n",
      "5-Layer Model | Seed: 167 | Fold: 3 | Log Loss: 0.017330158982688637\n",
      "5-Layer Model | Seed: 167 | Fold: 4 | Log Loss: 0.017381886981962698\n",
      "5-Layer Model | Seed: 167 | Fold: 5 | Log Loss: 0.017426292190763974\n",
      "5-Layer Model | Seed: 167 | Fold: 6 | Log Loss: 0.017621146171315192\n",
      "5-Layer Model | Seed: 167 | Fold: 7 | Log Loss: 0.017367569672172064\n",
      "\n",
      "5-Layer Model | Seed: 167 | Aggregate Log Loss: 0.01736510355525484\n",
      "--------------------------------------------------------------------\n",
      "5-Layer Model | Seed: 152 | Fold: 1 | Log Loss: 0.01731722300289722\n",
      "5-Layer Model | Seed: 152 | Fold: 2 | Log Loss: 0.017304787541721718\n",
      "5-Layer Model | Seed: 152 | Fold: 3 | Log Loss: 0.017462211672979174\n",
      "5-Layer Model | Seed: 152 | Fold: 4 | Log Loss: 0.017327605237627778\n",
      "5-Layer Model | Seed: 152 | Fold: 5 | Log Loss: 0.017307417313908183\n",
      "5-Layer Model | Seed: 152 | Fold: 6 | Log Loss: 0.017319827361111168\n",
      "5-Layer Model | Seed: 152 | Fold: 7 | Log Loss: 0.01728516536693293\n",
      "\n",
      "5-Layer Model | Seed: 152 | Aggregate Log Loss: 0.01733203392816831\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "5-Layer Model | Aggregate Log Loss: 0.017371721535617838\n",
      "--------------------------------------------------------------------\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Total #iterations: 77\n",
      "Validation Logloss Metric: 0.3648061522479746\n"
     ]
    }
   ],
   "source": [
    "val_metric_final = 0\n",
    "y_pred_final = 0\n",
    "idx = 0\n",
    "ctr = 1\n",
    "\n",
    "for i in range(len(seed_mstr)):\n",
    "    seeds = seed_mstr[i]\n",
    "    val_metric = 0\n",
    "    j = 0\n",
    "    ctr += 1\n",
    "    \n",
    "    for seed in seeds:\n",
    "        seed_metric = 0\n",
    "\n",
    "        # Data Preprocessing\n",
    "        # Xtrain, Ytrain, Xpredict = data_preprocess(datasets, seed)\n",
    "\n",
    "        # Define K-fold cross validation test harness\n",
    "        kfold = MultilabelStratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "        for i, (train, val) in enumerate(kfold.split(Xtrain, Ytrain)):\n",
    "\n",
    "            idx += 1\n",
    "            j += 1\n",
    "            train_x_tmp, val_x_tmp = Xtrain[train], Xtrain[val]\n",
    "            train_y_tmp, val_y_tmp = Ytrain[train], Ytrain[val]\n",
    "\n",
    "            # Create the model\n",
    "            if ctr==2:\n",
    "                model = moa_prediction_model_2L(Xtrain.shape[1], Ytrain.shape[1])\n",
    "            elif ctr==3:\n",
    "                model = moa_prediction_model_3L(Xtrain.shape[1], Ytrain.shape[1])\n",
    "            elif ctr==4:\n",
    "                model = moa_prediction_model_4L(Xtrain.shape[1], Ytrain.shape[1])\n",
    "            elif ctr==5:\n",
    "                model = moa_prediction_model_5L(Xtrain.shape[1], Ytrain.shape[1])\n",
    "\n",
    "            # Compile model to configure the learning process\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=Lookahead(AdamW(lr=1e-2, \n",
    "                                                    weight_decay=1e-5, \n",
    "                                                    clipvalue=700), \n",
    "                                              sync_period=10))\n",
    "\n",
    "            # Early stopping policy\n",
    "            early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n",
    "                                  restore_best_weights=True, \n",
    "                                  patience=10, verbose=0)\n",
    "\n",
    "            # Reduce LR on plateau policy\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, \n",
    "                                          min_lr=1e-5, patience=5, \n",
    "                                          verbose=0, mode='min')\n",
    "\n",
    "            # Fit the model\n",
    "            history = model.fit(x=train_x_tmp, y=train_y_tmp, \n",
    "                                batch_size=mini_batch_size, \n",
    "                                epochs=85, verbose=0, workers=5,\n",
    "                                callbacks=[reduce_lr, early], \n",
    "                                validation_data=(val_x_tmp, val_y_tmp))\n",
    "\n",
    "            # Get logloss metric on validation dataset\n",
    "            y_pred = model.predict(val_x_tmp)\n",
    "            y_pred = np.clip(y_pred, p_min, p_max)\n",
    "            true_labels = pd.DataFrame(val_y_tmp, columns=train_label_df.columns)\n",
    "            pred_labels = pd.DataFrame(y_pred, columns=train_label_df.columns)\n",
    "            metric = logloss_metric(train_label_df, true_labels, pred_labels)\n",
    "            \n",
    "            # Assign the logloss metric to individual variables\n",
    "            seed_metric += metric\n",
    "            val_metric += metric\n",
    "            val_metric_final += metric\n",
    "\n",
    "            pred_final = model.predict(Xpredict)\n",
    "            y_pred_final += pred_final\n",
    "            print(\"{}-Layer Model | Seed: {} | Fold: {} | Log Loss: {}\".format(ctr, seed, (i+1), metric))\n",
    "        \n",
    "        \n",
    "        agg_metric_per_fold = seed_metric / FOLD\n",
    "        print(\"\\n{}-Layer Model | Seed: {} | Aggregate Log Loss: {}\".format(ctr, seed, agg_metric_per_fold))\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "    agg_metric_per_seed = val_metric / j\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"{}-Layer Model | Aggregate Log Loss: {}\".format(ctr, agg_metric_per_seed))\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nTotal #iterations: {}\".format(idx))\n",
    "val_metric_final /= float(idx)\n",
    "y_pred_final /= float(idx)\n",
    "print(\"Validation Logloss Metric: {}\".format(val_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051955,
     "end_time": "2020-10-20T17:40:04.188826",
     "exception": false,
     "start_time": "2020-10-20T17:40:04.136871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T17:40:04.301101Z",
     "iopub.status.busy": "2020-10-20T17:40:04.300186Z",
     "iopub.status.idle": "2020-10-20T17:40:04.343760Z",
     "shell.execute_reply": "2020-10-20T17:40:04.344350Z"
    },
    "papermill": {
     "duration": 0.102749,
     "end_time": "2020-10-20T17:40:04.344515",
     "exception": false,
     "start_time": "2020-10-20T17:40:04.241766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3982, 206)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.001934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.001517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.011944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>0.014895</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.012268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                     0.001195                0.001304        0.001383   \n",
       "1                     0.001000                0.001000        0.002028   \n",
       "2                     0.000000                0.000000        0.000000   \n",
       "3                     0.001000                0.001000        0.001738   \n",
       "4                     0.001000                0.001071        0.001255   \n",
       "\n",
       "   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                        0.015090                           0.024498   \n",
       "1                        0.003667                           0.004198   \n",
       "2                        0.000000                           0.000000   \n",
       "3                        0.009912                           0.011846   \n",
       "4                        0.009942                           0.014895   \n",
       "\n",
       "   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                        0.005698                    0.003395   \n",
       "1                        0.001933                    0.002291   \n",
       "2                        0.000000                    0.000000   \n",
       "3                        0.003252                    0.002705   \n",
       "4                        0.003758                    0.003373   \n",
       "\n",
       "   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                       0.006010                    0.001000   \n",
       "1                       0.005213                    0.003312   \n",
       "2                       0.000000                    0.000000   \n",
       "3                       0.005112                    0.001000   \n",
       "4                       0.003761                    0.001000   \n",
       "\n",
       "   adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                     0.017447  ...                                  0.001   \n",
       "1                     0.011430  ...                                  0.001   \n",
       "2                     0.000000  ...                                  0.000   \n",
       "3                     0.011944  ...                                  0.001   \n",
       "4                     0.012268  ...                                  0.001   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.001000         0.003421           0.001868   \n",
       "1      0.002008         0.002123           0.001019   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.001116         0.002540           0.003387   \n",
       "4      0.001163         0.002768           0.003787   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.001427                                  0.001   \n",
       "1                   0.010571                                  0.001   \n",
       "2                   0.000000                                  0.000   \n",
       "3                   0.007088                                  0.001   \n",
       "4                   0.001627                                  0.001   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.001225   0.001789                    0.002849       0.001934  \n",
       "1         0.007473   0.001098                    0.002142       0.001517  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.004711   0.001820                    0.001835       0.001908  \n",
       "4         0.001232   0.001209                    0.001831       0.001368  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final = np.clip(y_pred_final, p_min, p_max)\n",
    "pred_labels = pd.DataFrame(y_pred_final, columns=train_label_df.columns)\n",
    "pred_labels.loc[predict_df['cp_type']=='ctl_vehicle', train_label_df.columns] = 0\n",
    "print(pred_labels.shape)\n",
    "pred_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T17:40:04.471928Z",
     "iopub.status.busy": "2020-10-20T17:40:04.471182Z",
     "iopub.status.idle": "2020-10-20T17:40:04.774661Z",
     "shell.execute_reply": "2020-10-20T17:40:04.775237Z"
    },
    "papermill": {
     "duration": 0.371155,
     "end_time": "2020-10-20T17:40:04.775386",
     "exception": false,
     "start_time": "2020-10-20T17:40:04.404231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.001934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.001517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>0.014895</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.001195                0.001304   \n",
       "1  id_001897cda                     0.001000                0.001000   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.001000                0.001000   \n",
       "4  id_0027f1083                     0.001000                0.001071   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.001383                        0.015090   \n",
       "1        0.002028                        0.003667   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.001738                        0.009912   \n",
       "4        0.001255                        0.009942   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.024498                        0.005698   \n",
       "1                           0.004198                        0.001933   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.011846                        0.003252   \n",
       "4                           0.014895                        0.003758   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.003395                       0.006010   \n",
       "1                    0.002291                       0.005213   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.002705                       0.005112   \n",
       "4                    0.003373                       0.003761   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.001000  ...                                  0.001   \n",
       "1                    0.003312  ...                                  0.001   \n",
       "2                    0.000000  ...                                  0.000   \n",
       "3                    0.001000  ...                                  0.001   \n",
       "4                    0.001000  ...                                  0.001   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.001000         0.003421           0.001868   \n",
       "1      0.002008         0.002123           0.001019   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.001116         0.002540           0.003387   \n",
       "4      0.001163         0.002768           0.003787   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.001427                                  0.001   \n",
       "1                   0.010571                                  0.001   \n",
       "2                   0.000000                                  0.000   \n",
       "3                   0.007088                                  0.001   \n",
       "4                   0.001627                                  0.001   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.001225   0.001789                    0.002849       0.001934  \n",
       "1         0.007473   0.001098                    0.002142       0.001517  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.004711   0.001820                    0.001835       0.001908  \n",
       "4         0.001232   0.001209                    0.001831       0.001368  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df = pd.read_csv(\"/kaggle/input/lish-moa/sample_submission.csv\")\n",
    "submit_df.loc[:, submit_df.columns != 'sig_id'] = pred_labels\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T17:40:04.901822Z",
     "iopub.status.busy": "2020-10-20T17:40:04.900837Z",
     "iopub.status.idle": "2020-10-20T17:40:06.581303Z",
     "shell.execute_reply": "2020-10-20T17:40:06.582644Z"
    },
    "papermill": {
     "duration": 1.747479,
     "end_time": "2020-10-20T17:40:06.582849",
     "exception": false,
     "start_time": "2020-10-20T17:40:04.835370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.074928,
     "end_time": "2020-10-20T17:40:06.741035",
     "exception": false,
     "start_time": "2020-10-20T17:40:06.666107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 8918.814551,
   "end_time": "2020-10-20T17:40:08.521481",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-20T15:11:29.706930",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
