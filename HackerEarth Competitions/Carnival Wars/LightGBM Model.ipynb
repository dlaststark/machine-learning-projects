{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124566,
     "status": "ok",
     "timestamp": 1606810481562,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "Wn3claY6X8M1",
    "outputId": "a8c36c9f-a04b-4f5a-9614-dfdc9d64a84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcOJogQsYDkG"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236550,
     "status": "ok",
     "timestamp": 1606810716042,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "R3BhSNeuYBhF",
    "outputId": "a46d24fa-0bca-4d59-b65f-9c874b8c7a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LightGBM'...\n",
      "remote: Enumerating objects: 15, done.\u001b[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 20721 (delta 2), reused 4 (delta 1), pack-reused 20706\u001b[K\n",
      "Receiving objects: 100% (20721/20721), 16.12 MiB | 28.86 MiB/s, done.\n",
      "Resolving deltas: 100% (15123/15123), done.\n",
      "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'compute'\n",
      "Cloning into '/content/LightGBM/compute'...\n",
      "remote: Enumerating objects: 21728, done.        \n",
      "remote: Total 21728 (delta 0), reused 0 (delta 0), pack-reused 21728        \n",
      "Receiving objects: 100% (21728/21728), 8.51 MiB | 27.65 MiB/s, done.\n",
      "Resolving deltas: 100% (17565/17565), done.\n",
      "Submodule path 'compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
      "/content/LightGBM\n",
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
      "-- Looking for CL_VERSION_2_2\n",
      "-- Looking for CL_VERSION_2_2 - found\n",
      "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
      "-- OpenCL include directory: /usr/include\n",
      "-- Boost version: 1.65.1\n",
      "-- Found the following Boost libraries:\n",
      "--   filesystem\n",
      "--   system\n",
      "-- Performing Test MM_PREFETCH\n",
      "-- Performing Test MM_PREFETCH - Success\n",
      "-- Using _mm_prefetch\n",
      "-- Performing Test MM_MALLOC\n",
      "-- Performing Test MM_MALLOC - Success\n",
      "-- Using _mm_malloc\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/LightGBM\n",
      "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
      "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
      "[ 98%] \u001b[32m\u001b[1mLinking CXX executable lightgbm\u001b[0m\n",
      "[ 98%] Built target lightgbm\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library lib_lightgbm.so\u001b[0m\n",
      "[100%] Built target _lightgbm\n",
      "/content/LightGBM/python-package\n",
      "running install\n",
      "running build\n",
      "running build_py\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/lightgbm\n",
      "copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "running egg_info\n",
      "creating lightgbm.egg-info\n",
      "writing lightgbm.egg-info/PKG-INFO\n",
      "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "writing requirements to lightgbm.egg-info/requires.txt\n",
      "writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "no previously-included directories found matching 'build'\n",
      "warning: no files found matching 'LICENSE'\n",
      "warning: no files found matching '*.txt'\n",
      "warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "warning: no files found matching '*.txt' under directory 'compile'\n",
      "warning: no files found matching '*.so' under directory 'compile'\n",
      "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "warning: no files found matching '*.txt' under directory 'compile/compute'\n",
      "warning: no files found matching '*' under directory 'compile/compute/cmake'\n",
      "warning: no files found matching '*' under directory 'compile/compute/include'\n",
      "warning: no files found matching '*' under directory 'compile/compute/meta'\n",
      "warning: no files found matching '*' under directory 'compile/include'\n",
      "warning: no files found matching '*' under directory 'compile/src'\n",
      "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
      "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
      "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "warning: no previously-included files found matching 'compile/compute/.git'\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "running install_lib\n",
      "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
      "copying ../lib_lightgbm.so -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/compat.py to compat.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/basic.py to basic.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py to sklearn.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/callback.py to callback.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/libpath.py to libpath.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/engine.py to engine.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/plotting.py to plotting.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/__init__.py to __init__.cpython-36.pyc\n",
      "running install_egg_info\n",
      "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-3.1.0.99-py3.6.egg-info\n",
      "running install_scripts\n"
     ]
    }
   ],
   "source": [
    "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "%cd /content/LightGBM\n",
    "!mkdir build\n",
    "!cmake -DUSE_GPU=1\n",
    "!make -j$(nproc)\n",
    "%cd /content/LightGBM/python-package\n",
    "!sudo python setup.py install --precompile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248914,
     "status": "ok",
     "timestamp": 1606810729014,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "ExPKobZLYBjs",
    "outputId": "9b5c223f-c006-4059-bc2d-c20c0749dee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/10/06b58f4120f26b603d905a594650440ea1fd74476b8b360dbf01e111469b/optuna-2.3.0.tar.gz (258kB)\n",
      "\r",
      "\u001b[K     |█▎                              | 10kB 27.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 20kB 14.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 30kB 13.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 40kB 13.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 51kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 61kB 10.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 71kB 11.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 81kB 11.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 92kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 102kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 112kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 122kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 133kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 143kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 153kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 163kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 174kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 184kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 194kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 204kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 215kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 225kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 235kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 245kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 256kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 266kB 11.8MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
      "Collecting cmaes>=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/3c/06c76ec8b54b9b1fad7f35e903fd25010fe3e0d41bd94cea5e6f12e0d651/cmaes-0.7.0-py3-none-any.whl\n",
      "Collecting colorlog\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/c8/c16d30bbed11a1722060014c246d124582d1f781b26f5859d8dacc3e08e1/colorlog-4.6.2-py2.py3-none-any.whl\n",
      "Collecting alembic\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 34.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.17.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
      "Collecting cliff\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/61/5b64d73b01c1218f55c894b5ec0fb89b32c6960b7f7b3ad9f5ac0c373b9d/cliff-3.5.0-py3-none-any.whl (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 12.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna) (1.15.0)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Collecting Mako\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 48.8MB/s \n",
      "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/54/af6e2703f064485d717cb311d3f9440cd302a823ba6d80a020b59eae166d/cmd2-1.4.0-py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 52.6MB/s \n",
      "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.2\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
      "Collecting stevedore>=2.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
      "Collecting colorama>=0.3.7\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (2.0.0)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.4.0)\n",
      "Building wheels for collected packages: optuna\n",
      "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for optuna: filename=optuna-2.3.0-cp36-none-any.whl size=359761 sha256=d8c67e3a9f60cd047a223229193e015553ce32b5a3f1af6b74bdf6a84b77f3d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/fa/91/19/64b0ec6b964f89c0695a9dc6db6f851d0b54c5381a5c9cadfb\n",
      "Successfully built optuna\n",
      "Building wheels for collected packages: PrettyTable, pyperclip\n",
      "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for PrettyTable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=0fe84802e21f3e46947b697c3d2f51b2e6fe95bbc2a0dc5806d0ac2a4c8b98ba\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11119 sha256=c494fef3580a1fa05f8b9bf313abc666b807600ed0b39770c13103abc91c3e6a\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
      "Successfully built PrettyTable pyperclip\n",
      "Installing collected packages: cmaes, colorlog, python-editor, Mako, alembic, pbr, pyperclip, colorama, cmd2, PrettyTable, stevedore, cliff, optuna\n",
      "  Found existing installation: prettytable 2.0.0\n",
      "    Uninstalling prettytable-2.0.0:\n",
      "      Successfully uninstalled prettytable-2.0.0\n",
      "Successfully installed Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 cliff-3.5.0 cmaes-0.7.0 cmd2-1.4.0 colorama-0.4.4 colorlog-4.6.2 optuna-2.3.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 stevedore-3.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4494,
     "status": "ok",
     "timestamp": 1606810825824,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "dnYTm_ShYBln"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gB1VDy1sYQF2"
   },
   "source": [
    "## Load processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3616,
     "status": "ok",
     "timestamp": 1606810826756,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "g3A8chXUYBoz",
    "outputId": "a17bad88-028b-43f0-f7d4-1b1eed4c2405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape: (6313, 716)\n",
      "Ytrain shape: (6313,)\n",
      "Xpredict shape: (3430, 716)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/content/drive/My Drive/Colab Notebooks/Carnival Wars/Carnival_Wars_Dataset.txt\", 'rb') as handle: \n",
    "    data = handle.read()\n",
    "\n",
    "processed_data = pickle.loads(data)\n",
    "Xtrain = processed_data['Xtrain']\n",
    "Ytrain = processed_data['Ytrain']\n",
    "Xpredict = processed_data['Xpredict']\n",
    "\n",
    "Ytrain = np.cbrt(Ytrain)\n",
    "\n",
    "print(\"Xtrain shape: {}\".format(Xtrain.shape))\n",
    "print(\"Ytrain shape: {}\".format(Ytrain.shape))\n",
    "print(\"Xpredict shape: {}\".format(Xpredict.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2710,
     "status": "ok",
     "timestamp": 1606810826759,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "Cyy-GdRVuQIh",
    "outputId": "ea6b7d8c-6db1-4cb1-93c2-da90c1ff1bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['Stall_no','Market_Category','Loyalty_customer',\n",
    "                       'Product_Category','instock_time','Grade_Bin','Grade',\n",
    "                       'Demand','Discount_avail','instock_date_year','charges_2 (%)',\n",
    "                       'instock_date_quarter','Market_Bin','instock_date_month',\n",
    "                       'instock_date_day_week','instock_date_day_weekend',\n",
    "                       'clusters_k']\n",
    "categorical_columns_indices = [Xtrain.columns.get_loc(col) for col in categorical_columns]\n",
    "print(categorical_columns_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iWk2gZbZvWL"
   },
   "source": [
    "## Hyperparameter search using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1960,
     "status": "ok",
     "timestamp": 1606810827749,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "-ZFEFm6LYBsv"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"device_type\": \"gpu\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-2, 1e-1),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-4, 1.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 40, 1500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 25),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 5, 15),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 15)\n",
    "    }\n",
    "\n",
    "    # Define K-fold cross validation test harness\n",
    "    kfold = KFold(n_splits=7, shuffle=True, random_state=10)\n",
    "    counter = 0\n",
    "    rmsle = 0\n",
    "\n",
    "    for train, val in kfold.split(Xtrain.values, Ytrain.values):\n",
    "        counter += 1\n",
    "\n",
    "        train_x, train_y = Xtrain.iloc[train], Ytrain.iloc[train]\n",
    "        val_x, val_y = Xtrain.iloc[val], Ytrain.iloc[val]\n",
    "\n",
    "        lgtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        lgvalidation = lgb.Dataset(val_x, label=val_y)\n",
    "        \n",
    "        model = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgvalidation], \n",
    "                          categorical_feature=categorical_columns_indices,\n",
    "                          num_boost_round=5000, early_stopping_rounds=200, \n",
    "                          verbose_eval=False)\n",
    "\n",
    "        y_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "        rmsle += np.sqrt(mean_squared_log_error(val_y, y_pred))\n",
    "    \n",
    "    score = rmsle / float(counter)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "executionInfo": {
     "elapsed": 4803846,
     "status": "error",
     "timestamp": 1606815634614,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "mQTiW1zZYByu",
    "outputId": "cef651cd-1844-4c9d-9688-d18a2f6540c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 08:20:31,362]\u001b[0m A new study created in memory with name: no-name-a93d9929-4592-49e6-9238-b72a21daaa1d\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 08:28:51,037]\u001b[0m Trial 0 finished with value: 0.031088383907620254 and parameters: {'learning_rate': 0.019657689826785583, 'lambda_l2': 0.00012549152755589123, 'num_leaves': 1338, 'max_depth': 15, 'feature_fraction': 0.77935268145205, 'bagging_fraction': 0.5657635729430122, 'bagging_freq': 10, 'min_child_samples': 10}. Best is trial 0 with value: 0.031088383907620254.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 08:36:36,062]\u001b[0m Trial 1 finished with value: 0.031215768960198998 and parameters: {'learning_rate': 0.0671430878359602, 'lambda_l2': 0.2112859536412777, 'num_leaves': 1182, 'max_depth': 23, 'feature_fraction': 0.9096831022275919, 'bagging_fraction': 0.6849057210168278, 'bagging_freq': 11, 'min_child_samples': 9}. Best is trial 0 with value: 0.031088383907620254.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 08:42:33,841]\u001b[0m Trial 2 finished with value: 0.031278922171531894 and parameters: {'learning_rate': 0.030726421384399957, 'lambda_l2': 0.0008421673681141045, 'num_leaves': 516, 'max_depth': 11, 'feature_fraction': 0.874336128527923, 'bagging_fraction': 0.7960966665584384, 'bagging_freq': 13, 'min_child_samples': 9}. Best is trial 0 with value: 0.031088383907620254.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 08:49:19,345]\u001b[0m Trial 3 finished with value: 0.030943351251483727 and parameters: {'learning_rate': 0.059859377776455155, 'lambda_l2': 0.008487422800225668, 'num_leaves': 329, 'max_depth': 22, 'feature_fraction': 0.6290535620110349, 'bagging_fraction': 0.9009890987571443, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 3 with value: 0.030943351251483727.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 08:56:19,496]\u001b[0m Trial 4 finished with value: 0.031778910701125436 and parameters: {'learning_rate': 0.05082137787926711, 'lambda_l2': 0.0005774848780480441, 'num_leaves': 249, 'max_depth': 21, 'feature_fraction': 0.9656972104145407, 'bagging_fraction': 0.5637477408942959, 'bagging_freq': 15, 'min_child_samples': 13}. Best is trial 3 with value: 0.030943351251483727.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:00:44,866]\u001b[0m Trial 5 finished with value: 0.03119899154267622 and parameters: {'learning_rate': 0.01268612184992392, 'lambda_l2': 0.004645316780236036, 'num_leaves': 620, 'max_depth': 8, 'feature_fraction': 0.798707804521361, 'bagging_fraction': 0.5727643999451785, 'bagging_freq': 13, 'min_child_samples': 11}. Best is trial 3 with value: 0.030943351251483727.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:11:05,034]\u001b[0m Trial 6 finished with value: 0.030879984921745124 and parameters: {'learning_rate': 0.012696995607159497, 'lambda_l2': 0.7408157830395915, 'num_leaves': 791, 'max_depth': 14, 'feature_fraction': 0.9570870616543761, 'bagging_fraction': 0.6219423468155523, 'bagging_freq': 9, 'min_child_samples': 10}. Best is trial 6 with value: 0.030879984921745124.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:25:00,077]\u001b[0m Trial 7 finished with value: 0.030701466881611246 and parameters: {'learning_rate': 0.012521380412919617, 'lambda_l2': 0.4163606248009528, 'num_leaves': 911, 'max_depth': 22, 'feature_fraction': 0.6850199687453369, 'bagging_fraction': 0.6886580955674425, 'bagging_freq': 10, 'min_child_samples': 10}. Best is trial 7 with value: 0.030701466881611246.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:28:18,400]\u001b[0m Trial 8 finished with value: 0.031168154251617584 and parameters: {'learning_rate': 0.09903277089281429, 'lambda_l2': 0.0028925793685194586, 'num_leaves': 1203, 'max_depth': 16, 'feature_fraction': 0.5337549855634, 'bagging_fraction': 0.6466743765223737, 'bagging_freq': 10, 'min_child_samples': 7}. Best is trial 7 with value: 0.030701466881611246.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:34:01,656]\u001b[0m Trial 9 finished with value: 0.03127186069131253 and parameters: {'learning_rate': 0.012436531113728964, 'lambda_l2': 0.0013853805777859901, 'num_leaves': 1338, 'max_depth': 9, 'feature_fraction': 0.8390237138143546, 'bagging_fraction': 0.6136960392398764, 'bagging_freq': 9, 'min_child_samples': 13}. Best is trial 7 with value: 0.030701466881611246.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dc92947633ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Register the last intermediate value if present as the value of the trial.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d7727ed2c3d7>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     34\u001b[0m                           \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_columns_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                           verbose_eval=False)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/LightGBM/python-package/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/LightGBM/python-package/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2440\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1475,
     "status": "ok",
     "timestamp": 1606815637165,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "w3ycyNBUYB1b",
    "outputId": "e9b85ca7-0c08-4f30-cb91-7a7656acc27f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 11\n",
      "Best trial:\n",
      " Value: 0.030701466881611246\n",
      "Params: \n",
      " learning_rate: 0.012521380412919617\n",
      " lambda_l2: 0.4163606248009528\n",
      " num_leaves: 911\n",
      " max_depth: 22\n",
      " feature_fraction: 0.6850199687453369\n",
      " bagging_fraction: 0.6886580955674425\n",
      " bagging_freq: 10\n",
      " min_child_samples: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\" Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\" {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVLHuPtoaIwr"
   },
   "source": [
    "## Build and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2723,
     "status": "ok",
     "timestamp": 1606815680766,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "5J4dHSPK9v3K"
   },
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "params = {}\n",
    "params[\"objective\"] = 'regression'\n",
    "params[\"metric\"] = 'rmse'\n",
    "params[\"boosting\"] = 'gbdt'\n",
    "params[\"device_type\"] = 'gpu'\n",
    "params[\"learning_rate\"] = 0.01252\n",
    "params[\"lambda_l2\"] = 0.416361\n",
    "params[\"num_leaves\"] = 911\n",
    "params[\"max_depth\"] = 22\n",
    "params[\"feature_fraction\"] = 0.685\n",
    "params[\"bagging_fraction\"] = 0.689\n",
    "params[\"bagging_freq\"] = 10\n",
    "params[\"min_data_in_leaf\"] = 10\n",
    "params[\"verbosity\"] = -1\n",
    "num_rounds = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3279050,
     "status": "ok",
     "timestamp": 1606818958449,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "YasJCcWmYBxp",
    "outputId": "006a05e2-51b1-4037-97a6-daa2aad8e990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.196474\tvalid_1's rmse: 0.454996\n",
      "Early stopping, best iteration is:\n",
      "[450]\ttraining's rmse: 0.213583\tvalid_1's rmse: 0.453625\n",
      "Seed-40 | Fold-0 | RMSE Score: 0.0319335310053383\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.195659\tvalid_1's rmse: 0.346443\n",
      "Early stopping, best iteration is:\n",
      "[546]\ttraining's rmse: 0.185424\tvalid_1's rmse: 0.345572\n",
      "Seed-40 | Fold-1 | RMSE Score: 0.021431238703266048\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.206242\tvalid_1's rmse: 0.282809\n",
      "Early stopping, best iteration is:\n",
      "[529]\ttraining's rmse: 0.194683\tvalid_1's rmse: 0.281439\n",
      "Seed-40 | Fold-2 | RMSE Score: 0.018668570077517994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.2051\tvalid_1's rmse: 0.268729\n",
      "Early stopping, best iteration is:\n",
      "[450]\ttraining's rmse: 0.217615\tvalid_1's rmse: 0.261699\n",
      "Seed-40 | Fold-3 | RMSE Score: 0.01595266905277157\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.201666\tvalid_1's rmse: 0.33394\n",
      "Early stopping, best iteration is:\n",
      "[430]\ttraining's rmse: 0.220332\tvalid_1's rmse: 0.332387\n",
      "Seed-40 | Fold-4 | RMSE Score: 0.021036196102048425\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.163703\tvalid_1's rmse: 0.656163\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttraining's rmse: 0.179962\tvalid_1's rmse: 0.653558\n",
      "Seed-40 | Fold-5 | RMSE Score: 0.05792305024507435\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.187398\tvalid_1's rmse: 0.47235\n",
      "Early stopping, best iteration is:\n",
      "[580]\ttraining's rmse: 0.17262\tvalid_1's rmse: 0.469401\n",
      "Seed-40 | Fold-6 | RMSE Score: 0.03530604010288612\n",
      "\n",
      "Seed: 40 | Aggregate Log Loss: 0.028893042184128973\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's rmse: 0.271344\tvalid_1's rmse: 0.380523\n",
      "Seed-15 | Fold-0 | RMSE Score: 0.024294371307695087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.193655\tvalid_1's rmse: 0.364966\n",
      "Early stopping, best iteration is:\n",
      "[492]\ttraining's rmse: 0.195817\tvalid_1's rmse: 0.364643\n",
      "Seed-15 | Fold-1 | RMSE Score: 0.025491486401038387\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.190571\tvalid_1's rmse: 0.439907\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's rmse: 0.194579\tvalid_1's rmse: 0.439688\n",
      "Seed-15 | Fold-2 | RMSE Score: 0.030879078063335338\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.203685\tvalid_1's rmse: 0.314421\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's rmse: 0.188717\tvalid_1's rmse: 0.313063\n",
      "Seed-15 | Fold-3 | RMSE Score: 0.021488136787236066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.195872\tvalid_1's rmse: 0.400475\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's rmse: 0.173589\tvalid_1's rmse: 0.396303\n",
      "Seed-15 | Fold-4 | RMSE Score: 0.030041608903373283\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.195196\tvalid_1's rmse: 0.299349\n",
      "Early stopping, best iteration is:\n",
      "[410]\ttraining's rmse: 0.224466\tvalid_1's rmse: 0.296745\n",
      "Seed-15 | Fold-5 | RMSE Score: 0.018279769175939403\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttraining's rmse: 0.190751\tvalid_1's rmse: 0.631908\n",
      "Seed-15 | Fold-6 | RMSE Score: 0.05670094989699468\n",
      "\n",
      "Seed: 15 | Aggregate Log Loss: 0.029596485790801753\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.203349\tvalid_1's rmse: 0.319911\n",
      "Early stopping, best iteration is:\n",
      "[519]\ttraining's rmse: 0.198334\tvalid_1's rmse: 0.31895\n",
      "Seed-72 | Fold-0 | RMSE Score: 0.019535200817928797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.191816\tvalid_1's rmse: 0.501655\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttraining's rmse: 0.190209\tvalid_1's rmse: 0.501461\n",
      "Seed-72 | Fold-1 | RMSE Score: 0.033949790698665785\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.20717\tvalid_1's rmse: 0.280093\n",
      "Early stopping, best iteration is:\n",
      "[400]\ttraining's rmse: 0.238846\tvalid_1's rmse: 0.276258\n",
      "Seed-72 | Fold-2 | RMSE Score: 0.019259532000914795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.196318\tvalid_1's rmse: 0.458903\n",
      "Early stopping, best iteration is:\n",
      "[420]\ttraining's rmse: 0.218155\tvalid_1's rmse: 0.456674\n",
      "Seed-72 | Fold-3 | RMSE Score: 0.032256691956107975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.210376\tvalid_1's rmse: 0.382174\n",
      "Early stopping, best iteration is:\n",
      "[568]\ttraining's rmse: 0.198097\tvalid_1's rmse: 0.379997\n",
      "Seed-72 | Fold-4 | RMSE Score: 0.027638927126074655\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.203435\tvalid_1's rmse: 0.348264\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's rmse: 0.188475\tvalid_1's rmse: 0.347356\n",
      "Seed-72 | Fold-5 | RMSE Score: 0.025682149279110656\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttraining's rmse: 0.199018\tvalid_1's rmse: 0.61503\n",
      "Seed-72 | Fold-6 | RMSE Score: 0.05418345175150424\n",
      "\n",
      "Seed: 72 | Aggregate Log Loss: 0.03035796337575813\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.206254\tvalid_1's rmse: 0.265194\n",
      "Early stopping, best iteration is:\n",
      "[410]\ttraining's rmse: 0.23089\tvalid_1's rmse: 0.263288\n",
      "Seed-22 | Fold-0 | RMSE Score: 0.01756055987688908\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.19107\tvalid_1's rmse: 0.287071\n",
      "Early stopping, best iteration is:\n",
      "[452]\ttraining's rmse: 0.203618\tvalid_1's rmse: 0.285071\n",
      "Seed-22 | Fold-1 | RMSE Score: 0.018777173215216564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.204766\tvalid_1's rmse: 0.298346\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's rmse: 0.17736\tvalid_1's rmse: 0.295744\n",
      "Seed-22 | Fold-2 | RMSE Score: 0.019878651466380272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.206102\tvalid_1's rmse: 0.277505\n",
      "Early stopping, best iteration is:\n",
      "[530]\ttraining's rmse: 0.198978\tvalid_1's rmse: 0.273048\n",
      "Seed-22 | Fold-3 | RMSE Score: 0.01777203250746297\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.171253\tvalid_1's rmse: 0.641006\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttraining's rmse: 0.171253\tvalid_1's rmse: 0.641006\n",
      "Seed-22 | Fold-4 | RMSE Score: 0.05739909654818363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[360]\ttraining's rmse: 0.23625\tvalid_1's rmse: 0.464129\n",
      "Seed-22 | Fold-5 | RMSE Score: 0.03143275547567035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.184465\tvalid_1's rmse: 0.554651\n",
      "Early stopping, best iteration is:\n",
      "[470]\ttraining's rmse: 0.191716\tvalid_1's rmse: 0.553272\n",
      "Seed-22 | Fold-6 | RMSE Score: 0.03938197529023322\n",
      "\n",
      "Seed: 22 | Aggregate Log Loss: 0.02888603491143372\n",
      "\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.19344\tvalid_1's rmse: 0.414423\n",
      "Early stopping, best iteration is:\n",
      "[410]\ttraining's rmse: 0.219681\tvalid_1's rmse: 0.411521\n",
      "Seed-43 | Fold-0 | RMSE Score: 0.031081130823324702\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.205333\tvalid_1's rmse: 0.294616\n",
      "Early stopping, best iteration is:\n",
      "[589]\ttraining's rmse: 0.184333\tvalid_1's rmse: 0.291837\n",
      "Seed-43 | Fold-1 | RMSE Score: 0.021268699500535455\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.194835\tvalid_1's rmse: 0.36694\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's rmse: 0.183083\tvalid_1's rmse: 0.364885\n",
      "Seed-43 | Fold-2 | RMSE Score: 0.023137953314035363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.18318\tvalid_1's rmse: 0.567484\n",
      "Early stopping, best iteration is:\n",
      "[460]\ttraining's rmse: 0.192669\tvalid_1's rmse: 0.564183\n",
      "Seed-43 | Fold-3 | RMSE Score: 0.04005119314977501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's rmse: 0.246477\tvalid_1's rmse: 0.380855\n",
      "Seed-43 | Fold-4 | RMSE Score: 0.02463338415332178\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.207846\tvalid_1's rmse: 0.382289\n",
      "Early stopping, best iteration is:\n",
      "[430]\ttraining's rmse: 0.228362\tvalid_1's rmse: 0.380736\n",
      "Seed-43 | Fold-5 | RMSE Score: 0.027718190264261932\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's rmse: 0.170242\tvalid_1's rmse: 0.493471\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's rmse: 0.144026\tvalid_1's rmse: 0.489665\n",
      "Seed-43 | Fold-6 | RMSE Score: 0.04771619225107015\n",
      "\n",
      "Seed: 43 | Aggregate Log Loss: 0.030800963350903484\n",
      "\n",
      "\n",
      "Aggregate RMSE Score: 0.029706897922605214\n"
     ]
    }
   ],
   "source": [
    "# Set number of K-Folds and seeds\n",
    "FOLD = 7\n",
    "NUM_SEED = 5\n",
    "\n",
    "# Set seeds for model training\n",
    "np.random.seed(2)\n",
    "seeds = np.random.randint(0, 100, size=NUM_SEED)\n",
    "\n",
    "oof_rmsle_score = 0\n",
    "y_pred_meta_lgb = np.zeros((Ytrain.shape[0], NUM_SEED))\n",
    "y_pred_final_lgb = 0\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for sidx, seed in enumerate(seeds):\n",
    "    seed_rmsle_score = 0\n",
    "    \n",
    "    # Define K-fold cross validation test harness\n",
    "    kfold = KFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for idx, (train, val) in enumerate(kfold.split(Xtrain.values, Ytrain.values)):\n",
    "        counter += 1\n",
    "\n",
    "        train_x, train_y = Xtrain.iloc[train], Ytrain.iloc[train]\n",
    "        val_x, val_y = Xtrain.iloc[val], Ytrain.iloc[val]\n",
    "\n",
    "        lgtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        lgvalidation = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "        model = lgb.train(params, lgtrain, num_rounds, \n",
    "                          valid_sets=[lgtrain, lgvalidation], \n",
    "                          categorical_feature=categorical_columns_indices,\n",
    "                          early_stopping_rounds=100, verbose_eval=500)\n",
    "\n",
    "        y_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "        y_pred_meta_lgb[val, sidx] = y_pred\n",
    "        y_pred_final_lgb += model.predict(Xpredict, num_iteration=model.best_iteration)\n",
    "\n",
    "        score = np.sqrt(mean_squared_log_error(val_y, y_pred))\n",
    "        oof_rmsle_score += score\n",
    "        seed_rmsle_score += score\n",
    "        print(\"Seed-{} | Fold-{} | RMSE Score: {}\".format(seed, idx, score))\n",
    "    \n",
    "    print(\"\\nSeed: {} | Aggregate Log Loss: {}\\n\\n\".format(seed, (seed_rmsle_score / FOLD)))\n",
    "\n",
    "y_pred_final_lgb /= float(counter)\n",
    "oof_rmsle_score /= float(counter)\n",
    "print(\"Aggregate RMSE Score: {}\".format(oof_rmsle_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8WFE2cKdFvF"
   },
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 4494,
     "status": "ok",
     "timestamp": 1606819015187,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "95XgXAO7YBvl",
    "outputId": "3eb279e7-9339-4b0b-f666-516bd0553621"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_id</th>\n",
       "      <th>Selling_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCHE4YSTDVPVZVXW</td>\n",
       "      <td>3336.652922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCEGCATKHNRXUHW</td>\n",
       "      <td>2024.848163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NKCE6GJ5XVJDXNNZ</td>\n",
       "      <td>11859.056076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NKCEB8BK3ZXDHDHM</td>\n",
       "      <td>9503.277093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPEFDXSAHRNPF94</td>\n",
       "      <td>5658.964038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Product_id  Selling_Price\n",
       "0  SCHE4YSTDVPVZVXW    3336.652922\n",
       "1  ACCEGCATKHNRXUHW    2024.848163\n",
       "2  NKCE6GJ5XVJDXNNZ   11859.056076\n",
       "3  NKCEB8BK3ZXDHDHM    9503.277093\n",
       "4  TOPEFDXSAHRNPF94    5658.964038"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Carnival Wars/Dataset/test.csv\")\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df['Product_id'] = predict_df['Product_id']\n",
    "submit_df['Selling_Price'] = y_pred_final_lgb ** 3\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2074,
     "status": "ok",
     "timestamp": 1606819016940,
     "user": {
      "displayName": "TAPAS DAS",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiyffdGKiPCR_UwVittzTcbBFms70IkGfU15fatCA=s64",
      "userId": "10798398878324948542"
     },
     "user_tz": -330
    },
    "id": "9ToGJmnFYBnl"
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"/content/drive/My Drive/Colab Notebooks/Carnival Wars/Predictions/prediction_v9_LGB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MO7uo59kd54E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNK7+j9TL4r66+y9RbyNA/G",
   "collapsed_sections": [],
   "name": "LightGBM Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
